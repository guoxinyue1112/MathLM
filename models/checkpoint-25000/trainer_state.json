{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1000.0,
  "eval_steps": 500,
  "global_step": 25000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.4,
      "grad_norm": 10.984045028686523,
      "learning_rate": 1.9992e-05,
      "loss": 10.5537,
      "step": 10
    },
    {
      "epoch": 0.8,
      "grad_norm": 8.84665584564209,
      "learning_rate": 1.9984e-05,
      "loss": 10.125,
      "step": 20
    },
    {
      "epoch": 1.2,
      "grad_norm": 7.300137996673584,
      "learning_rate": 1.9976000000000003e-05,
      "loss": 9.8242,
      "step": 30
    },
    {
      "epoch": 1.6,
      "grad_norm": 6.869999885559082,
      "learning_rate": 1.9968e-05,
      "loss": 9.6408,
      "step": 40
    },
    {
      "epoch": 2.0,
      "grad_norm": 6.6047821044921875,
      "learning_rate": 1.9960000000000002e-05,
      "loss": 9.4941,
      "step": 50
    },
    {
      "epoch": 2.4,
      "grad_norm": 6.559911727905273,
      "learning_rate": 1.9952e-05,
      "loss": 9.3771,
      "step": 60
    },
    {
      "epoch": 2.8,
      "grad_norm": 6.302743434906006,
      "learning_rate": 1.9944e-05,
      "loss": 9.2807,
      "step": 70
    },
    {
      "epoch": 3.2,
      "grad_norm": 6.060093879699707,
      "learning_rate": 1.9936000000000004e-05,
      "loss": 9.1994,
      "step": 80
    },
    {
      "epoch": 3.6,
      "grad_norm": 6.2214860916137695,
      "learning_rate": 1.9928e-05,
      "loss": 9.159,
      "step": 90
    },
    {
      "epoch": 4.0,
      "grad_norm": 6.5882158279418945,
      "learning_rate": 1.9920000000000002e-05,
      "loss": 9.1141,
      "step": 100
    },
    {
      "epoch": 4.4,
      "grad_norm": 6.481194972991943,
      "learning_rate": 1.9912000000000002e-05,
      "loss": 9.0375,
      "step": 110
    },
    {
      "epoch": 4.8,
      "grad_norm": 5.666996002197266,
      "learning_rate": 1.9904e-05,
      "loss": 8.9865,
      "step": 120
    },
    {
      "epoch": 5.2,
      "grad_norm": 5.888041973114014,
      "learning_rate": 1.9896e-05,
      "loss": 8.9696,
      "step": 130
    },
    {
      "epoch": 5.6,
      "grad_norm": 5.257037162780762,
      "learning_rate": 1.9888e-05,
      "loss": 8.9132,
      "step": 140
    },
    {
      "epoch": 6.0,
      "grad_norm": 5.463204383850098,
      "learning_rate": 1.9880000000000003e-05,
      "loss": 8.886,
      "step": 150
    },
    {
      "epoch": 6.4,
      "grad_norm": 5.54872465133667,
      "learning_rate": 1.9872000000000002e-05,
      "loss": 8.8242,
      "step": 160
    },
    {
      "epoch": 6.8,
      "grad_norm": 5.6475701332092285,
      "learning_rate": 1.9864e-05,
      "loss": 8.7933,
      "step": 170
    },
    {
      "epoch": 7.2,
      "grad_norm": 5.342311382293701,
      "learning_rate": 1.9856e-05,
      "loss": 8.7685,
      "step": 180
    },
    {
      "epoch": 7.6,
      "grad_norm": 5.9184746742248535,
      "learning_rate": 1.9848e-05,
      "loss": 8.7152,
      "step": 190
    },
    {
      "epoch": 8.0,
      "grad_norm": 5.1330766677856445,
      "learning_rate": 1.9840000000000003e-05,
      "loss": 8.6694,
      "step": 200
    },
    {
      "epoch": 8.4,
      "grad_norm": 5.730838298797607,
      "learning_rate": 1.9832000000000003e-05,
      "loss": 8.647,
      "step": 210
    },
    {
      "epoch": 8.8,
      "grad_norm": 5.151213645935059,
      "learning_rate": 1.9824000000000002e-05,
      "loss": 8.5834,
      "step": 220
    },
    {
      "epoch": 9.2,
      "grad_norm": 4.927268981933594,
      "learning_rate": 1.9816e-05,
      "loss": 8.5571,
      "step": 230
    },
    {
      "epoch": 9.6,
      "grad_norm": 5.857181072235107,
      "learning_rate": 1.9808e-05,
      "loss": 8.502,
      "step": 240
    },
    {
      "epoch": 10.0,
      "grad_norm": 5.344552516937256,
      "learning_rate": 1.98e-05,
      "loss": 8.4581,
      "step": 250
    },
    {
      "epoch": 10.4,
      "grad_norm": 5.414448261260986,
      "learning_rate": 1.9792000000000003e-05,
      "loss": 8.42,
      "step": 260
    },
    {
      "epoch": 10.8,
      "grad_norm": 4.993253231048584,
      "learning_rate": 1.9784000000000002e-05,
      "loss": 8.3818,
      "step": 270
    },
    {
      "epoch": 11.2,
      "grad_norm": 5.529799938201904,
      "learning_rate": 1.9776000000000002e-05,
      "loss": 8.3292,
      "step": 280
    },
    {
      "epoch": 11.6,
      "grad_norm": 5.2363176345825195,
      "learning_rate": 1.9768e-05,
      "loss": 8.3022,
      "step": 290
    },
    {
      "epoch": 12.0,
      "grad_norm": 5.484208106994629,
      "learning_rate": 1.976e-05,
      "loss": 8.2549,
      "step": 300
    },
    {
      "epoch": 12.4,
      "grad_norm": 5.888391494750977,
      "learning_rate": 1.9752000000000003e-05,
      "loss": 8.2025,
      "step": 310
    },
    {
      "epoch": 12.8,
      "grad_norm": 5.203641891479492,
      "learning_rate": 1.9744e-05,
      "loss": 8.1668,
      "step": 320
    },
    {
      "epoch": 13.2,
      "grad_norm": 5.231391429901123,
      "learning_rate": 1.9736000000000002e-05,
      "loss": 8.1124,
      "step": 330
    },
    {
      "epoch": 13.6,
      "grad_norm": 5.377755641937256,
      "learning_rate": 1.9728e-05,
      "loss": 8.0894,
      "step": 340
    },
    {
      "epoch": 14.0,
      "grad_norm": 5.109486103057861,
      "learning_rate": 1.972e-05,
      "loss": 8.036,
      "step": 350
    },
    {
      "epoch": 14.4,
      "grad_norm": 5.008396148681641,
      "learning_rate": 1.9712000000000004e-05,
      "loss": 7.9631,
      "step": 360
    },
    {
      "epoch": 14.8,
      "grad_norm": 5.380725860595703,
      "learning_rate": 1.9704e-05,
      "loss": 7.9691,
      "step": 370
    },
    {
      "epoch": 15.2,
      "grad_norm": 4.960098743438721,
      "learning_rate": 1.9696000000000003e-05,
      "loss": 7.9036,
      "step": 380
    },
    {
      "epoch": 15.6,
      "grad_norm": 5.341366767883301,
      "learning_rate": 1.9688000000000002e-05,
      "loss": 7.8686,
      "step": 390
    },
    {
      "epoch": 16.0,
      "grad_norm": 5.275757789611816,
      "learning_rate": 1.968e-05,
      "loss": 7.7991,
      "step": 400
    },
    {
      "epoch": 16.4,
      "grad_norm": 5.359349250793457,
      "learning_rate": 1.9672e-05,
      "loss": 7.7642,
      "step": 410
    },
    {
      "epoch": 16.8,
      "grad_norm": 5.323794364929199,
      "learning_rate": 1.9664e-05,
      "loss": 7.7143,
      "step": 420
    },
    {
      "epoch": 17.2,
      "grad_norm": 4.965693950653076,
      "learning_rate": 1.9656000000000003e-05,
      "loss": 7.6873,
      "step": 430
    },
    {
      "epoch": 17.6,
      "grad_norm": 4.965656757354736,
      "learning_rate": 1.9648000000000002e-05,
      "loss": 7.6213,
      "step": 440
    },
    {
      "epoch": 18.0,
      "grad_norm": 5.302633285522461,
      "learning_rate": 1.9640000000000002e-05,
      "loss": 7.5759,
      "step": 450
    },
    {
      "epoch": 18.4,
      "grad_norm": 5.030320167541504,
      "learning_rate": 1.9632e-05,
      "loss": 7.5314,
      "step": 460
    },
    {
      "epoch": 18.8,
      "grad_norm": 5.17173433303833,
      "learning_rate": 1.9624e-05,
      "loss": 7.4925,
      "step": 470
    },
    {
      "epoch": 19.2,
      "grad_norm": 4.994810581207275,
      "learning_rate": 1.9616000000000003e-05,
      "loss": 7.4221,
      "step": 480
    },
    {
      "epoch": 19.6,
      "grad_norm": 5.111212253570557,
      "learning_rate": 1.9608000000000003e-05,
      "loss": 7.3978,
      "step": 490
    },
    {
      "epoch": 20.0,
      "grad_norm": 5.310111045837402,
      "learning_rate": 1.9600000000000002e-05,
      "loss": 7.3466,
      "step": 500
    },
    {
      "epoch": 20.4,
      "grad_norm": 5.25485897064209,
      "learning_rate": 1.9592e-05,
      "loss": 7.3097,
      "step": 510
    },
    {
      "epoch": 20.8,
      "grad_norm": 4.9291486740112305,
      "learning_rate": 1.9584e-05,
      "loss": 7.2356,
      "step": 520
    },
    {
      "epoch": 21.2,
      "grad_norm": 4.976053714752197,
      "learning_rate": 1.9576e-05,
      "loss": 7.1833,
      "step": 530
    },
    {
      "epoch": 21.6,
      "grad_norm": 5.316774368286133,
      "learning_rate": 1.9568000000000003e-05,
      "loss": 7.1505,
      "step": 540
    },
    {
      "epoch": 22.0,
      "grad_norm": 4.911403179168701,
      "learning_rate": 1.9560000000000002e-05,
      "loss": 7.1162,
      "step": 550
    },
    {
      "epoch": 22.4,
      "grad_norm": 4.755661964416504,
      "learning_rate": 1.9552000000000002e-05,
      "loss": 7.0573,
      "step": 560
    },
    {
      "epoch": 22.8,
      "grad_norm": 5.3365983963012695,
      "learning_rate": 1.9544e-05,
      "loss": 6.9986,
      "step": 570
    },
    {
      "epoch": 23.2,
      "grad_norm": 5.00468635559082,
      "learning_rate": 1.9536e-05,
      "loss": 6.9695,
      "step": 580
    },
    {
      "epoch": 23.6,
      "grad_norm": 5.413937091827393,
      "learning_rate": 1.9528000000000003e-05,
      "loss": 6.8912,
      "step": 590
    },
    {
      "epoch": 24.0,
      "grad_norm": 5.132611274719238,
      "learning_rate": 1.9520000000000003e-05,
      "loss": 6.8782,
      "step": 600
    },
    {
      "epoch": 24.4,
      "grad_norm": 5.262465953826904,
      "learning_rate": 1.9512000000000002e-05,
      "loss": 6.8041,
      "step": 610
    },
    {
      "epoch": 24.8,
      "grad_norm": 4.923498153686523,
      "learning_rate": 1.9504e-05,
      "loss": 6.7623,
      "step": 620
    },
    {
      "epoch": 25.2,
      "grad_norm": 5.125679016113281,
      "learning_rate": 1.9496e-05,
      "loss": 6.7154,
      "step": 630
    },
    {
      "epoch": 25.6,
      "grad_norm": 4.926852703094482,
      "learning_rate": 1.9488000000000004e-05,
      "loss": 6.6721,
      "step": 640
    },
    {
      "epoch": 26.0,
      "grad_norm": 4.830376148223877,
      "learning_rate": 1.948e-05,
      "loss": 6.6298,
      "step": 650
    },
    {
      "epoch": 26.4,
      "grad_norm": 5.0431318283081055,
      "learning_rate": 1.9472000000000003e-05,
      "loss": 6.5777,
      "step": 660
    },
    {
      "epoch": 26.8,
      "grad_norm": 4.799330711364746,
      "learning_rate": 1.9464000000000002e-05,
      "loss": 6.5202,
      "step": 670
    },
    {
      "epoch": 27.2,
      "grad_norm": 5.507471561431885,
      "learning_rate": 1.9456e-05,
      "loss": 6.4977,
      "step": 680
    },
    {
      "epoch": 27.6,
      "grad_norm": 5.003963947296143,
      "learning_rate": 1.9448e-05,
      "loss": 6.3917,
      "step": 690
    },
    {
      "epoch": 28.0,
      "grad_norm": 5.310183048248291,
      "learning_rate": 1.944e-05,
      "loss": 6.3844,
      "step": 700
    },
    {
      "epoch": 28.4,
      "grad_norm": 5.089722633361816,
      "learning_rate": 1.9432000000000003e-05,
      "loss": 6.3411,
      "step": 710
    },
    {
      "epoch": 28.8,
      "grad_norm": 4.9734883308410645,
      "learning_rate": 1.9424e-05,
      "loss": 6.2572,
      "step": 720
    },
    {
      "epoch": 29.2,
      "grad_norm": 5.415148735046387,
      "learning_rate": 1.9416000000000002e-05,
      "loss": 6.2308,
      "step": 730
    },
    {
      "epoch": 29.6,
      "grad_norm": 4.9348931312561035,
      "learning_rate": 1.9408e-05,
      "loss": 6.1682,
      "step": 740
    },
    {
      "epoch": 30.0,
      "grad_norm": 6.2699151039123535,
      "learning_rate": 1.94e-05,
      "loss": 6.1449,
      "step": 750
    },
    {
      "epoch": 30.4,
      "grad_norm": 5.318149089813232,
      "learning_rate": 1.9392000000000003e-05,
      "loss": 6.0947,
      "step": 760
    },
    {
      "epoch": 30.8,
      "grad_norm": 5.351165771484375,
      "learning_rate": 1.9384e-05,
      "loss": 6.0274,
      "step": 770
    },
    {
      "epoch": 31.2,
      "grad_norm": 5.508075714111328,
      "learning_rate": 1.9376000000000002e-05,
      "loss": 5.9759,
      "step": 780
    },
    {
      "epoch": 31.6,
      "grad_norm": 4.767101287841797,
      "learning_rate": 1.9368e-05,
      "loss": 5.9356,
      "step": 790
    },
    {
      "epoch": 32.0,
      "grad_norm": 5.408819675445557,
      "learning_rate": 1.936e-05,
      "loss": 5.8841,
      "step": 800
    },
    {
      "epoch": 32.4,
      "grad_norm": 5.700122833251953,
      "learning_rate": 1.9352e-05,
      "loss": 5.8519,
      "step": 810
    },
    {
      "epoch": 32.8,
      "grad_norm": 5.3708391189575195,
      "learning_rate": 1.9344e-05,
      "loss": 5.7651,
      "step": 820
    },
    {
      "epoch": 33.2,
      "grad_norm": 5.289337158203125,
      "learning_rate": 1.9336000000000003e-05,
      "loss": 5.7552,
      "step": 830
    },
    {
      "epoch": 33.6,
      "grad_norm": 5.029097080230713,
      "learning_rate": 1.9328000000000002e-05,
      "loss": 5.6805,
      "step": 840
    },
    {
      "epoch": 34.0,
      "grad_norm": 5.210256099700928,
      "learning_rate": 1.932e-05,
      "loss": 5.6445,
      "step": 850
    },
    {
      "epoch": 34.4,
      "grad_norm": 5.400643825531006,
      "learning_rate": 1.9312e-05,
      "loss": 5.5901,
      "step": 860
    },
    {
      "epoch": 34.8,
      "grad_norm": 5.0527777671813965,
      "learning_rate": 1.9304e-05,
      "loss": 5.5317,
      "step": 870
    },
    {
      "epoch": 35.2,
      "grad_norm": 4.929161548614502,
      "learning_rate": 1.9296000000000003e-05,
      "loss": 5.4934,
      "step": 880
    },
    {
      "epoch": 35.6,
      "grad_norm": 5.1490254402160645,
      "learning_rate": 1.9288000000000002e-05,
      "loss": 5.4301,
      "step": 890
    },
    {
      "epoch": 36.0,
      "grad_norm": 5.202225208282471,
      "learning_rate": 1.9280000000000002e-05,
      "loss": 5.425,
      "step": 900
    },
    {
      "epoch": 36.4,
      "grad_norm": 5.183063507080078,
      "learning_rate": 1.9272e-05,
      "loss": 5.3278,
      "step": 910
    },
    {
      "epoch": 36.8,
      "grad_norm": 5.066257476806641,
      "learning_rate": 1.9264e-05,
      "loss": 5.2952,
      "step": 920
    },
    {
      "epoch": 37.2,
      "grad_norm": 5.268606662750244,
      "learning_rate": 1.9256e-05,
      "loss": 5.2515,
      "step": 930
    },
    {
      "epoch": 37.6,
      "grad_norm": 4.992539882659912,
      "learning_rate": 1.9248000000000003e-05,
      "loss": 5.2137,
      "step": 940
    },
    {
      "epoch": 38.0,
      "grad_norm": 4.797325611114502,
      "learning_rate": 1.9240000000000002e-05,
      "loss": 5.157,
      "step": 950
    },
    {
      "epoch": 38.4,
      "grad_norm": 4.946631908416748,
      "learning_rate": 1.9232e-05,
      "loss": 5.0943,
      "step": 960
    },
    {
      "epoch": 38.8,
      "grad_norm": 5.0034613609313965,
      "learning_rate": 1.9224000000000004e-05,
      "loss": 5.0526,
      "step": 970
    },
    {
      "epoch": 39.2,
      "grad_norm": 4.856152534484863,
      "learning_rate": 1.9216e-05,
      "loss": 5.0218,
      "step": 980
    },
    {
      "epoch": 39.6,
      "grad_norm": 5.286744594573975,
      "learning_rate": 1.9208000000000003e-05,
      "loss": 4.9621,
      "step": 990
    },
    {
      "epoch": 40.0,
      "grad_norm": 5.493757724761963,
      "learning_rate": 1.9200000000000003e-05,
      "loss": 4.915,
      "step": 1000
    },
    {
      "epoch": 40.4,
      "grad_norm": 4.91395902633667,
      "learning_rate": 1.9192000000000002e-05,
      "loss": 4.8475,
      "step": 1010
    },
    {
      "epoch": 40.8,
      "grad_norm": 5.274454593658447,
      "learning_rate": 1.9184e-05,
      "loss": 4.8147,
      "step": 1020
    },
    {
      "epoch": 41.2,
      "grad_norm": 5.158360004425049,
      "learning_rate": 1.9176e-05,
      "loss": 4.7774,
      "step": 1030
    },
    {
      "epoch": 41.6,
      "grad_norm": 4.969630241394043,
      "learning_rate": 1.9168000000000004e-05,
      "loss": 4.7392,
      "step": 1040
    },
    {
      "epoch": 42.0,
      "grad_norm": 4.87748384475708,
      "learning_rate": 1.916e-05,
      "loss": 4.6841,
      "step": 1050
    },
    {
      "epoch": 42.4,
      "grad_norm": 4.8815155029296875,
      "learning_rate": 1.9152000000000002e-05,
      "loss": 4.6511,
      "step": 1060
    },
    {
      "epoch": 42.8,
      "grad_norm": 4.9653096199035645,
      "learning_rate": 1.9144000000000002e-05,
      "loss": 4.5675,
      "step": 1070
    },
    {
      "epoch": 43.2,
      "grad_norm": 4.945370197296143,
      "learning_rate": 1.9136e-05,
      "loss": 4.548,
      "step": 1080
    },
    {
      "epoch": 43.6,
      "grad_norm": 4.831944465637207,
      "learning_rate": 1.9128e-05,
      "loss": 4.4871,
      "step": 1090
    },
    {
      "epoch": 44.0,
      "grad_norm": 4.807396411895752,
      "learning_rate": 1.912e-05,
      "loss": 4.4274,
      "step": 1100
    },
    {
      "epoch": 44.4,
      "grad_norm": 4.8876471519470215,
      "learning_rate": 1.9112000000000003e-05,
      "loss": 4.3993,
      "step": 1110
    },
    {
      "epoch": 44.8,
      "grad_norm": 5.525731086730957,
      "learning_rate": 1.9104000000000002e-05,
      "loss": 4.3406,
      "step": 1120
    },
    {
      "epoch": 45.2,
      "grad_norm": 5.1943159103393555,
      "learning_rate": 1.9096e-05,
      "loss": 4.2952,
      "step": 1130
    },
    {
      "epoch": 45.6,
      "grad_norm": 4.839542865753174,
      "learning_rate": 1.9088e-05,
      "loss": 4.2938,
      "step": 1140
    },
    {
      "epoch": 46.0,
      "grad_norm": 4.724793910980225,
      "learning_rate": 1.908e-05,
      "loss": 4.1989,
      "step": 1150
    },
    {
      "epoch": 46.4,
      "grad_norm": 4.845808029174805,
      "learning_rate": 1.9072000000000003e-05,
      "loss": 4.1577,
      "step": 1160
    },
    {
      "epoch": 46.8,
      "grad_norm": 4.7575907707214355,
      "learning_rate": 1.9064000000000002e-05,
      "loss": 4.1259,
      "step": 1170
    },
    {
      "epoch": 47.2,
      "grad_norm": 4.703101634979248,
      "learning_rate": 1.9056000000000002e-05,
      "loss": 4.102,
      "step": 1180
    },
    {
      "epoch": 47.6,
      "grad_norm": 4.556838512420654,
      "learning_rate": 1.9048e-05,
      "loss": 4.0147,
      "step": 1190
    },
    {
      "epoch": 48.0,
      "grad_norm": 4.580620288848877,
      "learning_rate": 1.904e-05,
      "loss": 3.9936,
      "step": 1200
    },
    {
      "epoch": 48.4,
      "grad_norm": 4.7984137535095215,
      "learning_rate": 1.9032e-05,
      "loss": 3.9282,
      "step": 1210
    },
    {
      "epoch": 48.8,
      "grad_norm": 4.940051555633545,
      "learning_rate": 1.9024000000000003e-05,
      "loss": 3.9296,
      "step": 1220
    },
    {
      "epoch": 49.2,
      "grad_norm": 4.659286022186279,
      "learning_rate": 1.9016000000000002e-05,
      "loss": 3.8557,
      "step": 1230
    },
    {
      "epoch": 49.6,
      "grad_norm": 4.763175964355469,
      "learning_rate": 1.9008e-05,
      "loss": 3.821,
      "step": 1240
    },
    {
      "epoch": 50.0,
      "grad_norm": 5.010505199432373,
      "learning_rate": 1.9e-05,
      "loss": 3.7898,
      "step": 1250
    },
    {
      "epoch": 50.4,
      "grad_norm": 4.739394664764404,
      "learning_rate": 1.8992e-05,
      "loss": 3.7366,
      "step": 1260
    },
    {
      "epoch": 50.8,
      "grad_norm": 5.778618812561035,
      "learning_rate": 1.8984000000000003e-05,
      "loss": 3.6814,
      "step": 1270
    },
    {
      "epoch": 51.2,
      "grad_norm": 4.87892484664917,
      "learning_rate": 1.8976000000000003e-05,
      "loss": 3.6951,
      "step": 1280
    },
    {
      "epoch": 51.6,
      "grad_norm": 4.863799095153809,
      "learning_rate": 1.8968000000000002e-05,
      "loss": 3.6099,
      "step": 1290
    },
    {
      "epoch": 52.0,
      "grad_norm": 4.9098358154296875,
      "learning_rate": 1.896e-05,
      "loss": 3.5445,
      "step": 1300
    },
    {
      "epoch": 52.4,
      "grad_norm": 4.745373725891113,
      "learning_rate": 1.8952e-05,
      "loss": 3.5291,
      "step": 1310
    },
    {
      "epoch": 52.8,
      "grad_norm": 4.8315324783325195,
      "learning_rate": 1.8944000000000004e-05,
      "loss": 3.4949,
      "step": 1320
    },
    {
      "epoch": 53.2,
      "grad_norm": 5.170849323272705,
      "learning_rate": 1.8936e-05,
      "loss": 3.4527,
      "step": 1330
    },
    {
      "epoch": 53.6,
      "grad_norm": 4.7143635749816895,
      "learning_rate": 1.8928000000000002e-05,
      "loss": 3.4185,
      "step": 1340
    },
    {
      "epoch": 54.0,
      "grad_norm": 4.3288750648498535,
      "learning_rate": 1.8920000000000002e-05,
      "loss": 3.391,
      "step": 1350
    },
    {
      "epoch": 54.4,
      "grad_norm": 4.73554801940918,
      "learning_rate": 1.8912e-05,
      "loss": 3.3316,
      "step": 1360
    },
    {
      "epoch": 54.8,
      "grad_norm": 4.3849711418151855,
      "learning_rate": 1.8904000000000004e-05,
      "loss": 3.3118,
      "step": 1370
    },
    {
      "epoch": 55.2,
      "grad_norm": 4.780151844024658,
      "learning_rate": 1.8896e-05,
      "loss": 3.2742,
      "step": 1380
    },
    {
      "epoch": 55.6,
      "grad_norm": 4.2945661544799805,
      "learning_rate": 1.8888000000000003e-05,
      "loss": 3.2209,
      "step": 1390
    },
    {
      "epoch": 56.0,
      "grad_norm": 4.427391052246094,
      "learning_rate": 1.8880000000000002e-05,
      "loss": 3.1991,
      "step": 1400
    },
    {
      "epoch": 56.4,
      "grad_norm": 4.378344535827637,
      "learning_rate": 1.8872e-05,
      "loss": 3.17,
      "step": 1410
    },
    {
      "epoch": 56.8,
      "grad_norm": 4.70041561126709,
      "learning_rate": 1.8864e-05,
      "loss": 3.1263,
      "step": 1420
    },
    {
      "epoch": 57.2,
      "grad_norm": 4.442695140838623,
      "learning_rate": 1.8856e-05,
      "loss": 3.0834,
      "step": 1430
    },
    {
      "epoch": 57.6,
      "grad_norm": 4.181030750274658,
      "learning_rate": 1.8848000000000003e-05,
      "loss": 3.0457,
      "step": 1440
    },
    {
      "epoch": 58.0,
      "grad_norm": 4.684377670288086,
      "learning_rate": 1.884e-05,
      "loss": 3.0283,
      "step": 1450
    },
    {
      "epoch": 58.4,
      "grad_norm": 4.271407127380371,
      "learning_rate": 1.8832000000000002e-05,
      "loss": 3.0082,
      "step": 1460
    },
    {
      "epoch": 58.8,
      "grad_norm": 4.165981769561768,
      "learning_rate": 1.8824e-05,
      "loss": 2.9562,
      "step": 1470
    },
    {
      "epoch": 59.2,
      "grad_norm": 4.69419002532959,
      "learning_rate": 1.8816e-05,
      "loss": 2.9281,
      "step": 1480
    },
    {
      "epoch": 59.6,
      "grad_norm": 4.200986862182617,
      "learning_rate": 1.8808e-05,
      "loss": 2.9047,
      "step": 1490
    },
    {
      "epoch": 60.0,
      "grad_norm": 4.271190166473389,
      "learning_rate": 1.88e-05,
      "loss": 2.8348,
      "step": 1500
    },
    {
      "epoch": 60.4,
      "grad_norm": 3.912787437438965,
      "learning_rate": 1.8792000000000002e-05,
      "loss": 2.858,
      "step": 1510
    },
    {
      "epoch": 60.8,
      "grad_norm": 4.17155647277832,
      "learning_rate": 1.8784000000000002e-05,
      "loss": 2.7762,
      "step": 1520
    },
    {
      "epoch": 61.2,
      "grad_norm": 4.300570487976074,
      "learning_rate": 1.8776e-05,
      "loss": 2.8071,
      "step": 1530
    },
    {
      "epoch": 61.6,
      "grad_norm": 4.143209934234619,
      "learning_rate": 1.8768e-05,
      "loss": 2.7378,
      "step": 1540
    },
    {
      "epoch": 62.0,
      "grad_norm": 3.948417901992798,
      "learning_rate": 1.876e-05,
      "loss": 2.7059,
      "step": 1550
    },
    {
      "epoch": 62.4,
      "grad_norm": 3.6351001262664795,
      "learning_rate": 1.8752000000000003e-05,
      "loss": 2.7029,
      "step": 1560
    },
    {
      "epoch": 62.8,
      "grad_norm": 4.074438571929932,
      "learning_rate": 1.8744000000000002e-05,
      "loss": 2.6594,
      "step": 1570
    },
    {
      "epoch": 63.2,
      "grad_norm": 3.9156737327575684,
      "learning_rate": 1.8736e-05,
      "loss": 2.6256,
      "step": 1580
    },
    {
      "epoch": 63.6,
      "grad_norm": 4.077658653259277,
      "learning_rate": 1.8728e-05,
      "loss": 2.6244,
      "step": 1590
    },
    {
      "epoch": 64.0,
      "grad_norm": 3.886077642440796,
      "learning_rate": 1.8720000000000004e-05,
      "loss": 2.5814,
      "step": 1600
    },
    {
      "epoch": 64.4,
      "grad_norm": 3.6805715560913086,
      "learning_rate": 1.8712e-05,
      "loss": 2.5502,
      "step": 1610
    },
    {
      "epoch": 64.8,
      "grad_norm": 3.3923861980438232,
      "learning_rate": 1.8704000000000003e-05,
      "loss": 2.5512,
      "step": 1620
    },
    {
      "epoch": 65.2,
      "grad_norm": 3.595731735229492,
      "learning_rate": 1.8696000000000002e-05,
      "loss": 2.538,
      "step": 1630
    },
    {
      "epoch": 65.6,
      "grad_norm": 3.9286959171295166,
      "learning_rate": 1.8688e-05,
      "loss": 2.4932,
      "step": 1640
    },
    {
      "epoch": 66.0,
      "grad_norm": 3.5261001586914062,
      "learning_rate": 1.8680000000000004e-05,
      "loss": 2.4571,
      "step": 1650
    },
    {
      "epoch": 66.4,
      "grad_norm": 3.2980215549468994,
      "learning_rate": 1.8672e-05,
      "loss": 2.4719,
      "step": 1660
    },
    {
      "epoch": 66.8,
      "grad_norm": 3.5581259727478027,
      "learning_rate": 1.8664000000000003e-05,
      "loss": 2.3967,
      "step": 1670
    },
    {
      "epoch": 67.2,
      "grad_norm": 3.7667105197906494,
      "learning_rate": 1.8656000000000002e-05,
      "loss": 2.4062,
      "step": 1680
    },
    {
      "epoch": 67.6,
      "grad_norm": 3.816715717315674,
      "learning_rate": 1.8648000000000002e-05,
      "loss": 2.3569,
      "step": 1690
    },
    {
      "epoch": 68.0,
      "grad_norm": 3.7463181018829346,
      "learning_rate": 1.864e-05,
      "loss": 2.3818,
      "step": 1700
    },
    {
      "epoch": 68.4,
      "grad_norm": 3.584178924560547,
      "learning_rate": 1.8632e-05,
      "loss": 2.3364,
      "step": 1710
    },
    {
      "epoch": 68.8,
      "grad_norm": 3.657989740371704,
      "learning_rate": 1.8624000000000003e-05,
      "loss": 2.3278,
      "step": 1720
    },
    {
      "epoch": 69.2,
      "grad_norm": 3.5103790760040283,
      "learning_rate": 1.8616e-05,
      "loss": 2.2771,
      "step": 1730
    },
    {
      "epoch": 69.6,
      "grad_norm": 3.6919686794281006,
      "learning_rate": 1.8608000000000002e-05,
      "loss": 2.3079,
      "step": 1740
    },
    {
      "epoch": 70.0,
      "grad_norm": 3.187002658843994,
      "learning_rate": 1.86e-05,
      "loss": 2.2639,
      "step": 1750
    },
    {
      "epoch": 70.4,
      "grad_norm": 3.460911273956299,
      "learning_rate": 1.8592e-05,
      "loss": 2.2581,
      "step": 1760
    },
    {
      "epoch": 70.8,
      "grad_norm": 3.5556180477142334,
      "learning_rate": 1.8584000000000004e-05,
      "loss": 2.2176,
      "step": 1770
    },
    {
      "epoch": 71.2,
      "grad_norm": 3.109210729598999,
      "learning_rate": 1.8576e-05,
      "loss": 2.2364,
      "step": 1780
    },
    {
      "epoch": 71.6,
      "grad_norm": 3.0653183460235596,
      "learning_rate": 1.8568000000000002e-05,
      "loss": 2.238,
      "step": 1790
    },
    {
      "epoch": 72.0,
      "grad_norm": 3.1781575679779053,
      "learning_rate": 1.8560000000000002e-05,
      "loss": 2.1354,
      "step": 1800
    },
    {
      "epoch": 72.4,
      "grad_norm": 2.8937511444091797,
      "learning_rate": 1.8552e-05,
      "loss": 2.1902,
      "step": 1810
    },
    {
      "epoch": 72.8,
      "grad_norm": 3.049426555633545,
      "learning_rate": 1.8544e-05,
      "loss": 2.1637,
      "step": 1820
    },
    {
      "epoch": 73.2,
      "grad_norm": 3.9226620197296143,
      "learning_rate": 1.8536e-05,
      "loss": 2.1255,
      "step": 1830
    },
    {
      "epoch": 73.6,
      "grad_norm": 3.405506134033203,
      "learning_rate": 1.8528000000000003e-05,
      "loss": 2.0786,
      "step": 1840
    },
    {
      "epoch": 74.0,
      "grad_norm": 3.6721885204315186,
      "learning_rate": 1.8520000000000002e-05,
      "loss": 2.1223,
      "step": 1850
    },
    {
      "epoch": 74.4,
      "grad_norm": 3.355752468109131,
      "learning_rate": 1.8512e-05,
      "loss": 2.0971,
      "step": 1860
    },
    {
      "epoch": 74.8,
      "grad_norm": 3.194007158279419,
      "learning_rate": 1.8504e-05,
      "loss": 2.08,
      "step": 1870
    },
    {
      "epoch": 75.2,
      "grad_norm": 3.364915370941162,
      "learning_rate": 1.8496e-05,
      "loss": 2.0575,
      "step": 1880
    },
    {
      "epoch": 75.6,
      "grad_norm": 2.639008045196533,
      "learning_rate": 1.8488e-05,
      "loss": 2.0694,
      "step": 1890
    },
    {
      "epoch": 76.0,
      "grad_norm": 4.001629829406738,
      "learning_rate": 1.8480000000000003e-05,
      "loss": 2.025,
      "step": 1900
    },
    {
      "epoch": 76.4,
      "grad_norm": 2.860657215118408,
      "learning_rate": 1.8472000000000002e-05,
      "loss": 2.0268,
      "step": 1910
    },
    {
      "epoch": 76.8,
      "grad_norm": 2.621433973312378,
      "learning_rate": 1.8464e-05,
      "loss": 2.0261,
      "step": 1920
    },
    {
      "epoch": 77.2,
      "grad_norm": 2.9605369567871094,
      "learning_rate": 1.8456e-05,
      "loss": 1.9819,
      "step": 1930
    },
    {
      "epoch": 77.6,
      "grad_norm": 2.85697078704834,
      "learning_rate": 1.8448e-05,
      "loss": 2.0043,
      "step": 1940
    },
    {
      "epoch": 78.0,
      "grad_norm": 3.071510076522827,
      "learning_rate": 1.8440000000000003e-05,
      "loss": 1.9853,
      "step": 1950
    },
    {
      "epoch": 78.4,
      "grad_norm": 3.18681001663208,
      "learning_rate": 1.8432000000000002e-05,
      "loss": 1.9564,
      "step": 1960
    },
    {
      "epoch": 78.8,
      "grad_norm": 2.9233555793762207,
      "learning_rate": 1.8424000000000002e-05,
      "loss": 2.0129,
      "step": 1970
    },
    {
      "epoch": 79.2,
      "grad_norm": 2.9201087951660156,
      "learning_rate": 1.8416e-05,
      "loss": 1.9084,
      "step": 1980
    },
    {
      "epoch": 79.6,
      "grad_norm": 3.3548500537872314,
      "learning_rate": 1.8408e-05,
      "loss": 1.9131,
      "step": 1990
    },
    {
      "epoch": 80.0,
      "grad_norm": 2.680398941040039,
      "learning_rate": 1.8400000000000003e-05,
      "loss": 1.9548,
      "step": 2000
    },
    {
      "epoch": 80.4,
      "grad_norm": 2.9092857837677,
      "learning_rate": 1.8392e-05,
      "loss": 1.9215,
      "step": 2010
    },
    {
      "epoch": 80.8,
      "grad_norm": 2.7287471294403076,
      "learning_rate": 1.8384000000000002e-05,
      "loss": 1.9121,
      "step": 2020
    },
    {
      "epoch": 81.2,
      "grad_norm": 2.7424206733703613,
      "learning_rate": 1.8376e-05,
      "loss": 1.8723,
      "step": 2030
    },
    {
      "epoch": 81.6,
      "grad_norm": 2.9397192001342773,
      "learning_rate": 1.8368e-05,
      "loss": 1.9173,
      "step": 2040
    },
    {
      "epoch": 82.0,
      "grad_norm": 2.3720569610595703,
      "learning_rate": 1.8360000000000004e-05,
      "loss": 1.8801,
      "step": 2050
    },
    {
      "epoch": 82.4,
      "grad_norm": 2.3611693382263184,
      "learning_rate": 1.8352e-05,
      "loss": 1.8992,
      "step": 2060
    },
    {
      "epoch": 82.8,
      "grad_norm": 3.135589599609375,
      "learning_rate": 1.8344000000000003e-05,
      "loss": 1.8419,
      "step": 2070
    },
    {
      "epoch": 83.2,
      "grad_norm": 2.603569507598877,
      "learning_rate": 1.8336000000000002e-05,
      "loss": 1.8359,
      "step": 2080
    },
    {
      "epoch": 83.6,
      "grad_norm": 2.930450677871704,
      "learning_rate": 1.8328e-05,
      "loss": 1.8816,
      "step": 2090
    },
    {
      "epoch": 84.0,
      "grad_norm": 2.6511926651000977,
      "learning_rate": 1.832e-05,
      "loss": 1.8298,
      "step": 2100
    },
    {
      "epoch": 84.4,
      "grad_norm": 2.5654945373535156,
      "learning_rate": 1.8312e-05,
      "loss": 1.8477,
      "step": 2110
    },
    {
      "epoch": 84.8,
      "grad_norm": 2.8360836505889893,
      "learning_rate": 1.8304000000000003e-05,
      "loss": 1.8209,
      "step": 2120
    },
    {
      "epoch": 85.2,
      "grad_norm": 2.740746259689331,
      "learning_rate": 1.8296e-05,
      "loss": 1.8047,
      "step": 2130
    },
    {
      "epoch": 85.6,
      "grad_norm": 3.2155258655548096,
      "learning_rate": 1.8288000000000002e-05,
      "loss": 1.7974,
      "step": 2140
    },
    {
      "epoch": 86.0,
      "grad_norm": 2.2882702350616455,
      "learning_rate": 1.828e-05,
      "loss": 1.8042,
      "step": 2150
    },
    {
      "epoch": 86.4,
      "grad_norm": 2.326479434967041,
      "learning_rate": 1.8272e-05,
      "loss": 1.8413,
      "step": 2160
    },
    {
      "epoch": 86.8,
      "grad_norm": 3.023836851119995,
      "learning_rate": 1.8264000000000003e-05,
      "loss": 1.7682,
      "step": 2170
    },
    {
      "epoch": 87.2,
      "grad_norm": 2.249667167663574,
      "learning_rate": 1.8256e-05,
      "loss": 1.7522,
      "step": 2180
    },
    {
      "epoch": 87.6,
      "grad_norm": 3.115701913833618,
      "learning_rate": 1.8248000000000002e-05,
      "loss": 1.761,
      "step": 2190
    },
    {
      "epoch": 88.0,
      "grad_norm": 2.4917218685150146,
      "learning_rate": 1.824e-05,
      "loss": 1.7799,
      "step": 2200
    },
    {
      "epoch": 88.4,
      "grad_norm": 2.6187031269073486,
      "learning_rate": 1.8232e-05,
      "loss": 1.7585,
      "step": 2210
    },
    {
      "epoch": 88.8,
      "grad_norm": 2.5652854442596436,
      "learning_rate": 1.8224e-05,
      "loss": 1.7582,
      "step": 2220
    },
    {
      "epoch": 89.2,
      "grad_norm": 2.5138158798217773,
      "learning_rate": 1.8216000000000003e-05,
      "loss": 1.7413,
      "step": 2230
    },
    {
      "epoch": 89.6,
      "grad_norm": 2.4268853664398193,
      "learning_rate": 1.8208000000000003e-05,
      "loss": 1.7105,
      "step": 2240
    },
    {
      "epoch": 90.0,
      "grad_norm": 2.698077440261841,
      "learning_rate": 1.8200000000000002e-05,
      "loss": 1.7777,
      "step": 2250
    },
    {
      "epoch": 90.4,
      "grad_norm": 2.374873399734497,
      "learning_rate": 1.8192e-05,
      "loss": 1.7346,
      "step": 2260
    },
    {
      "epoch": 90.8,
      "grad_norm": 2.7772417068481445,
      "learning_rate": 1.8184e-05,
      "loss": 1.6944,
      "step": 2270
    },
    {
      "epoch": 91.2,
      "grad_norm": 2.7885143756866455,
      "learning_rate": 1.8176000000000004e-05,
      "loss": 1.7347,
      "step": 2280
    },
    {
      "epoch": 91.6,
      "grad_norm": 2.1990597248077393,
      "learning_rate": 1.8168e-05,
      "loss": 1.7281,
      "step": 2290
    },
    {
      "epoch": 92.0,
      "grad_norm": 2.842606782913208,
      "learning_rate": 1.8160000000000002e-05,
      "loss": 1.7027,
      "step": 2300
    },
    {
      "epoch": 92.4,
      "grad_norm": 2.45975661277771,
      "learning_rate": 1.8152000000000002e-05,
      "loss": 1.6816,
      "step": 2310
    },
    {
      "epoch": 92.8,
      "grad_norm": 2.3022851943969727,
      "learning_rate": 1.8144e-05,
      "loss": 1.6903,
      "step": 2320
    },
    {
      "epoch": 93.2,
      "grad_norm": 2.8452980518341064,
      "learning_rate": 1.8136000000000004e-05,
      "loss": 1.7246,
      "step": 2330
    },
    {
      "epoch": 93.6,
      "grad_norm": 2.6239013671875,
      "learning_rate": 1.8128e-05,
      "loss": 1.6681,
      "step": 2340
    },
    {
      "epoch": 94.0,
      "grad_norm": 2.7267422676086426,
      "learning_rate": 1.8120000000000003e-05,
      "loss": 1.7015,
      "step": 2350
    },
    {
      "epoch": 94.4,
      "grad_norm": 2.8934178352355957,
      "learning_rate": 1.8112000000000002e-05,
      "loss": 1.6873,
      "step": 2360
    },
    {
      "epoch": 94.8,
      "grad_norm": 2.9187796115875244,
      "learning_rate": 1.8104e-05,
      "loss": 1.6888,
      "step": 2370
    },
    {
      "epoch": 95.2,
      "grad_norm": 2.1750710010528564,
      "learning_rate": 1.8096e-05,
      "loss": 1.625,
      "step": 2380
    },
    {
      "epoch": 95.6,
      "grad_norm": 2.7835845947265625,
      "learning_rate": 1.8088e-05,
      "loss": 1.6835,
      "step": 2390
    },
    {
      "epoch": 96.0,
      "grad_norm": 2.2918777465820312,
      "learning_rate": 1.8080000000000003e-05,
      "loss": 1.6667,
      "step": 2400
    },
    {
      "epoch": 96.4,
      "grad_norm": 2.637678861618042,
      "learning_rate": 1.8072e-05,
      "loss": 1.6627,
      "step": 2410
    },
    {
      "epoch": 96.8,
      "grad_norm": 2.802427291870117,
      "learning_rate": 1.8064000000000002e-05,
      "loss": 1.6525,
      "step": 2420
    },
    {
      "epoch": 97.2,
      "grad_norm": 2.426640033721924,
      "learning_rate": 1.8056e-05,
      "loss": 1.6462,
      "step": 2430
    },
    {
      "epoch": 97.6,
      "grad_norm": 2.9495179653167725,
      "learning_rate": 1.8048e-05,
      "loss": 1.6414,
      "step": 2440
    },
    {
      "epoch": 98.0,
      "grad_norm": 3.14784836769104,
      "learning_rate": 1.8040000000000003e-05,
      "loss": 1.6354,
      "step": 2450
    },
    {
      "epoch": 98.4,
      "grad_norm": 2.4253740310668945,
      "learning_rate": 1.8032e-05,
      "loss": 1.6594,
      "step": 2460
    },
    {
      "epoch": 98.8,
      "grad_norm": 2.623180627822876,
      "learning_rate": 1.8024000000000002e-05,
      "loss": 1.6102,
      "step": 2470
    },
    {
      "epoch": 99.2,
      "grad_norm": 2.8733983039855957,
      "learning_rate": 1.8016e-05,
      "loss": 1.6297,
      "step": 2480
    },
    {
      "epoch": 99.6,
      "grad_norm": 2.928831100463867,
      "learning_rate": 1.8008e-05,
      "loss": 1.6213,
      "step": 2490
    },
    {
      "epoch": 100.0,
      "grad_norm": 3.595693588256836,
      "learning_rate": 1.8e-05,
      "loss": 1.6067,
      "step": 2500
    },
    {
      "epoch": 100.4,
      "grad_norm": 2.892726421356201,
      "learning_rate": 1.7992e-05,
      "loss": 1.6239,
      "step": 2510
    },
    {
      "epoch": 100.8,
      "grad_norm": 2.191763401031494,
      "learning_rate": 1.7984000000000003e-05,
      "loss": 1.5987,
      "step": 2520
    },
    {
      "epoch": 101.2,
      "grad_norm": 3.0005581378936768,
      "learning_rate": 1.7976000000000002e-05,
      "loss": 1.5808,
      "step": 2530
    },
    {
      "epoch": 101.6,
      "grad_norm": 2.5391502380371094,
      "learning_rate": 1.7968e-05,
      "loss": 1.581,
      "step": 2540
    },
    {
      "epoch": 102.0,
      "grad_norm": 2.713179588317871,
      "learning_rate": 1.796e-05,
      "loss": 1.64,
      "step": 2550
    },
    {
      "epoch": 102.4,
      "grad_norm": 2.4369449615478516,
      "learning_rate": 1.7952e-05,
      "loss": 1.6087,
      "step": 2560
    },
    {
      "epoch": 102.8,
      "grad_norm": 2.7927608489990234,
      "learning_rate": 1.7944000000000003e-05,
      "loss": 1.5822,
      "step": 2570
    },
    {
      "epoch": 103.2,
      "grad_norm": 2.241619110107422,
      "learning_rate": 1.7936000000000002e-05,
      "loss": 1.5693,
      "step": 2580
    },
    {
      "epoch": 103.6,
      "grad_norm": 2.6114749908447266,
      "learning_rate": 1.7928000000000002e-05,
      "loss": 1.5944,
      "step": 2590
    },
    {
      "epoch": 104.0,
      "grad_norm": 3.4793624877929688,
      "learning_rate": 1.792e-05,
      "loss": 1.5756,
      "step": 2600
    },
    {
      "epoch": 104.4,
      "grad_norm": 2.670175552368164,
      "learning_rate": 1.7912e-05,
      "loss": 1.5787,
      "step": 2610
    },
    {
      "epoch": 104.8,
      "grad_norm": 2.0689139366149902,
      "learning_rate": 1.7904e-05,
      "loss": 1.546,
      "step": 2620
    },
    {
      "epoch": 105.2,
      "grad_norm": 2.631895065307617,
      "learning_rate": 1.7896000000000003e-05,
      "loss": 1.586,
      "step": 2630
    },
    {
      "epoch": 105.6,
      "grad_norm": 2.6748242378234863,
      "learning_rate": 1.7888000000000002e-05,
      "loss": 1.5865,
      "step": 2640
    },
    {
      "epoch": 106.0,
      "grad_norm": 2.9347083568573,
      "learning_rate": 1.788e-05,
      "loss": 1.5477,
      "step": 2650
    },
    {
      "epoch": 106.4,
      "grad_norm": 2.566716432571411,
      "learning_rate": 1.7872e-05,
      "loss": 1.5284,
      "step": 2660
    },
    {
      "epoch": 106.8,
      "grad_norm": 4.214953422546387,
      "learning_rate": 1.7864e-05,
      "loss": 1.5726,
      "step": 2670
    },
    {
      "epoch": 107.2,
      "grad_norm": 2.8546416759490967,
      "learning_rate": 1.7856000000000003e-05,
      "loss": 1.5826,
      "step": 2680
    },
    {
      "epoch": 107.6,
      "grad_norm": 2.5898795127868652,
      "learning_rate": 1.7848e-05,
      "loss": 1.502,
      "step": 2690
    },
    {
      "epoch": 108.0,
      "grad_norm": 3.0775411128997803,
      "learning_rate": 1.7840000000000002e-05,
      "loss": 1.5578,
      "step": 2700
    },
    {
      "epoch": 108.4,
      "grad_norm": 2.5654914379119873,
      "learning_rate": 1.7832e-05,
      "loss": 1.5536,
      "step": 2710
    },
    {
      "epoch": 108.8,
      "grad_norm": 2.3461501598358154,
      "learning_rate": 1.7824e-05,
      "loss": 1.5487,
      "step": 2720
    },
    {
      "epoch": 109.2,
      "grad_norm": 2.923670530319214,
      "learning_rate": 1.7816000000000004e-05,
      "loss": 1.4974,
      "step": 2730
    },
    {
      "epoch": 109.6,
      "grad_norm": 2.460648775100708,
      "learning_rate": 1.7808e-05,
      "loss": 1.5584,
      "step": 2740
    },
    {
      "epoch": 110.0,
      "grad_norm": 2.8310513496398926,
      "learning_rate": 1.7800000000000002e-05,
      "loss": 1.5206,
      "step": 2750
    },
    {
      "epoch": 110.4,
      "grad_norm": 2.7255899906158447,
      "learning_rate": 1.7792000000000002e-05,
      "loss": 1.5272,
      "step": 2760
    },
    {
      "epoch": 110.8,
      "grad_norm": 2.561338424682617,
      "learning_rate": 1.7784e-05,
      "loss": 1.5142,
      "step": 2770
    },
    {
      "epoch": 111.2,
      "grad_norm": 3.031450033187866,
      "learning_rate": 1.7776e-05,
      "loss": 1.519,
      "step": 2780
    },
    {
      "epoch": 111.6,
      "grad_norm": 1.9909250736236572,
      "learning_rate": 1.7768e-05,
      "loss": 1.5122,
      "step": 2790
    },
    {
      "epoch": 112.0,
      "grad_norm": 2.372966766357422,
      "learning_rate": 1.7760000000000003e-05,
      "loss": 1.5408,
      "step": 2800
    },
    {
      "epoch": 112.4,
      "grad_norm": 3.2336885929107666,
      "learning_rate": 1.7752e-05,
      "loss": 1.5162,
      "step": 2810
    },
    {
      "epoch": 112.8,
      "grad_norm": 2.3863000869750977,
      "learning_rate": 1.7744e-05,
      "loss": 1.4984,
      "step": 2820
    },
    {
      "epoch": 113.2,
      "grad_norm": 2.435182571411133,
      "learning_rate": 1.7736e-05,
      "loss": 1.4891,
      "step": 2830
    },
    {
      "epoch": 113.6,
      "grad_norm": 2.789011001586914,
      "learning_rate": 1.7728e-05,
      "loss": 1.4995,
      "step": 2840
    },
    {
      "epoch": 114.0,
      "grad_norm": 2.6198408603668213,
      "learning_rate": 1.7720000000000003e-05,
      "loss": 1.5201,
      "step": 2850
    },
    {
      "epoch": 114.4,
      "grad_norm": 2.756786346435547,
      "learning_rate": 1.7712000000000003e-05,
      "loss": 1.5358,
      "step": 2860
    },
    {
      "epoch": 114.8,
      "grad_norm": 2.459019422531128,
      "learning_rate": 1.7704000000000002e-05,
      "loss": 1.468,
      "step": 2870
    },
    {
      "epoch": 115.2,
      "grad_norm": 2.494391441345215,
      "learning_rate": 1.7696e-05,
      "loss": 1.47,
      "step": 2880
    },
    {
      "epoch": 115.6,
      "grad_norm": 2.0751943588256836,
      "learning_rate": 1.7688e-05,
      "loss": 1.5204,
      "step": 2890
    },
    {
      "epoch": 116.0,
      "grad_norm": 2.210052013397217,
      "learning_rate": 1.768e-05,
      "loss": 1.4621,
      "step": 2900
    },
    {
      "epoch": 116.4,
      "grad_norm": 2.9354288578033447,
      "learning_rate": 1.7672000000000003e-05,
      "loss": 1.4539,
      "step": 2910
    },
    {
      "epoch": 116.8,
      "grad_norm": 2.0841283798217773,
      "learning_rate": 1.7664000000000002e-05,
      "loss": 1.5138,
      "step": 2920
    },
    {
      "epoch": 117.2,
      "grad_norm": 2.2248177528381348,
      "learning_rate": 1.7656000000000002e-05,
      "loss": 1.4709,
      "step": 2930
    },
    {
      "epoch": 117.6,
      "grad_norm": 3.459578275680542,
      "learning_rate": 1.7648e-05,
      "loss": 1.4936,
      "step": 2940
    },
    {
      "epoch": 118.0,
      "grad_norm": 2.440704345703125,
      "learning_rate": 1.764e-05,
      "loss": 1.4695,
      "step": 2950
    },
    {
      "epoch": 118.4,
      "grad_norm": 3.2983593940734863,
      "learning_rate": 1.7632000000000003e-05,
      "loss": 1.4697,
      "step": 2960
    },
    {
      "epoch": 118.8,
      "grad_norm": 2.8655691146850586,
      "learning_rate": 1.7624000000000003e-05,
      "loss": 1.4687,
      "step": 2970
    },
    {
      "epoch": 119.2,
      "grad_norm": 2.7236626148223877,
      "learning_rate": 1.7616000000000002e-05,
      "loss": 1.475,
      "step": 2980
    },
    {
      "epoch": 119.6,
      "grad_norm": 2.6828079223632812,
      "learning_rate": 1.7608e-05,
      "loss": 1.4374,
      "step": 2990
    },
    {
      "epoch": 120.0,
      "grad_norm": 2.6075522899627686,
      "learning_rate": 1.76e-05,
      "loss": 1.496,
      "step": 3000
    },
    {
      "epoch": 120.4,
      "grad_norm": 2.7027339935302734,
      "learning_rate": 1.7592000000000004e-05,
      "loss": 1.4756,
      "step": 3010
    },
    {
      "epoch": 120.8,
      "grad_norm": 2.5046422481536865,
      "learning_rate": 1.7584e-05,
      "loss": 1.4385,
      "step": 3020
    },
    {
      "epoch": 121.2,
      "grad_norm": 2.3118975162506104,
      "learning_rate": 1.7576000000000002e-05,
      "loss": 1.4524,
      "step": 3030
    },
    {
      "epoch": 121.6,
      "grad_norm": 2.4584097862243652,
      "learning_rate": 1.7568000000000002e-05,
      "loss": 1.43,
      "step": 3040
    },
    {
      "epoch": 122.0,
      "grad_norm": 2.4735970497131348,
      "learning_rate": 1.756e-05,
      "loss": 1.4832,
      "step": 3050
    },
    {
      "epoch": 122.4,
      "grad_norm": 3.3680171966552734,
      "learning_rate": 1.7552e-05,
      "loss": 1.4674,
      "step": 3060
    },
    {
      "epoch": 122.8,
      "grad_norm": 2.276005268096924,
      "learning_rate": 1.7544e-05,
      "loss": 1.4329,
      "step": 3070
    },
    {
      "epoch": 123.2,
      "grad_norm": 2.678436040878296,
      "learning_rate": 1.7536000000000003e-05,
      "loss": 1.4602,
      "step": 3080
    },
    {
      "epoch": 123.6,
      "grad_norm": 1.9462816715240479,
      "learning_rate": 1.7528e-05,
      "loss": 1.4489,
      "step": 3090
    },
    {
      "epoch": 124.0,
      "grad_norm": 3.6940155029296875,
      "learning_rate": 1.752e-05,
      "loss": 1.4275,
      "step": 3100
    },
    {
      "epoch": 124.4,
      "grad_norm": 2.5661423206329346,
      "learning_rate": 1.7512e-05,
      "loss": 1.4659,
      "step": 3110
    },
    {
      "epoch": 124.8,
      "grad_norm": 3.2824411392211914,
      "learning_rate": 1.7504e-05,
      "loss": 1.4206,
      "step": 3120
    },
    {
      "epoch": 125.2,
      "grad_norm": 2.0474491119384766,
      "learning_rate": 1.7496000000000003e-05,
      "loss": 1.4128,
      "step": 3130
    },
    {
      "epoch": 125.6,
      "grad_norm": 2.960374116897583,
      "learning_rate": 1.7488e-05,
      "loss": 1.4517,
      "step": 3140
    },
    {
      "epoch": 126.0,
      "grad_norm": 2.0545458793640137,
      "learning_rate": 1.7480000000000002e-05,
      "loss": 1.4266,
      "step": 3150
    },
    {
      "epoch": 126.4,
      "grad_norm": 2.6062676906585693,
      "learning_rate": 1.7472e-05,
      "loss": 1.4314,
      "step": 3160
    },
    {
      "epoch": 126.8,
      "grad_norm": 2.505464553833008,
      "learning_rate": 1.7464e-05,
      "loss": 1.4223,
      "step": 3170
    },
    {
      "epoch": 127.2,
      "grad_norm": 2.6469902992248535,
      "learning_rate": 1.7456e-05,
      "loss": 1.4305,
      "step": 3180
    },
    {
      "epoch": 127.6,
      "grad_norm": 3.381685733795166,
      "learning_rate": 1.7448e-05,
      "loss": 1.4398,
      "step": 3190
    },
    {
      "epoch": 128.0,
      "grad_norm": 2.793830633163452,
      "learning_rate": 1.7440000000000002e-05,
      "loss": 1.4027,
      "step": 3200
    },
    {
      "epoch": 128.4,
      "grad_norm": 2.2671284675598145,
      "learning_rate": 1.7432000000000002e-05,
      "loss": 1.4099,
      "step": 3210
    },
    {
      "epoch": 128.8,
      "grad_norm": 2.5955467224121094,
      "learning_rate": 1.7424e-05,
      "loss": 1.4178,
      "step": 3220
    },
    {
      "epoch": 129.2,
      "grad_norm": 3.0377612113952637,
      "learning_rate": 1.7416e-05,
      "loss": 1.4196,
      "step": 3230
    },
    {
      "epoch": 129.6,
      "grad_norm": 2.476161003112793,
      "learning_rate": 1.7408e-05,
      "loss": 1.3935,
      "step": 3240
    },
    {
      "epoch": 130.0,
      "grad_norm": 2.2014620304107666,
      "learning_rate": 1.7400000000000003e-05,
      "loss": 1.4478,
      "step": 3250
    },
    {
      "epoch": 130.4,
      "grad_norm": 2.3327436447143555,
      "learning_rate": 1.7392000000000002e-05,
      "loss": 1.4199,
      "step": 3260
    },
    {
      "epoch": 130.8,
      "grad_norm": 3.3678042888641357,
      "learning_rate": 1.7384e-05,
      "loss": 1.4112,
      "step": 3270
    },
    {
      "epoch": 131.2,
      "grad_norm": 2.7792556285858154,
      "learning_rate": 1.7376e-05,
      "loss": 1.3923,
      "step": 3280
    },
    {
      "epoch": 131.6,
      "grad_norm": 2.2271039485931396,
      "learning_rate": 1.7368e-05,
      "loss": 1.409,
      "step": 3290
    },
    {
      "epoch": 132.0,
      "grad_norm": 2.8407819271087646,
      "learning_rate": 1.736e-05,
      "loss": 1.4099,
      "step": 3300
    },
    {
      "epoch": 132.4,
      "grad_norm": 3.3470540046691895,
      "learning_rate": 1.7352000000000003e-05,
      "loss": 1.41,
      "step": 3310
    },
    {
      "epoch": 132.8,
      "grad_norm": 2.3882522583007812,
      "learning_rate": 1.7344000000000002e-05,
      "loss": 1.3984,
      "step": 3320
    },
    {
      "epoch": 133.2,
      "grad_norm": 2.4258649349212646,
      "learning_rate": 1.7336e-05,
      "loss": 1.3834,
      "step": 3330
    },
    {
      "epoch": 133.6,
      "grad_norm": 2.0938832759857178,
      "learning_rate": 1.7328e-05,
      "loss": 1.3826,
      "step": 3340
    },
    {
      "epoch": 134.0,
      "grad_norm": 2.2250847816467285,
      "learning_rate": 1.732e-05,
      "loss": 1.4148,
      "step": 3350
    },
    {
      "epoch": 134.4,
      "grad_norm": 2.941378355026245,
      "learning_rate": 1.7312000000000003e-05,
      "loss": 1.4005,
      "step": 3360
    },
    {
      "epoch": 134.8,
      "grad_norm": 2.908020496368408,
      "learning_rate": 1.7304000000000002e-05,
      "loss": 1.3895,
      "step": 3370
    },
    {
      "epoch": 135.2,
      "grad_norm": 2.455461025238037,
      "learning_rate": 1.7296000000000002e-05,
      "loss": 1.3814,
      "step": 3380
    },
    {
      "epoch": 135.6,
      "grad_norm": 2.883587121963501,
      "learning_rate": 1.7288e-05,
      "loss": 1.3893,
      "step": 3390
    },
    {
      "epoch": 136.0,
      "grad_norm": 2.1278610229492188,
      "learning_rate": 1.728e-05,
      "loss": 1.3931,
      "step": 3400
    },
    {
      "epoch": 136.4,
      "grad_norm": 2.5049469470977783,
      "learning_rate": 1.7272000000000003e-05,
      "loss": 1.3657,
      "step": 3410
    },
    {
      "epoch": 136.8,
      "grad_norm": 3.387101650238037,
      "learning_rate": 1.7264e-05,
      "loss": 1.3587,
      "step": 3420
    },
    {
      "epoch": 137.2,
      "grad_norm": 2.939574718475342,
      "learning_rate": 1.7256000000000002e-05,
      "loss": 1.4192,
      "step": 3430
    },
    {
      "epoch": 137.6,
      "grad_norm": 3.1186420917510986,
      "learning_rate": 1.7248e-05,
      "loss": 1.3862,
      "step": 3440
    },
    {
      "epoch": 138.0,
      "grad_norm": 2.392076253890991,
      "learning_rate": 1.724e-05,
      "loss": 1.3724,
      "step": 3450
    },
    {
      "epoch": 138.4,
      "grad_norm": 2.1783812046051025,
      "learning_rate": 1.7232000000000004e-05,
      "loss": 1.3731,
      "step": 3460
    },
    {
      "epoch": 138.8,
      "grad_norm": 2.74108624458313,
      "learning_rate": 1.7224e-05,
      "loss": 1.3694,
      "step": 3470
    },
    {
      "epoch": 139.2,
      "grad_norm": 2.4316935539245605,
      "learning_rate": 1.7216000000000003e-05,
      "loss": 1.3781,
      "step": 3480
    },
    {
      "epoch": 139.6,
      "grad_norm": 3.1138784885406494,
      "learning_rate": 1.7208000000000002e-05,
      "loss": 1.371,
      "step": 3490
    },
    {
      "epoch": 140.0,
      "grad_norm": 3.1430280208587646,
      "learning_rate": 1.72e-05,
      "loss": 1.3554,
      "step": 3500
    },
    {
      "epoch": 140.4,
      "grad_norm": 2.488685131072998,
      "learning_rate": 1.7192e-05,
      "loss": 1.3504,
      "step": 3510
    },
    {
      "epoch": 140.8,
      "grad_norm": 2.8822450637817383,
      "learning_rate": 1.7184e-05,
      "loss": 1.3621,
      "step": 3520
    },
    {
      "epoch": 141.2,
      "grad_norm": 1.8114936351776123,
      "learning_rate": 1.7176000000000003e-05,
      "loss": 1.3854,
      "step": 3530
    },
    {
      "epoch": 141.6,
      "grad_norm": 2.3140344619750977,
      "learning_rate": 1.7168000000000002e-05,
      "loss": 1.3448,
      "step": 3540
    },
    {
      "epoch": 142.0,
      "grad_norm": 2.7501299381256104,
      "learning_rate": 1.7160000000000002e-05,
      "loss": 1.3675,
      "step": 3550
    },
    {
      "epoch": 142.4,
      "grad_norm": 2.9656484127044678,
      "learning_rate": 1.7152e-05,
      "loss": 1.3758,
      "step": 3560
    },
    {
      "epoch": 142.8,
      "grad_norm": 2.8348846435546875,
      "learning_rate": 1.7144e-05,
      "loss": 1.3469,
      "step": 3570
    },
    {
      "epoch": 143.2,
      "grad_norm": 2.3430168628692627,
      "learning_rate": 1.7136e-05,
      "loss": 1.3608,
      "step": 3580
    },
    {
      "epoch": 143.6,
      "grad_norm": 2.2091288566589355,
      "learning_rate": 1.7128000000000003e-05,
      "loss": 1.3622,
      "step": 3590
    },
    {
      "epoch": 144.0,
      "grad_norm": 3.342440128326416,
      "learning_rate": 1.7120000000000002e-05,
      "loss": 1.3303,
      "step": 3600
    },
    {
      "epoch": 144.4,
      "grad_norm": 2.3665435314178467,
      "learning_rate": 1.7112e-05,
      "loss": 1.353,
      "step": 3610
    },
    {
      "epoch": 144.8,
      "grad_norm": 2.486647367477417,
      "learning_rate": 1.7104e-05,
      "loss": 1.3311,
      "step": 3620
    },
    {
      "epoch": 145.2,
      "grad_norm": 2.4805142879486084,
      "learning_rate": 1.7096e-05,
      "loss": 1.3579,
      "step": 3630
    },
    {
      "epoch": 145.6,
      "grad_norm": 2.804166793823242,
      "learning_rate": 1.7088000000000003e-05,
      "loss": 1.3329,
      "step": 3640
    },
    {
      "epoch": 146.0,
      "grad_norm": 2.729654312133789,
      "learning_rate": 1.7080000000000002e-05,
      "loss": 1.3669,
      "step": 3650
    },
    {
      "epoch": 146.4,
      "grad_norm": 2.7750964164733887,
      "learning_rate": 1.7072000000000002e-05,
      "loss": 1.3265,
      "step": 3660
    },
    {
      "epoch": 146.8,
      "grad_norm": 2.9518611431121826,
      "learning_rate": 1.7064e-05,
      "loss": 1.3427,
      "step": 3670
    },
    {
      "epoch": 147.2,
      "grad_norm": 2.936882257461548,
      "learning_rate": 1.7056e-05,
      "loss": 1.3511,
      "step": 3680
    },
    {
      "epoch": 147.6,
      "grad_norm": 2.768570899963379,
      "learning_rate": 1.7048000000000003e-05,
      "loss": 1.3375,
      "step": 3690
    },
    {
      "epoch": 148.0,
      "grad_norm": 2.754089117050171,
      "learning_rate": 1.704e-05,
      "loss": 1.343,
      "step": 3700
    },
    {
      "epoch": 148.4,
      "grad_norm": 3.3537676334381104,
      "learning_rate": 1.7032000000000002e-05,
      "loss": 1.3681,
      "step": 3710
    },
    {
      "epoch": 148.8,
      "grad_norm": 3.5580546855926514,
      "learning_rate": 1.7024e-05,
      "loss": 1.3153,
      "step": 3720
    },
    {
      "epoch": 149.2,
      "grad_norm": 2.8337175846099854,
      "learning_rate": 1.7016e-05,
      "loss": 1.3143,
      "step": 3730
    },
    {
      "epoch": 149.6,
      "grad_norm": 3.1991569995880127,
      "learning_rate": 1.7008000000000004e-05,
      "loss": 1.3521,
      "step": 3740
    },
    {
      "epoch": 150.0,
      "grad_norm": 3.771923303604126,
      "learning_rate": 1.7e-05,
      "loss": 1.313,
      "step": 3750
    },
    {
      "epoch": 150.4,
      "grad_norm": 3.322854518890381,
      "learning_rate": 1.6992000000000003e-05,
      "loss": 1.3285,
      "step": 3760
    },
    {
      "epoch": 150.8,
      "grad_norm": 2.2973077297210693,
      "learning_rate": 1.6984000000000002e-05,
      "loss": 1.3257,
      "step": 3770
    },
    {
      "epoch": 151.2,
      "grad_norm": 3.1627607345581055,
      "learning_rate": 1.6976e-05,
      "loss": 1.3173,
      "step": 3780
    },
    {
      "epoch": 151.6,
      "grad_norm": 2.6027708053588867,
      "learning_rate": 1.6968e-05,
      "loss": 1.3421,
      "step": 3790
    },
    {
      "epoch": 152.0,
      "grad_norm": 3.529966354370117,
      "learning_rate": 1.696e-05,
      "loss": 1.3159,
      "step": 3800
    },
    {
      "epoch": 152.4,
      "grad_norm": 2.7145321369171143,
      "learning_rate": 1.6952000000000003e-05,
      "loss": 1.3201,
      "step": 3810
    },
    {
      "epoch": 152.8,
      "grad_norm": 2.904691696166992,
      "learning_rate": 1.6944e-05,
      "loss": 1.3085,
      "step": 3820
    },
    {
      "epoch": 153.2,
      "grad_norm": 3.318601369857788,
      "learning_rate": 1.6936000000000002e-05,
      "loss": 1.3267,
      "step": 3830
    },
    {
      "epoch": 153.6,
      "grad_norm": 2.487687587738037,
      "learning_rate": 1.6928e-05,
      "loss": 1.32,
      "step": 3840
    },
    {
      "epoch": 154.0,
      "grad_norm": 2.3428568840026855,
      "learning_rate": 1.692e-05,
      "loss": 1.3108,
      "step": 3850
    },
    {
      "epoch": 154.4,
      "grad_norm": 2.8303143978118896,
      "learning_rate": 1.6912000000000003e-05,
      "loss": 1.3145,
      "step": 3860
    },
    {
      "epoch": 154.8,
      "grad_norm": 2.6606595516204834,
      "learning_rate": 1.6904e-05,
      "loss": 1.3233,
      "step": 3870
    },
    {
      "epoch": 155.2,
      "grad_norm": 3.0319676399230957,
      "learning_rate": 1.6896000000000002e-05,
      "loss": 1.306,
      "step": 3880
    },
    {
      "epoch": 155.6,
      "grad_norm": 2.6653995513916016,
      "learning_rate": 1.6888e-05,
      "loss": 1.3189,
      "step": 3890
    },
    {
      "epoch": 156.0,
      "grad_norm": 3.5360500812530518,
      "learning_rate": 1.688e-05,
      "loss": 1.2924,
      "step": 3900
    },
    {
      "epoch": 156.4,
      "grad_norm": 2.7006444931030273,
      "learning_rate": 1.6872e-05,
      "loss": 1.2876,
      "step": 3910
    },
    {
      "epoch": 156.8,
      "grad_norm": 2.449845314025879,
      "learning_rate": 1.6864e-05,
      "loss": 1.3365,
      "step": 3920
    },
    {
      "epoch": 157.2,
      "grad_norm": 2.30720591545105,
      "learning_rate": 1.6856000000000003e-05,
      "loss": 1.3151,
      "step": 3930
    },
    {
      "epoch": 157.6,
      "grad_norm": 3.1462087631225586,
      "learning_rate": 1.6848000000000002e-05,
      "loss": 1.2748,
      "step": 3940
    },
    {
      "epoch": 158.0,
      "grad_norm": 2.798572540283203,
      "learning_rate": 1.684e-05,
      "loss": 1.3071,
      "step": 3950
    },
    {
      "epoch": 158.4,
      "grad_norm": 2.7404944896698,
      "learning_rate": 1.6832e-05,
      "loss": 1.3017,
      "step": 3960
    },
    {
      "epoch": 158.8,
      "grad_norm": 3.502214193344116,
      "learning_rate": 1.6824e-05,
      "loss": 1.3167,
      "step": 3970
    },
    {
      "epoch": 159.2,
      "grad_norm": 2.6268258094787598,
      "learning_rate": 1.6816e-05,
      "loss": 1.2794,
      "step": 3980
    },
    {
      "epoch": 159.6,
      "grad_norm": 2.7151830196380615,
      "learning_rate": 1.6808000000000002e-05,
      "loss": 1.282,
      "step": 3990
    },
    {
      "epoch": 160.0,
      "grad_norm": 3.0595812797546387,
      "learning_rate": 1.6800000000000002e-05,
      "loss": 1.3164,
      "step": 4000
    },
    {
      "epoch": 160.4,
      "grad_norm": 2.7378089427948,
      "learning_rate": 1.6792e-05,
      "loss": 1.3125,
      "step": 4010
    },
    {
      "epoch": 160.8,
      "grad_norm": 2.4872848987579346,
      "learning_rate": 1.6784e-05,
      "loss": 1.2885,
      "step": 4020
    },
    {
      "epoch": 161.2,
      "grad_norm": 2.536585807800293,
      "learning_rate": 1.6776e-05,
      "loss": 1.269,
      "step": 4030
    },
    {
      "epoch": 161.6,
      "grad_norm": 2.6434996128082275,
      "learning_rate": 1.6768000000000003e-05,
      "loss": 1.3105,
      "step": 4040
    },
    {
      "epoch": 162.0,
      "grad_norm": 3.1439967155456543,
      "learning_rate": 1.6760000000000002e-05,
      "loss": 1.2793,
      "step": 4050
    },
    {
      "epoch": 162.4,
      "grad_norm": 2.231602907180786,
      "learning_rate": 1.6752e-05,
      "loss": 1.3006,
      "step": 4060
    },
    {
      "epoch": 162.8,
      "grad_norm": 2.9549126625061035,
      "learning_rate": 1.6744e-05,
      "loss": 1.3017,
      "step": 4070
    },
    {
      "epoch": 163.2,
      "grad_norm": 2.3204023838043213,
      "learning_rate": 1.6736e-05,
      "loss": 1.2384,
      "step": 4080
    },
    {
      "epoch": 163.6,
      "grad_norm": 2.7598018646240234,
      "learning_rate": 1.6728000000000003e-05,
      "loss": 1.2967,
      "step": 4090
    },
    {
      "epoch": 164.0,
      "grad_norm": 3.8379271030426025,
      "learning_rate": 1.672e-05,
      "loss": 1.2852,
      "step": 4100
    },
    {
      "epoch": 164.4,
      "grad_norm": 2.603214979171753,
      "learning_rate": 1.6712000000000002e-05,
      "loss": 1.288,
      "step": 4110
    },
    {
      "epoch": 164.8,
      "grad_norm": 2.778301477432251,
      "learning_rate": 1.6704e-05,
      "loss": 1.2723,
      "step": 4120
    },
    {
      "epoch": 165.2,
      "grad_norm": 2.292297601699829,
      "learning_rate": 1.6696e-05,
      "loss": 1.2553,
      "step": 4130
    },
    {
      "epoch": 165.6,
      "grad_norm": 2.6863319873809814,
      "learning_rate": 1.6688000000000004e-05,
      "loss": 1.276,
      "step": 4140
    },
    {
      "epoch": 166.0,
      "grad_norm": 2.6696314811706543,
      "learning_rate": 1.668e-05,
      "loss": 1.2912,
      "step": 4150
    },
    {
      "epoch": 166.4,
      "grad_norm": 2.824915647506714,
      "learning_rate": 1.6672000000000002e-05,
      "loss": 1.2823,
      "step": 4160
    },
    {
      "epoch": 166.8,
      "grad_norm": 2.932474374771118,
      "learning_rate": 1.6664000000000002e-05,
      "loss": 1.2646,
      "step": 4170
    },
    {
      "epoch": 167.2,
      "grad_norm": 3.9073221683502197,
      "learning_rate": 1.6656e-05,
      "loss": 1.2715,
      "step": 4180
    },
    {
      "epoch": 167.6,
      "grad_norm": 2.878382444381714,
      "learning_rate": 1.6648e-05,
      "loss": 1.264,
      "step": 4190
    },
    {
      "epoch": 168.0,
      "grad_norm": 2.5102078914642334,
      "learning_rate": 1.664e-05,
      "loss": 1.2776,
      "step": 4200
    },
    {
      "epoch": 168.4,
      "grad_norm": 2.668212413787842,
      "learning_rate": 1.6632000000000003e-05,
      "loss": 1.2494,
      "step": 4210
    },
    {
      "epoch": 168.8,
      "grad_norm": 2.3741698265075684,
      "learning_rate": 1.6624000000000002e-05,
      "loss": 1.2632,
      "step": 4220
    },
    {
      "epoch": 169.2,
      "grad_norm": 3.122560739517212,
      "learning_rate": 1.6616e-05,
      "loss": 1.2885,
      "step": 4230
    },
    {
      "epoch": 169.6,
      "grad_norm": 4.2598676681518555,
      "learning_rate": 1.6608e-05,
      "loss": 1.2769,
      "step": 4240
    },
    {
      "epoch": 170.0,
      "grad_norm": 2.7183420658111572,
      "learning_rate": 1.66e-05,
      "loss": 1.2554,
      "step": 4250
    },
    {
      "epoch": 170.4,
      "grad_norm": 3.649733781814575,
      "learning_rate": 1.6592000000000003e-05,
      "loss": 1.2747,
      "step": 4260
    },
    {
      "epoch": 170.8,
      "grad_norm": 2.6641907691955566,
      "learning_rate": 1.6584000000000002e-05,
      "loss": 1.2471,
      "step": 4270
    },
    {
      "epoch": 171.2,
      "grad_norm": 3.0611202716827393,
      "learning_rate": 1.6576000000000002e-05,
      "loss": 1.2665,
      "step": 4280
    },
    {
      "epoch": 171.6,
      "grad_norm": 2.1528232097625732,
      "learning_rate": 1.6568e-05,
      "loss": 1.2262,
      "step": 4290
    },
    {
      "epoch": 172.0,
      "grad_norm": 3.5127828121185303,
      "learning_rate": 1.656e-05,
      "loss": 1.2711,
      "step": 4300
    },
    {
      "epoch": 172.4,
      "grad_norm": 6.448054790496826,
      "learning_rate": 1.6552e-05,
      "loss": 1.2389,
      "step": 4310
    },
    {
      "epoch": 172.8,
      "grad_norm": 2.8521673679351807,
      "learning_rate": 1.6544000000000003e-05,
      "loss": 1.2845,
      "step": 4320
    },
    {
      "epoch": 173.2,
      "grad_norm": 2.5624661445617676,
      "learning_rate": 1.6536000000000002e-05,
      "loss": 1.2306,
      "step": 4330
    },
    {
      "epoch": 173.6,
      "grad_norm": 3.217315673828125,
      "learning_rate": 1.6528e-05,
      "loss": 1.2539,
      "step": 4340
    },
    {
      "epoch": 174.0,
      "grad_norm": 3.7561919689178467,
      "learning_rate": 1.652e-05,
      "loss": 1.2563,
      "step": 4350
    },
    {
      "epoch": 174.4,
      "grad_norm": 2.882108449935913,
      "learning_rate": 1.6512e-05,
      "loss": 1.26,
      "step": 4360
    },
    {
      "epoch": 174.8,
      "grad_norm": 4.0893940925598145,
      "learning_rate": 1.6504000000000003e-05,
      "loss": 1.2209,
      "step": 4370
    },
    {
      "epoch": 175.2,
      "grad_norm": 2.384726047515869,
      "learning_rate": 1.6496e-05,
      "loss": 1.2619,
      "step": 4380
    },
    {
      "epoch": 175.6,
      "grad_norm": 2.8962314128875732,
      "learning_rate": 1.6488000000000002e-05,
      "loss": 1.2715,
      "step": 4390
    },
    {
      "epoch": 176.0,
      "grad_norm": 4.328444957733154,
      "learning_rate": 1.648e-05,
      "loss": 1.2208,
      "step": 4400
    },
    {
      "epoch": 176.4,
      "grad_norm": 2.917598247528076,
      "learning_rate": 1.6472e-05,
      "loss": 1.2303,
      "step": 4410
    },
    {
      "epoch": 176.8,
      "grad_norm": 2.9892497062683105,
      "learning_rate": 1.6464000000000004e-05,
      "loss": 1.2278,
      "step": 4420
    },
    {
      "epoch": 177.2,
      "grad_norm": 2.557339906692505,
      "learning_rate": 1.6456e-05,
      "loss": 1.2941,
      "step": 4430
    },
    {
      "epoch": 177.6,
      "grad_norm": 3.8236119747161865,
      "learning_rate": 1.6448000000000002e-05,
      "loss": 1.2255,
      "step": 4440
    },
    {
      "epoch": 178.0,
      "grad_norm": 3.328599691390991,
      "learning_rate": 1.6440000000000002e-05,
      "loss": 1.2398,
      "step": 4450
    },
    {
      "epoch": 178.4,
      "grad_norm": 3.298095226287842,
      "learning_rate": 1.6432e-05,
      "loss": 1.2191,
      "step": 4460
    },
    {
      "epoch": 178.8,
      "grad_norm": 3.533964157104492,
      "learning_rate": 1.6424e-05,
      "loss": 1.244,
      "step": 4470
    },
    {
      "epoch": 179.2,
      "grad_norm": 2.4606080055236816,
      "learning_rate": 1.6416e-05,
      "loss": 1.2603,
      "step": 4480
    },
    {
      "epoch": 179.6,
      "grad_norm": 3.054501533508301,
      "learning_rate": 1.6408000000000003e-05,
      "loss": 1.2456,
      "step": 4490
    },
    {
      "epoch": 180.0,
      "grad_norm": 3.1057381629943848,
      "learning_rate": 1.64e-05,
      "loss": 1.2301,
      "step": 4500
    },
    {
      "epoch": 180.4,
      "grad_norm": 3.6117310523986816,
      "learning_rate": 1.6392e-05,
      "loss": 1.2398,
      "step": 4510
    },
    {
      "epoch": 180.8,
      "grad_norm": 2.2076504230499268,
      "learning_rate": 1.6384e-05,
      "loss": 1.2194,
      "step": 4520
    },
    {
      "epoch": 181.2,
      "grad_norm": 2.494554042816162,
      "learning_rate": 1.6376e-05,
      "loss": 1.2316,
      "step": 4530
    },
    {
      "epoch": 181.6,
      "grad_norm": 3.5810437202453613,
      "learning_rate": 1.6368000000000003e-05,
      "loss": 1.2646,
      "step": 4540
    },
    {
      "epoch": 182.0,
      "grad_norm": 4.075323104858398,
      "learning_rate": 1.636e-05,
      "loss": 1.1993,
      "step": 4550
    },
    {
      "epoch": 182.4,
      "grad_norm": 2.550947904586792,
      "learning_rate": 1.6352000000000002e-05,
      "loss": 1.1934,
      "step": 4560
    },
    {
      "epoch": 182.8,
      "grad_norm": 3.697523593902588,
      "learning_rate": 1.6344e-05,
      "loss": 1.247,
      "step": 4570
    },
    {
      "epoch": 183.2,
      "grad_norm": 2.642263650894165,
      "learning_rate": 1.6336e-05,
      "loss": 1.2571,
      "step": 4580
    },
    {
      "epoch": 183.6,
      "grad_norm": 3.288099527359009,
      "learning_rate": 1.6328e-05,
      "loss": 1.2242,
      "step": 4590
    },
    {
      "epoch": 184.0,
      "grad_norm": 3.5385067462921143,
      "learning_rate": 1.632e-05,
      "loss": 1.2324,
      "step": 4600
    },
    {
      "epoch": 184.4,
      "grad_norm": 3.067199945449829,
      "learning_rate": 1.6312000000000002e-05,
      "loss": 1.2051,
      "step": 4610
    },
    {
      "epoch": 184.8,
      "grad_norm": 2.921074151992798,
      "learning_rate": 1.6304000000000002e-05,
      "loss": 1.2173,
      "step": 4620
    },
    {
      "epoch": 185.2,
      "grad_norm": 3.1513264179229736,
      "learning_rate": 1.6296e-05,
      "loss": 1.2334,
      "step": 4630
    },
    {
      "epoch": 185.6,
      "grad_norm": 3.71418833732605,
      "learning_rate": 1.6288e-05,
      "loss": 1.2502,
      "step": 4640
    },
    {
      "epoch": 186.0,
      "grad_norm": 3.1376848220825195,
      "learning_rate": 1.628e-05,
      "loss": 1.2212,
      "step": 4650
    },
    {
      "epoch": 186.4,
      "grad_norm": 2.2937021255493164,
      "learning_rate": 1.6272000000000003e-05,
      "loss": 1.2278,
      "step": 4660
    },
    {
      "epoch": 186.8,
      "grad_norm": 2.7613258361816406,
      "learning_rate": 1.6264000000000002e-05,
      "loss": 1.1976,
      "step": 4670
    },
    {
      "epoch": 187.2,
      "grad_norm": 6.024230003356934,
      "learning_rate": 1.6256e-05,
      "loss": 1.2107,
      "step": 4680
    },
    {
      "epoch": 187.6,
      "grad_norm": 3.229337453842163,
      "learning_rate": 1.6248e-05,
      "loss": 1.2409,
      "step": 4690
    },
    {
      "epoch": 188.0,
      "grad_norm": 3.6623239517211914,
      "learning_rate": 1.6240000000000004e-05,
      "loss": 1.2141,
      "step": 4700
    },
    {
      "epoch": 188.4,
      "grad_norm": 2.822988986968994,
      "learning_rate": 1.6232e-05,
      "loss": 1.2217,
      "step": 4710
    },
    {
      "epoch": 188.8,
      "grad_norm": 3.2258567810058594,
      "learning_rate": 1.6224000000000003e-05,
      "loss": 1.2149,
      "step": 4720
    },
    {
      "epoch": 189.2,
      "grad_norm": 2.867429733276367,
      "learning_rate": 1.6216000000000002e-05,
      "loss": 1.2176,
      "step": 4730
    },
    {
      "epoch": 189.6,
      "grad_norm": 4.714286804199219,
      "learning_rate": 1.6208e-05,
      "loss": 1.2099,
      "step": 4740
    },
    {
      "epoch": 190.0,
      "grad_norm": 4.573692321777344,
      "learning_rate": 1.62e-05,
      "loss": 1.201,
      "step": 4750
    },
    {
      "epoch": 190.4,
      "grad_norm": 3.277769088745117,
      "learning_rate": 1.6192e-05,
      "loss": 1.2358,
      "step": 4760
    },
    {
      "epoch": 190.8,
      "grad_norm": 3.1654345989227295,
      "learning_rate": 1.6184000000000003e-05,
      "loss": 1.1933,
      "step": 4770
    },
    {
      "epoch": 191.2,
      "grad_norm": 3.5522429943084717,
      "learning_rate": 1.6176e-05,
      "loss": 1.2082,
      "step": 4780
    },
    {
      "epoch": 191.6,
      "grad_norm": 2.600255250930786,
      "learning_rate": 1.6168000000000002e-05,
      "loss": 1.1914,
      "step": 4790
    },
    {
      "epoch": 192.0,
      "grad_norm": 4.031550884246826,
      "learning_rate": 1.616e-05,
      "loss": 1.2121,
      "step": 4800
    },
    {
      "epoch": 192.4,
      "grad_norm": 4.989314079284668,
      "learning_rate": 1.6152e-05,
      "loss": 1.2139,
      "step": 4810
    },
    {
      "epoch": 192.8,
      "grad_norm": 3.4421544075012207,
      "learning_rate": 1.6144000000000003e-05,
      "loss": 1.2147,
      "step": 4820
    },
    {
      "epoch": 193.2,
      "grad_norm": 4.425675868988037,
      "learning_rate": 1.6136e-05,
      "loss": 1.1682,
      "step": 4830
    },
    {
      "epoch": 193.6,
      "grad_norm": 2.584664821624756,
      "learning_rate": 1.6128000000000002e-05,
      "loss": 1.2281,
      "step": 4840
    },
    {
      "epoch": 194.0,
      "grad_norm": 3.2760865688323975,
      "learning_rate": 1.612e-05,
      "loss": 1.1902,
      "step": 4850
    },
    {
      "epoch": 194.4,
      "grad_norm": 3.7826685905456543,
      "learning_rate": 1.6112e-05,
      "loss": 1.1701,
      "step": 4860
    },
    {
      "epoch": 194.8,
      "grad_norm": 3.096517324447632,
      "learning_rate": 1.6104e-05,
      "loss": 1.2459,
      "step": 4870
    },
    {
      "epoch": 195.2,
      "grad_norm": 3.0328807830810547,
      "learning_rate": 1.6096e-05,
      "loss": 1.2242,
      "step": 4880
    },
    {
      "epoch": 195.6,
      "grad_norm": 3.3190274238586426,
      "learning_rate": 1.6088000000000002e-05,
      "loss": 1.1774,
      "step": 4890
    },
    {
      "epoch": 196.0,
      "grad_norm": 2.9897966384887695,
      "learning_rate": 1.6080000000000002e-05,
      "loss": 1.1747,
      "step": 4900
    },
    {
      "epoch": 196.4,
      "grad_norm": 3.3069145679473877,
      "learning_rate": 1.6072e-05,
      "loss": 1.1968,
      "step": 4910
    },
    {
      "epoch": 196.8,
      "grad_norm": 3.8781113624572754,
      "learning_rate": 1.6064e-05,
      "loss": 1.2005,
      "step": 4920
    },
    {
      "epoch": 197.2,
      "grad_norm": 5.295881271362305,
      "learning_rate": 1.6056e-05,
      "loss": 1.1906,
      "step": 4930
    },
    {
      "epoch": 197.6,
      "grad_norm": 2.57009220123291,
      "learning_rate": 1.6048000000000003e-05,
      "loss": 1.1994,
      "step": 4940
    },
    {
      "epoch": 198.0,
      "grad_norm": 3.9650418758392334,
      "learning_rate": 1.6040000000000002e-05,
      "loss": 1.2087,
      "step": 4950
    },
    {
      "epoch": 198.4,
      "grad_norm": 4.2992753982543945,
      "learning_rate": 1.6032e-05,
      "loss": 1.1833,
      "step": 4960
    },
    {
      "epoch": 198.8,
      "grad_norm": 2.468597888946533,
      "learning_rate": 1.6024e-05,
      "loss": 1.197,
      "step": 4970
    },
    {
      "epoch": 199.2,
      "grad_norm": 4.681587219238281,
      "learning_rate": 1.6016e-05,
      "loss": 1.1952,
      "step": 4980
    },
    {
      "epoch": 199.6,
      "grad_norm": 2.650758743286133,
      "learning_rate": 1.6008e-05,
      "loss": 1.1915,
      "step": 4990
    },
    {
      "epoch": 200.0,
      "grad_norm": 4.444789886474609,
      "learning_rate": 1.6000000000000003e-05,
      "loss": 1.1893,
      "step": 5000
    },
    {
      "epoch": 200.4,
      "grad_norm": 3.4525742530822754,
      "learning_rate": 1.5992000000000002e-05,
      "loss": 1.1937,
      "step": 5010
    },
    {
      "epoch": 200.8,
      "grad_norm": 4.5222392082214355,
      "learning_rate": 1.5984e-05,
      "loss": 1.1854,
      "step": 5020
    },
    {
      "epoch": 201.2,
      "grad_norm": 2.8098747730255127,
      "learning_rate": 1.5976e-05,
      "loss": 1.2052,
      "step": 5030
    },
    {
      "epoch": 201.6,
      "grad_norm": 4.19790506362915,
      "learning_rate": 1.5968e-05,
      "loss": 1.2094,
      "step": 5040
    },
    {
      "epoch": 202.0,
      "grad_norm": 2.8090412616729736,
      "learning_rate": 1.5960000000000003e-05,
      "loss": 1.1631,
      "step": 5050
    },
    {
      "epoch": 202.4,
      "grad_norm": 2.7918202877044678,
      "learning_rate": 1.5952000000000002e-05,
      "loss": 1.1605,
      "step": 5060
    },
    {
      "epoch": 202.8,
      "grad_norm": 4.056282997131348,
      "learning_rate": 1.5944000000000002e-05,
      "loss": 1.198,
      "step": 5070
    },
    {
      "epoch": 203.2,
      "grad_norm": 3.0642659664154053,
      "learning_rate": 1.5936e-05,
      "loss": 1.1973,
      "step": 5080
    },
    {
      "epoch": 203.6,
      "grad_norm": 4.598696708679199,
      "learning_rate": 1.5928e-05,
      "loss": 1.181,
      "step": 5090
    },
    {
      "epoch": 204.0,
      "grad_norm": 3.9440090656280518,
      "learning_rate": 1.5920000000000003e-05,
      "loss": 1.1683,
      "step": 5100
    },
    {
      "epoch": 204.4,
      "grad_norm": 2.365440607070923,
      "learning_rate": 1.5912e-05,
      "loss": 1.1835,
      "step": 5110
    },
    {
      "epoch": 204.8,
      "grad_norm": 3.7935128211975098,
      "learning_rate": 1.5904000000000002e-05,
      "loss": 1.154,
      "step": 5120
    },
    {
      "epoch": 205.2,
      "grad_norm": 2.611403465270996,
      "learning_rate": 1.5896e-05,
      "loss": 1.1874,
      "step": 5130
    },
    {
      "epoch": 205.6,
      "grad_norm": 3.65511417388916,
      "learning_rate": 1.5888e-05,
      "loss": 1.1726,
      "step": 5140
    },
    {
      "epoch": 206.0,
      "grad_norm": 3.617178201675415,
      "learning_rate": 1.588e-05,
      "loss": 1.1881,
      "step": 5150
    },
    {
      "epoch": 206.4,
      "grad_norm": 3.989341974258423,
      "learning_rate": 1.5872e-05,
      "loss": 1.1878,
      "step": 5160
    },
    {
      "epoch": 206.8,
      "grad_norm": 4.199770927429199,
      "learning_rate": 1.5864000000000003e-05,
      "loss": 1.1674,
      "step": 5170
    },
    {
      "epoch": 207.2,
      "grad_norm": 2.783292293548584,
      "learning_rate": 1.5856e-05,
      "loss": 1.1835,
      "step": 5180
    },
    {
      "epoch": 207.6,
      "grad_norm": 3.785146474838257,
      "learning_rate": 1.5848e-05,
      "loss": 1.1693,
      "step": 5190
    },
    {
      "epoch": 208.0,
      "grad_norm": 4.727751731872559,
      "learning_rate": 1.584e-05,
      "loss": 1.1827,
      "step": 5200
    },
    {
      "epoch": 208.4,
      "grad_norm": 3.0421929359436035,
      "learning_rate": 1.5832e-05,
      "loss": 1.1786,
      "step": 5210
    },
    {
      "epoch": 208.8,
      "grad_norm": 4.239263534545898,
      "learning_rate": 1.5824000000000003e-05,
      "loss": 1.1566,
      "step": 5220
    },
    {
      "epoch": 209.2,
      "grad_norm": 3.1049606800079346,
      "learning_rate": 1.5816e-05,
      "loss": 1.1814,
      "step": 5230
    },
    {
      "epoch": 209.6,
      "grad_norm": 2.8697919845581055,
      "learning_rate": 1.5808000000000002e-05,
      "loss": 1.1848,
      "step": 5240
    },
    {
      "epoch": 210.0,
      "grad_norm": 2.734759569168091,
      "learning_rate": 1.58e-05,
      "loss": 1.1764,
      "step": 5250
    },
    {
      "epoch": 210.4,
      "grad_norm": 3.052654266357422,
      "learning_rate": 1.5792e-05,
      "loss": 1.1663,
      "step": 5260
    },
    {
      "epoch": 210.8,
      "grad_norm": 3.686544895172119,
      "learning_rate": 1.5784e-05,
      "loss": 1.1533,
      "step": 5270
    },
    {
      "epoch": 211.2,
      "grad_norm": 4.477402687072754,
      "learning_rate": 1.5776e-05,
      "loss": 1.1855,
      "step": 5280
    },
    {
      "epoch": 211.6,
      "grad_norm": 3.5027332305908203,
      "learning_rate": 1.5768000000000002e-05,
      "loss": 1.1848,
      "step": 5290
    },
    {
      "epoch": 212.0,
      "grad_norm": 3.701267719268799,
      "learning_rate": 1.576e-05,
      "loss": 1.1911,
      "step": 5300
    },
    {
      "epoch": 212.4,
      "grad_norm": 4.260640621185303,
      "learning_rate": 1.5752e-05,
      "loss": 1.1377,
      "step": 5310
    },
    {
      "epoch": 212.8,
      "grad_norm": 3.8071048259735107,
      "learning_rate": 1.5744e-05,
      "loss": 1.1926,
      "step": 5320
    },
    {
      "epoch": 213.2,
      "grad_norm": 4.06397819519043,
      "learning_rate": 1.5736000000000003e-05,
      "loss": 1.1739,
      "step": 5330
    },
    {
      "epoch": 213.6,
      "grad_norm": 3.45627498626709,
      "learning_rate": 1.5728000000000003e-05,
      "loss": 1.1288,
      "step": 5340
    },
    {
      "epoch": 214.0,
      "grad_norm": 4.516757488250732,
      "learning_rate": 1.5720000000000002e-05,
      "loss": 1.1805,
      "step": 5350
    },
    {
      "epoch": 214.4,
      "grad_norm": 3.6890079975128174,
      "learning_rate": 1.5712e-05,
      "loss": 1.1572,
      "step": 5360
    },
    {
      "epoch": 214.8,
      "grad_norm": 4.230496883392334,
      "learning_rate": 1.5704e-05,
      "loss": 1.1514,
      "step": 5370
    },
    {
      "epoch": 215.2,
      "grad_norm": 4.9860734939575195,
      "learning_rate": 1.5696000000000004e-05,
      "loss": 1.2001,
      "step": 5380
    },
    {
      "epoch": 215.6,
      "grad_norm": 3.7120258808135986,
      "learning_rate": 1.5688e-05,
      "loss": 1.1549,
      "step": 5390
    },
    {
      "epoch": 216.0,
      "grad_norm": 3.471020460128784,
      "learning_rate": 1.5680000000000002e-05,
      "loss": 1.1464,
      "step": 5400
    },
    {
      "epoch": 216.4,
      "grad_norm": 3.8327789306640625,
      "learning_rate": 1.5672000000000002e-05,
      "loss": 1.1843,
      "step": 5410
    },
    {
      "epoch": 216.8,
      "grad_norm": 4.880294322967529,
      "learning_rate": 1.5664e-05,
      "loss": 1.1317,
      "step": 5420
    },
    {
      "epoch": 217.2,
      "grad_norm": 3.475147247314453,
      "learning_rate": 1.5656000000000004e-05,
      "loss": 1.1364,
      "step": 5430
    },
    {
      "epoch": 217.6,
      "grad_norm": 4.981505870819092,
      "learning_rate": 1.5648e-05,
      "loss": 1.1853,
      "step": 5440
    },
    {
      "epoch": 218.0,
      "grad_norm": 3.2783100605010986,
      "learning_rate": 1.5640000000000003e-05,
      "loss": 1.1405,
      "step": 5450
    },
    {
      "epoch": 218.4,
      "grad_norm": 3.675293207168579,
      "learning_rate": 1.5632000000000002e-05,
      "loss": 1.1553,
      "step": 5460
    },
    {
      "epoch": 218.8,
      "grad_norm": 3.5935189723968506,
      "learning_rate": 1.5624e-05,
      "loss": 1.1475,
      "step": 5470
    },
    {
      "epoch": 219.2,
      "grad_norm": 3.302262544631958,
      "learning_rate": 1.5616e-05,
      "loss": 1.173,
      "step": 5480
    },
    {
      "epoch": 219.6,
      "grad_norm": 6.409991264343262,
      "learning_rate": 1.5608e-05,
      "loss": 1.168,
      "step": 5490
    },
    {
      "epoch": 220.0,
      "grad_norm": 5.067116737365723,
      "learning_rate": 1.5600000000000003e-05,
      "loss": 1.1469,
      "step": 5500
    },
    {
      "epoch": 220.4,
      "grad_norm": 3.7640459537506104,
      "learning_rate": 1.5592e-05,
      "loss": 1.1241,
      "step": 5510
    },
    {
      "epoch": 220.8,
      "grad_norm": 6.180155277252197,
      "learning_rate": 1.5584000000000002e-05,
      "loss": 1.1714,
      "step": 5520
    },
    {
      "epoch": 221.2,
      "grad_norm": 5.499504089355469,
      "learning_rate": 1.5576e-05,
      "loss": 1.1327,
      "step": 5530
    },
    {
      "epoch": 221.6,
      "grad_norm": 2.7839300632476807,
      "learning_rate": 1.5568e-05,
      "loss": 1.1425,
      "step": 5540
    },
    {
      "epoch": 222.0,
      "grad_norm": 4.208678245544434,
      "learning_rate": 1.556e-05,
      "loss": 1.1706,
      "step": 5550
    },
    {
      "epoch": 222.4,
      "grad_norm": 5.8021087646484375,
      "learning_rate": 1.5552e-05,
      "loss": 1.1619,
      "step": 5560
    },
    {
      "epoch": 222.8,
      "grad_norm": 3.465561866760254,
      "learning_rate": 1.5544000000000002e-05,
      "loss": 1.1583,
      "step": 5570
    },
    {
      "epoch": 223.2,
      "grad_norm": 4.565671920776367,
      "learning_rate": 1.5536e-05,
      "loss": 1.128,
      "step": 5580
    },
    {
      "epoch": 223.6,
      "grad_norm": 4.371865749359131,
      "learning_rate": 1.5528e-05,
      "loss": 1.1142,
      "step": 5590
    },
    {
      "epoch": 224.0,
      "grad_norm": 3.5478854179382324,
      "learning_rate": 1.552e-05,
      "loss": 1.1638,
      "step": 5600
    },
    {
      "epoch": 224.4,
      "grad_norm": 3.861794948577881,
      "learning_rate": 1.5512e-05,
      "loss": 1.1313,
      "step": 5610
    },
    {
      "epoch": 224.8,
      "grad_norm": 3.462892770767212,
      "learning_rate": 1.5504000000000003e-05,
      "loss": 1.1317,
      "step": 5620
    },
    {
      "epoch": 225.2,
      "grad_norm": 3.7501306533813477,
      "learning_rate": 1.5496000000000002e-05,
      "loss": 1.1575,
      "step": 5630
    },
    {
      "epoch": 225.6,
      "grad_norm": 5.015167713165283,
      "learning_rate": 1.5488e-05,
      "loss": 1.1447,
      "step": 5640
    },
    {
      "epoch": 226.0,
      "grad_norm": 2.855729341506958,
      "learning_rate": 1.548e-05,
      "loss": 1.1599,
      "step": 5650
    },
    {
      "epoch": 226.4,
      "grad_norm": 6.9809112548828125,
      "learning_rate": 1.5472e-05,
      "loss": 1.1685,
      "step": 5660
    },
    {
      "epoch": 226.8,
      "grad_norm": 2.646444320678711,
      "learning_rate": 1.5464e-05,
      "loss": 1.1262,
      "step": 5670
    },
    {
      "epoch": 227.2,
      "grad_norm": 2.7134153842926025,
      "learning_rate": 1.5456000000000002e-05,
      "loss": 1.1281,
      "step": 5680
    },
    {
      "epoch": 227.6,
      "grad_norm": 5.4225382804870605,
      "learning_rate": 1.5448000000000002e-05,
      "loss": 1.1442,
      "step": 5690
    },
    {
      "epoch": 228.0,
      "grad_norm": 5.565636157989502,
      "learning_rate": 1.544e-05,
      "loss": 1.1365,
      "step": 5700
    },
    {
      "epoch": 228.4,
      "grad_norm": 6.194066047668457,
      "learning_rate": 1.5432e-05,
      "loss": 1.1568,
      "step": 5710
    },
    {
      "epoch": 228.8,
      "grad_norm": 6.435213565826416,
      "learning_rate": 1.5424e-05,
      "loss": 1.1268,
      "step": 5720
    },
    {
      "epoch": 229.2,
      "grad_norm": 6.045165538787842,
      "learning_rate": 1.5416000000000003e-05,
      "loss": 1.1209,
      "step": 5730
    },
    {
      "epoch": 229.6,
      "grad_norm": 6.31278133392334,
      "learning_rate": 1.5408000000000002e-05,
      "loss": 1.1372,
      "step": 5740
    },
    {
      "epoch": 230.0,
      "grad_norm": 3.0141372680664062,
      "learning_rate": 1.54e-05,
      "loss": 1.1368,
      "step": 5750
    },
    {
      "epoch": 230.4,
      "grad_norm": 3.410552740097046,
      "learning_rate": 1.5392e-05,
      "loss": 1.156,
      "step": 5760
    },
    {
      "epoch": 230.8,
      "grad_norm": 5.328139781951904,
      "learning_rate": 1.5384e-05,
      "loss": 1.1132,
      "step": 5770
    },
    {
      "epoch": 231.2,
      "grad_norm": 5.360978603363037,
      "learning_rate": 1.5376000000000003e-05,
      "loss": 1.1545,
      "step": 5780
    },
    {
      "epoch": 231.6,
      "grad_norm": 2.8058478832244873,
      "learning_rate": 1.5368e-05,
      "loss": 1.1449,
      "step": 5790
    },
    {
      "epoch": 232.0,
      "grad_norm": 3.714484930038452,
      "learning_rate": 1.5360000000000002e-05,
      "loss": 1.1274,
      "step": 5800
    },
    {
      "epoch": 232.4,
      "grad_norm": 4.370909214019775,
      "learning_rate": 1.5352e-05,
      "loss": 1.137,
      "step": 5810
    },
    {
      "epoch": 232.8,
      "grad_norm": 4.809756755828857,
      "learning_rate": 1.5344e-05,
      "loss": 1.1292,
      "step": 5820
    },
    {
      "epoch": 233.2,
      "grad_norm": 5.680890083312988,
      "learning_rate": 1.5336000000000004e-05,
      "loss": 1.1713,
      "step": 5830
    },
    {
      "epoch": 233.6,
      "grad_norm": 4.498038291931152,
      "learning_rate": 1.5328e-05,
      "loss": 1.1527,
      "step": 5840
    },
    {
      "epoch": 234.0,
      "grad_norm": 5.654555320739746,
      "learning_rate": 1.5320000000000002e-05,
      "loss": 1.1231,
      "step": 5850
    },
    {
      "epoch": 234.4,
      "grad_norm": 3.187028408050537,
      "learning_rate": 1.5312000000000002e-05,
      "loss": 1.1135,
      "step": 5860
    },
    {
      "epoch": 234.8,
      "grad_norm": 4.679435729980469,
      "learning_rate": 1.5304e-05,
      "loss": 1.1325,
      "step": 5870
    },
    {
      "epoch": 235.2,
      "grad_norm": 4.592417240142822,
      "learning_rate": 1.5296e-05,
      "loss": 1.1626,
      "step": 5880
    },
    {
      "epoch": 235.6,
      "grad_norm": 6.336001396179199,
      "learning_rate": 1.5288e-05,
      "loss": 1.1104,
      "step": 5890
    },
    {
      "epoch": 236.0,
      "grad_norm": 4.7614030838012695,
      "learning_rate": 1.5280000000000003e-05,
      "loss": 1.1204,
      "step": 5900
    },
    {
      "epoch": 236.4,
      "grad_norm": 5.626911640167236,
      "learning_rate": 1.5272e-05,
      "loss": 1.1231,
      "step": 5910
    },
    {
      "epoch": 236.8,
      "grad_norm": 3.619290828704834,
      "learning_rate": 1.5264e-05,
      "loss": 1.1192,
      "step": 5920
    },
    {
      "epoch": 237.2,
      "grad_norm": 4.9034576416015625,
      "learning_rate": 1.5256000000000003e-05,
      "loss": 1.151,
      "step": 5930
    },
    {
      "epoch": 237.6,
      "grad_norm": 3.017618179321289,
      "learning_rate": 1.5248e-05,
      "loss": 1.1214,
      "step": 5940
    },
    {
      "epoch": 238.0,
      "grad_norm": 4.821639060974121,
      "learning_rate": 1.5240000000000001e-05,
      "loss": 1.1325,
      "step": 5950
    },
    {
      "epoch": 238.4,
      "grad_norm": 3.789588689804077,
      "learning_rate": 1.5232000000000003e-05,
      "loss": 1.106,
      "step": 5960
    },
    {
      "epoch": 238.8,
      "grad_norm": 4.067503929138184,
      "learning_rate": 1.5224e-05,
      "loss": 1.1361,
      "step": 5970
    },
    {
      "epoch": 239.2,
      "grad_norm": 4.00546407699585,
      "learning_rate": 1.5216000000000001e-05,
      "loss": 1.1114,
      "step": 5980
    },
    {
      "epoch": 239.6,
      "grad_norm": 3.021939754486084,
      "learning_rate": 1.5208e-05,
      "loss": 1.1481,
      "step": 5990
    },
    {
      "epoch": 240.0,
      "grad_norm": 4.027541160583496,
      "learning_rate": 1.5200000000000002e-05,
      "loss": 1.1029,
      "step": 6000
    },
    {
      "epoch": 240.4,
      "grad_norm": 3.853656530380249,
      "learning_rate": 1.5192000000000003e-05,
      "loss": 1.1266,
      "step": 6010
    },
    {
      "epoch": 240.8,
      "grad_norm": 3.0087997913360596,
      "learning_rate": 1.5184e-05,
      "loss": 1.1023,
      "step": 6020
    },
    {
      "epoch": 241.2,
      "grad_norm": 3.367767810821533,
      "learning_rate": 1.5176000000000002e-05,
      "loss": 1.1313,
      "step": 6030
    },
    {
      "epoch": 241.6,
      "grad_norm": 5.875168323516846,
      "learning_rate": 1.5168000000000001e-05,
      "loss": 1.1292,
      "step": 6040
    },
    {
      "epoch": 242.0,
      "grad_norm": 4.287041187286377,
      "learning_rate": 1.516e-05,
      "loss": 1.1,
      "step": 6050
    },
    {
      "epoch": 242.4,
      "grad_norm": 3.5270864963531494,
      "learning_rate": 1.5152000000000002e-05,
      "loss": 1.1063,
      "step": 6060
    },
    {
      "epoch": 242.8,
      "grad_norm": 3.914762258529663,
      "learning_rate": 1.5144000000000001e-05,
      "loss": 1.1213,
      "step": 6070
    },
    {
      "epoch": 243.2,
      "grad_norm": 3.787177801132202,
      "learning_rate": 1.5136000000000002e-05,
      "loss": 1.1428,
      "step": 6080
    },
    {
      "epoch": 243.6,
      "grad_norm": 4.965367794036865,
      "learning_rate": 1.5128e-05,
      "loss": 1.0911,
      "step": 6090
    },
    {
      "epoch": 244.0,
      "grad_norm": 3.0485568046569824,
      "learning_rate": 1.5120000000000001e-05,
      "loss": 1.1232,
      "step": 6100
    },
    {
      "epoch": 244.4,
      "grad_norm": 2.727792978286743,
      "learning_rate": 1.5112000000000002e-05,
      "loss": 1.1199,
      "step": 6110
    },
    {
      "epoch": 244.8,
      "grad_norm": 9.0009765625,
      "learning_rate": 1.5104000000000001e-05,
      "loss": 1.1466,
      "step": 6120
    },
    {
      "epoch": 245.2,
      "grad_norm": 4.933292388916016,
      "learning_rate": 1.5096000000000003e-05,
      "loss": 1.0781,
      "step": 6130
    },
    {
      "epoch": 245.6,
      "grad_norm": 6.512823104858398,
      "learning_rate": 1.5088e-05,
      "loss": 1.1203,
      "step": 6140
    },
    {
      "epoch": 246.0,
      "grad_norm": 3.3620989322662354,
      "learning_rate": 1.5080000000000001e-05,
      "loss": 1.13,
      "step": 6150
    },
    {
      "epoch": 246.4,
      "grad_norm": 6.503533840179443,
      "learning_rate": 1.5072000000000002e-05,
      "loss": 1.1445,
      "step": 6160
    },
    {
      "epoch": 246.8,
      "grad_norm": 4.122264385223389,
      "learning_rate": 1.5064e-05,
      "loss": 1.0961,
      "step": 6170
    },
    {
      "epoch": 247.2,
      "grad_norm": 4.7147345542907715,
      "learning_rate": 1.5056000000000001e-05,
      "loss": 1.1271,
      "step": 6180
    },
    {
      "epoch": 247.6,
      "grad_norm": 5.299396991729736,
      "learning_rate": 1.5048e-05,
      "loss": 1.1206,
      "step": 6190
    },
    {
      "epoch": 248.0,
      "grad_norm": 3.5736136436462402,
      "learning_rate": 1.5040000000000002e-05,
      "loss": 1.1137,
      "step": 6200
    },
    {
      "epoch": 248.4,
      "grad_norm": 5.111923694610596,
      "learning_rate": 1.5032000000000003e-05,
      "loss": 1.1095,
      "step": 6210
    },
    {
      "epoch": 248.8,
      "grad_norm": 6.165798664093018,
      "learning_rate": 1.5024e-05,
      "loss": 1.1073,
      "step": 6220
    },
    {
      "epoch": 249.2,
      "grad_norm": 4.336436748504639,
      "learning_rate": 1.5016000000000002e-05,
      "loss": 1.132,
      "step": 6230
    },
    {
      "epoch": 249.6,
      "grad_norm": 4.284183025360107,
      "learning_rate": 1.5008000000000001e-05,
      "loss": 1.1186,
      "step": 6240
    },
    {
      "epoch": 250.0,
      "grad_norm": 6.6822733879089355,
      "learning_rate": 1.5000000000000002e-05,
      "loss": 1.1042,
      "step": 6250
    },
    {
      "epoch": 250.4,
      "grad_norm": 3.2690634727478027,
      "learning_rate": 1.4992000000000001e-05,
      "loss": 1.1062,
      "step": 6260
    },
    {
      "epoch": 250.8,
      "grad_norm": 3.3071634769439697,
      "learning_rate": 1.4984000000000001e-05,
      "loss": 1.0979,
      "step": 6270
    },
    {
      "epoch": 251.2,
      "grad_norm": 7.112551689147949,
      "learning_rate": 1.4976000000000002e-05,
      "loss": 1.1096,
      "step": 6280
    },
    {
      "epoch": 251.6,
      "grad_norm": 3.9037532806396484,
      "learning_rate": 1.4968e-05,
      "loss": 1.1002,
      "step": 6290
    },
    {
      "epoch": 252.0,
      "grad_norm": 5.0093255043029785,
      "learning_rate": 1.496e-05,
      "loss": 1.1091,
      "step": 6300
    },
    {
      "epoch": 252.4,
      "grad_norm": 3.165862798690796,
      "learning_rate": 1.4952000000000002e-05,
      "loss": 1.0746,
      "step": 6310
    },
    {
      "epoch": 252.8,
      "grad_norm": 3.032912492752075,
      "learning_rate": 1.4944000000000001e-05,
      "loss": 1.1498,
      "step": 6320
    },
    {
      "epoch": 253.2,
      "grad_norm": 3.5386924743652344,
      "learning_rate": 1.4936000000000002e-05,
      "loss": 1.0968,
      "step": 6330
    },
    {
      "epoch": 253.6,
      "grad_norm": 3.1394460201263428,
      "learning_rate": 1.4928e-05,
      "loss": 1.1006,
      "step": 6340
    },
    {
      "epoch": 254.0,
      "grad_norm": 8.024092674255371,
      "learning_rate": 1.4920000000000001e-05,
      "loss": 1.1011,
      "step": 6350
    },
    {
      "epoch": 254.4,
      "grad_norm": 3.425123453140259,
      "learning_rate": 1.4912000000000002e-05,
      "loss": 1.0729,
      "step": 6360
    },
    {
      "epoch": 254.8,
      "grad_norm": 5.912727355957031,
      "learning_rate": 1.4904e-05,
      "loss": 1.1216,
      "step": 6370
    },
    {
      "epoch": 255.2,
      "grad_norm": 3.0509235858917236,
      "learning_rate": 1.4896000000000001e-05,
      "loss": 1.0967,
      "step": 6380
    },
    {
      "epoch": 255.6,
      "grad_norm": 8.078153610229492,
      "learning_rate": 1.4888e-05,
      "loss": 1.0951,
      "step": 6390
    },
    {
      "epoch": 256.0,
      "grad_norm": 4.720639228820801,
      "learning_rate": 1.4880000000000002e-05,
      "loss": 1.0781,
      "step": 6400
    },
    {
      "epoch": 256.4,
      "grad_norm": 3.839292287826538,
      "learning_rate": 1.4872000000000003e-05,
      "loss": 1.0859,
      "step": 6410
    },
    {
      "epoch": 256.8,
      "grad_norm": 6.224001884460449,
      "learning_rate": 1.4864e-05,
      "loss": 1.0861,
      "step": 6420
    },
    {
      "epoch": 257.2,
      "grad_norm": 4.505810260772705,
      "learning_rate": 1.4856000000000001e-05,
      "loss": 1.1092,
      "step": 6430
    },
    {
      "epoch": 257.6,
      "grad_norm": 2.7018070220947266,
      "learning_rate": 1.4848e-05,
      "loss": 1.1007,
      "step": 6440
    },
    {
      "epoch": 258.0,
      "grad_norm": 11.031091690063477,
      "learning_rate": 1.4840000000000002e-05,
      "loss": 1.1021,
      "step": 6450
    },
    {
      "epoch": 258.4,
      "grad_norm": 3.3717737197875977,
      "learning_rate": 1.4832000000000001e-05,
      "loss": 1.0931,
      "step": 6460
    },
    {
      "epoch": 258.8,
      "grad_norm": 4.243931293487549,
      "learning_rate": 1.4824e-05,
      "loss": 1.1056,
      "step": 6470
    },
    {
      "epoch": 259.2,
      "grad_norm": 4.973378658294678,
      "learning_rate": 1.4816000000000002e-05,
      "loss": 1.0884,
      "step": 6480
    },
    {
      "epoch": 259.6,
      "grad_norm": 4.182610511779785,
      "learning_rate": 1.4808e-05,
      "loss": 1.1237,
      "step": 6490
    },
    {
      "epoch": 260.0,
      "grad_norm": 3.414069652557373,
      "learning_rate": 1.48e-05,
      "loss": 1.0716,
      "step": 6500
    },
    {
      "epoch": 260.4,
      "grad_norm": 6.494718551635742,
      "learning_rate": 1.4792000000000002e-05,
      "loss": 1.0757,
      "step": 6510
    },
    {
      "epoch": 260.8,
      "grad_norm": 4.820211410522461,
      "learning_rate": 1.4784000000000001e-05,
      "loss": 1.1053,
      "step": 6520
    },
    {
      "epoch": 261.2,
      "grad_norm": 5.095919609069824,
      "learning_rate": 1.4776000000000002e-05,
      "loss": 1.1138,
      "step": 6530
    },
    {
      "epoch": 261.6,
      "grad_norm": 3.2279255390167236,
      "learning_rate": 1.4768e-05,
      "loss": 1.0662,
      "step": 6540
    },
    {
      "epoch": 262.0,
      "grad_norm": 3.6709675788879395,
      "learning_rate": 1.4760000000000001e-05,
      "loss": 1.1055,
      "step": 6550
    },
    {
      "epoch": 262.4,
      "grad_norm": 3.502267599105835,
      "learning_rate": 1.4752000000000002e-05,
      "loss": 1.0771,
      "step": 6560
    },
    {
      "epoch": 262.8,
      "grad_norm": 4.9922871589660645,
      "learning_rate": 1.4744e-05,
      "loss": 1.091,
      "step": 6570
    },
    {
      "epoch": 263.2,
      "grad_norm": 4.896313190460205,
      "learning_rate": 1.4736000000000001e-05,
      "loss": 1.1007,
      "step": 6580
    },
    {
      "epoch": 263.6,
      "grad_norm": 2.7195944786071777,
      "learning_rate": 1.4728000000000002e-05,
      "loss": 1.0655,
      "step": 6590
    },
    {
      "epoch": 264.0,
      "grad_norm": 5.291210174560547,
      "learning_rate": 1.4720000000000001e-05,
      "loss": 1.0966,
      "step": 6600
    },
    {
      "epoch": 264.4,
      "grad_norm": 5.446598529815674,
      "learning_rate": 1.4712000000000002e-05,
      "loss": 1.1004,
      "step": 6610
    },
    {
      "epoch": 264.8,
      "grad_norm": 4.6590256690979,
      "learning_rate": 1.4704e-05,
      "loss": 1.0645,
      "step": 6620
    },
    {
      "epoch": 265.2,
      "grad_norm": 3.6458334922790527,
      "learning_rate": 1.4696000000000001e-05,
      "loss": 1.0691,
      "step": 6630
    },
    {
      "epoch": 265.6,
      "grad_norm": 4.4431657791137695,
      "learning_rate": 1.4688000000000002e-05,
      "loss": 1.0699,
      "step": 6640
    },
    {
      "epoch": 266.0,
      "grad_norm": 3.281512498855591,
      "learning_rate": 1.4680000000000002e-05,
      "loss": 1.1011,
      "step": 6650
    },
    {
      "epoch": 266.4,
      "grad_norm": 4.7010650634765625,
      "learning_rate": 1.4672000000000001e-05,
      "loss": 1.0787,
      "step": 6660
    },
    {
      "epoch": 266.8,
      "grad_norm": 5.03145170211792,
      "learning_rate": 1.4664e-05,
      "loss": 1.0774,
      "step": 6670
    },
    {
      "epoch": 267.2,
      "grad_norm": 6.0307135581970215,
      "learning_rate": 1.4656000000000002e-05,
      "loss": 1.0877,
      "step": 6680
    },
    {
      "epoch": 267.6,
      "grad_norm": 4.531650066375732,
      "learning_rate": 1.4648000000000003e-05,
      "loss": 1.0904,
      "step": 6690
    },
    {
      "epoch": 268.0,
      "grad_norm": 3.0391526222229004,
      "learning_rate": 1.464e-05,
      "loss": 1.0752,
      "step": 6700
    },
    {
      "epoch": 268.4,
      "grad_norm": 3.0622665882110596,
      "learning_rate": 1.4632000000000002e-05,
      "loss": 1.0632,
      "step": 6710
    },
    {
      "epoch": 268.8,
      "grad_norm": 3.887911319732666,
      "learning_rate": 1.4624000000000001e-05,
      "loss": 1.0839,
      "step": 6720
    },
    {
      "epoch": 269.2,
      "grad_norm": 4.123936653137207,
      "learning_rate": 1.4616000000000002e-05,
      "loss": 1.0764,
      "step": 6730
    },
    {
      "epoch": 269.6,
      "grad_norm": 3.428223133087158,
      "learning_rate": 1.4608000000000001e-05,
      "loss": 1.0936,
      "step": 6740
    },
    {
      "epoch": 270.0,
      "grad_norm": 4.621819019317627,
      "learning_rate": 1.46e-05,
      "loss": 1.0714,
      "step": 6750
    },
    {
      "epoch": 270.4,
      "grad_norm": 5.3104777336120605,
      "learning_rate": 1.4592000000000002e-05,
      "loss": 1.0944,
      "step": 6760
    },
    {
      "epoch": 270.8,
      "grad_norm": 5.390864849090576,
      "learning_rate": 1.4584e-05,
      "loss": 1.0848,
      "step": 6770
    },
    {
      "epoch": 271.2,
      "grad_norm": 2.796814203262329,
      "learning_rate": 1.4576e-05,
      "loss": 1.0655,
      "step": 6780
    },
    {
      "epoch": 271.6,
      "grad_norm": 4.8814826011657715,
      "learning_rate": 1.4568000000000002e-05,
      "loss": 1.0816,
      "step": 6790
    },
    {
      "epoch": 272.0,
      "grad_norm": 3.8121187686920166,
      "learning_rate": 1.4560000000000001e-05,
      "loss": 1.0783,
      "step": 6800
    },
    {
      "epoch": 272.4,
      "grad_norm": 2.501723289489746,
      "learning_rate": 1.4552000000000002e-05,
      "loss": 1.0828,
      "step": 6810
    },
    {
      "epoch": 272.8,
      "grad_norm": 4.35167121887207,
      "learning_rate": 1.4544e-05,
      "loss": 1.0807,
      "step": 6820
    },
    {
      "epoch": 273.2,
      "grad_norm": 2.7801201343536377,
      "learning_rate": 1.4536000000000001e-05,
      "loss": 1.0553,
      "step": 6830
    },
    {
      "epoch": 273.6,
      "grad_norm": 6.018445014953613,
      "learning_rate": 1.4528000000000002e-05,
      "loss": 1.0626,
      "step": 6840
    },
    {
      "epoch": 274.0,
      "grad_norm": 3.3419792652130127,
      "learning_rate": 1.4520000000000002e-05,
      "loss": 1.0817,
      "step": 6850
    },
    {
      "epoch": 274.4,
      "grad_norm": 3.9936623573303223,
      "learning_rate": 1.4512000000000001e-05,
      "loss": 1.0626,
      "step": 6860
    },
    {
      "epoch": 274.8,
      "grad_norm": 3.8736789226531982,
      "learning_rate": 1.4504e-05,
      "loss": 1.0468,
      "step": 6870
    },
    {
      "epoch": 275.2,
      "grad_norm": 4.813769340515137,
      "learning_rate": 1.4496000000000001e-05,
      "loss": 1.1166,
      "step": 6880
    },
    {
      "epoch": 275.6,
      "grad_norm": 4.549986362457275,
      "learning_rate": 1.4488000000000003e-05,
      "loss": 1.0672,
      "step": 6890
    },
    {
      "epoch": 276.0,
      "grad_norm": 7.807341575622559,
      "learning_rate": 1.448e-05,
      "loss": 1.0801,
      "step": 6900
    },
    {
      "epoch": 276.4,
      "grad_norm": 3.0063316822052,
      "learning_rate": 1.4472000000000001e-05,
      "loss": 1.0544,
      "step": 6910
    },
    {
      "epoch": 276.8,
      "grad_norm": 4.874949932098389,
      "learning_rate": 1.4464e-05,
      "loss": 1.0602,
      "step": 6920
    },
    {
      "epoch": 277.2,
      "grad_norm": 4.121153354644775,
      "learning_rate": 1.4456000000000002e-05,
      "loss": 1.0651,
      "step": 6930
    },
    {
      "epoch": 277.6,
      "grad_norm": 5.508481025695801,
      "learning_rate": 1.4448000000000001e-05,
      "loss": 1.0783,
      "step": 6940
    },
    {
      "epoch": 278.0,
      "grad_norm": 3.3276896476745605,
      "learning_rate": 1.444e-05,
      "loss": 1.0816,
      "step": 6950
    },
    {
      "epoch": 278.4,
      "grad_norm": 7.067427635192871,
      "learning_rate": 1.4432000000000002e-05,
      "loss": 1.0575,
      "step": 6960
    },
    {
      "epoch": 278.8,
      "grad_norm": 6.098563194274902,
      "learning_rate": 1.4424e-05,
      "loss": 1.0844,
      "step": 6970
    },
    {
      "epoch": 279.2,
      "grad_norm": 6.125304698944092,
      "learning_rate": 1.4416e-05,
      "loss": 1.0402,
      "step": 6980
    },
    {
      "epoch": 279.6,
      "grad_norm": 9.077502250671387,
      "learning_rate": 1.4408000000000002e-05,
      "loss": 1.0656,
      "step": 6990
    },
    {
      "epoch": 280.0,
      "grad_norm": 3.9973621368408203,
      "learning_rate": 1.4400000000000001e-05,
      "loss": 1.0859,
      "step": 7000
    },
    {
      "epoch": 280.4,
      "grad_norm": 4.767369270324707,
      "learning_rate": 1.4392000000000002e-05,
      "loss": 1.0641,
      "step": 7010
    },
    {
      "epoch": 280.8,
      "grad_norm": 2.811282157897949,
      "learning_rate": 1.4384e-05,
      "loss": 1.071,
      "step": 7020
    },
    {
      "epoch": 281.2,
      "grad_norm": 3.2058279514312744,
      "learning_rate": 1.4376000000000001e-05,
      "loss": 1.0648,
      "step": 7030
    },
    {
      "epoch": 281.6,
      "grad_norm": 3.8984975814819336,
      "learning_rate": 1.4368000000000002e-05,
      "loss": 1.0664,
      "step": 7040
    },
    {
      "epoch": 282.0,
      "grad_norm": 3.317208766937256,
      "learning_rate": 1.4360000000000001e-05,
      "loss": 1.0717,
      "step": 7050
    },
    {
      "epoch": 282.4,
      "grad_norm": 5.763248443603516,
      "learning_rate": 1.4352e-05,
      "loss": 1.0563,
      "step": 7060
    },
    {
      "epoch": 282.8,
      "grad_norm": 7.021568298339844,
      "learning_rate": 1.4344e-05,
      "loss": 1.0757,
      "step": 7070
    },
    {
      "epoch": 283.2,
      "grad_norm": 3.0968737602233887,
      "learning_rate": 1.4336000000000001e-05,
      "loss": 1.0452,
      "step": 7080
    },
    {
      "epoch": 283.6,
      "grad_norm": 3.780776023864746,
      "learning_rate": 1.4328000000000002e-05,
      "loss": 1.0781,
      "step": 7090
    },
    {
      "epoch": 284.0,
      "grad_norm": 2.680917263031006,
      "learning_rate": 1.432e-05,
      "loss": 1.0764,
      "step": 7100
    },
    {
      "epoch": 284.4,
      "grad_norm": 8.68928050994873,
      "learning_rate": 1.4312000000000001e-05,
      "loss": 1.0641,
      "step": 7110
    },
    {
      "epoch": 284.8,
      "grad_norm": 6.783241271972656,
      "learning_rate": 1.4304e-05,
      "loss": 1.0517,
      "step": 7120
    },
    {
      "epoch": 285.2,
      "grad_norm": 5.873973846435547,
      "learning_rate": 1.4296000000000002e-05,
      "loss": 1.0526,
      "step": 7130
    },
    {
      "epoch": 285.6,
      "grad_norm": 4.948981285095215,
      "learning_rate": 1.4288000000000001e-05,
      "loss": 1.0907,
      "step": 7140
    },
    {
      "epoch": 286.0,
      "grad_norm": 10.451056480407715,
      "learning_rate": 1.428e-05,
      "loss": 1.0601,
      "step": 7150
    },
    {
      "epoch": 286.4,
      "grad_norm": 3.4923195838928223,
      "learning_rate": 1.4272000000000002e-05,
      "loss": 1.0696,
      "step": 7160
    },
    {
      "epoch": 286.8,
      "grad_norm": 4.445733070373535,
      "learning_rate": 1.4264e-05,
      "loss": 1.0493,
      "step": 7170
    },
    {
      "epoch": 287.2,
      "grad_norm": 5.317190170288086,
      "learning_rate": 1.4256e-05,
      "loss": 1.0735,
      "step": 7180
    },
    {
      "epoch": 287.6,
      "grad_norm": 4.821159839630127,
      "learning_rate": 1.4248000000000001e-05,
      "loss": 1.0473,
      "step": 7190
    },
    {
      "epoch": 288.0,
      "grad_norm": 3.602736711502075,
      "learning_rate": 1.4240000000000001e-05,
      "loss": 1.0661,
      "step": 7200
    },
    {
      "epoch": 288.4,
      "grad_norm": 5.097821235656738,
      "learning_rate": 1.4232000000000002e-05,
      "loss": 1.0689,
      "step": 7210
    },
    {
      "epoch": 288.8,
      "grad_norm": 2.7205190658569336,
      "learning_rate": 1.4224000000000003e-05,
      "loss": 1.0702,
      "step": 7220
    },
    {
      "epoch": 289.2,
      "grad_norm": 6.850016117095947,
      "learning_rate": 1.4216e-05,
      "loss": 1.02,
      "step": 7230
    },
    {
      "epoch": 289.6,
      "grad_norm": 4.025462627410889,
      "learning_rate": 1.4208000000000002e-05,
      "loss": 1.082,
      "step": 7240
    },
    {
      "epoch": 290.0,
      "grad_norm": 6.640204906463623,
      "learning_rate": 1.4200000000000001e-05,
      "loss": 1.0261,
      "step": 7250
    },
    {
      "epoch": 290.4,
      "grad_norm": 7.27932596206665,
      "learning_rate": 1.4192e-05,
      "loss": 1.0467,
      "step": 7260
    },
    {
      "epoch": 290.8,
      "grad_norm": 5.866766929626465,
      "learning_rate": 1.4184000000000002e-05,
      "loss": 1.0749,
      "step": 7270
    },
    {
      "epoch": 291.2,
      "grad_norm": 7.025369644165039,
      "learning_rate": 1.4176000000000001e-05,
      "loss": 1.0493,
      "step": 7280
    },
    {
      "epoch": 291.6,
      "grad_norm": 5.046145915985107,
      "learning_rate": 1.4168000000000002e-05,
      "loss": 1.0175,
      "step": 7290
    },
    {
      "epoch": 292.0,
      "grad_norm": 4.629655361175537,
      "learning_rate": 1.416e-05,
      "loss": 1.0754,
      "step": 7300
    },
    {
      "epoch": 292.4,
      "grad_norm": 4.5098466873168945,
      "learning_rate": 1.4152000000000001e-05,
      "loss": 1.0565,
      "step": 7310
    },
    {
      "epoch": 292.8,
      "grad_norm": 10.573010444641113,
      "learning_rate": 1.4144000000000002e-05,
      "loss": 1.0548,
      "step": 7320
    },
    {
      "epoch": 293.2,
      "grad_norm": 7.245541095733643,
      "learning_rate": 1.4136000000000002e-05,
      "loss": 1.0682,
      "step": 7330
    },
    {
      "epoch": 293.6,
      "grad_norm": 5.396610736846924,
      "learning_rate": 1.4128000000000001e-05,
      "loss": 1.0471,
      "step": 7340
    },
    {
      "epoch": 294.0,
      "grad_norm": 8.009990692138672,
      "learning_rate": 1.412e-05,
      "loss": 1.0478,
      "step": 7350
    },
    {
      "epoch": 294.4,
      "grad_norm": 6.098363876342773,
      "learning_rate": 1.4112000000000001e-05,
      "loss": 1.0559,
      "step": 7360
    },
    {
      "epoch": 294.8,
      "grad_norm": 6.186532497406006,
      "learning_rate": 1.4104000000000003e-05,
      "loss": 1.0431,
      "step": 7370
    },
    {
      "epoch": 295.2,
      "grad_norm": 3.9488840103149414,
      "learning_rate": 1.4096e-05,
      "loss": 1.0424,
      "step": 7380
    },
    {
      "epoch": 295.6,
      "grad_norm": 4.431213855743408,
      "learning_rate": 1.4088000000000001e-05,
      "loss": 1.0351,
      "step": 7390
    },
    {
      "epoch": 296.0,
      "grad_norm": 12.162628173828125,
      "learning_rate": 1.408e-05,
      "loss": 1.0322,
      "step": 7400
    },
    {
      "epoch": 296.4,
      "grad_norm": 4.786746978759766,
      "learning_rate": 1.4072000000000002e-05,
      "loss": 1.0266,
      "step": 7410
    },
    {
      "epoch": 296.8,
      "grad_norm": 6.825387001037598,
      "learning_rate": 1.4064000000000003e-05,
      "loss": 1.0362,
      "step": 7420
    },
    {
      "epoch": 297.2,
      "grad_norm": 3.412461519241333,
      "learning_rate": 1.4056e-05,
      "loss": 1.0682,
      "step": 7430
    },
    {
      "epoch": 297.6,
      "grad_norm": 5.030065536499023,
      "learning_rate": 1.4048000000000002e-05,
      "loss": 1.0483,
      "step": 7440
    },
    {
      "epoch": 298.0,
      "grad_norm": 3.26629376411438,
      "learning_rate": 1.4040000000000001e-05,
      "loss": 1.043,
      "step": 7450
    },
    {
      "epoch": 298.4,
      "grad_norm": 6.651511192321777,
      "learning_rate": 1.4032e-05,
      "loss": 1.0149,
      "step": 7460
    },
    {
      "epoch": 298.8,
      "grad_norm": 5.411706924438477,
      "learning_rate": 1.4024000000000002e-05,
      "loss": 1.0985,
      "step": 7470
    },
    {
      "epoch": 299.2,
      "grad_norm": 4.402095317840576,
      "learning_rate": 1.4016000000000001e-05,
      "loss": 1.0502,
      "step": 7480
    },
    {
      "epoch": 299.6,
      "grad_norm": 6.466428279876709,
      "learning_rate": 1.4008000000000002e-05,
      "loss": 1.0512,
      "step": 7490
    },
    {
      "epoch": 300.0,
      "grad_norm": 3.1936912536621094,
      "learning_rate": 1.4e-05,
      "loss": 1.0476,
      "step": 7500
    },
    {
      "epoch": 300.4,
      "grad_norm": 3.4485225677490234,
      "learning_rate": 1.3992000000000001e-05,
      "loss": 1.042,
      "step": 7510
    },
    {
      "epoch": 300.8,
      "grad_norm": 6.273809432983398,
      "learning_rate": 1.3984000000000002e-05,
      "loss": 1.0608,
      "step": 7520
    },
    {
      "epoch": 301.2,
      "grad_norm": 4.597984790802002,
      "learning_rate": 1.3976000000000001e-05,
      "loss": 1.045,
      "step": 7530
    },
    {
      "epoch": 301.6,
      "grad_norm": 4.1035966873168945,
      "learning_rate": 1.3968e-05,
      "loss": 1.0469,
      "step": 7540
    },
    {
      "epoch": 302.0,
      "grad_norm": 6.311459541320801,
      "learning_rate": 1.396e-05,
      "loss": 1.0395,
      "step": 7550
    },
    {
      "epoch": 302.4,
      "grad_norm": 5.215616703033447,
      "learning_rate": 1.3952000000000001e-05,
      "loss": 1.0341,
      "step": 7560
    },
    {
      "epoch": 302.8,
      "grad_norm": 10.636844635009766,
      "learning_rate": 1.3944000000000002e-05,
      "loss": 1.0468,
      "step": 7570
    },
    {
      "epoch": 303.2,
      "grad_norm": 3.099780321121216,
      "learning_rate": 1.3936e-05,
      "loss": 1.0378,
      "step": 7580
    },
    {
      "epoch": 303.6,
      "grad_norm": 5.9928178787231445,
      "learning_rate": 1.3928000000000001e-05,
      "loss": 1.042,
      "step": 7590
    },
    {
      "epoch": 304.0,
      "grad_norm": 7.162365436553955,
      "learning_rate": 1.392e-05,
      "loss": 1.0461,
      "step": 7600
    },
    {
      "epoch": 304.4,
      "grad_norm": 5.565479755401611,
      "learning_rate": 1.3912000000000002e-05,
      "loss": 1.0158,
      "step": 7610
    },
    {
      "epoch": 304.8,
      "grad_norm": 3.703406810760498,
      "learning_rate": 1.3904000000000003e-05,
      "loss": 1.0723,
      "step": 7620
    },
    {
      "epoch": 305.2,
      "grad_norm": 7.568408012390137,
      "learning_rate": 1.3896e-05,
      "loss": 1.0419,
      "step": 7630
    },
    {
      "epoch": 305.6,
      "grad_norm": 7.660638332366943,
      "learning_rate": 1.3888000000000002e-05,
      "loss": 1.0162,
      "step": 7640
    },
    {
      "epoch": 306.0,
      "grad_norm": 3.0410869121551514,
      "learning_rate": 1.3880000000000001e-05,
      "loss": 1.0694,
      "step": 7650
    },
    {
      "epoch": 306.4,
      "grad_norm": 3.55079984664917,
      "learning_rate": 1.3872e-05,
      "loss": 1.037,
      "step": 7660
    },
    {
      "epoch": 306.8,
      "grad_norm": 5.233724117279053,
      "learning_rate": 1.3864000000000001e-05,
      "loss": 1.0373,
      "step": 7670
    },
    {
      "epoch": 307.2,
      "grad_norm": 8.13278865814209,
      "learning_rate": 1.3856e-05,
      "loss": 1.0823,
      "step": 7680
    },
    {
      "epoch": 307.6,
      "grad_norm": 5.41596794128418,
      "learning_rate": 1.3848000000000002e-05,
      "loss": 1.027,
      "step": 7690
    },
    {
      "epoch": 308.0,
      "grad_norm": 5.470495700836182,
      "learning_rate": 1.384e-05,
      "loss": 1.0445,
      "step": 7700
    },
    {
      "epoch": 308.4,
      "grad_norm": 5.714481830596924,
      "learning_rate": 1.3832e-05,
      "loss": 1.0363,
      "step": 7710
    },
    {
      "epoch": 308.8,
      "grad_norm": 7.482788562774658,
      "learning_rate": 1.3824000000000002e-05,
      "loss": 1.063,
      "step": 7720
    },
    {
      "epoch": 309.2,
      "grad_norm": 3.273111581802368,
      "learning_rate": 1.3816000000000001e-05,
      "loss": 1.0308,
      "step": 7730
    },
    {
      "epoch": 309.6,
      "grad_norm": 10.261795043945312,
      "learning_rate": 1.3808e-05,
      "loss": 1.0425,
      "step": 7740
    },
    {
      "epoch": 310.0,
      "grad_norm": 5.738493919372559,
      "learning_rate": 1.38e-05,
      "loss": 1.0522,
      "step": 7750
    },
    {
      "epoch": 310.4,
      "grad_norm": 5.4888811111450195,
      "learning_rate": 1.3792000000000001e-05,
      "loss": 1.0038,
      "step": 7760
    },
    {
      "epoch": 310.8,
      "grad_norm": 8.141313552856445,
      "learning_rate": 1.3784000000000002e-05,
      "loss": 1.0525,
      "step": 7770
    },
    {
      "epoch": 311.2,
      "grad_norm": 9.723376274108887,
      "learning_rate": 1.3776e-05,
      "loss": 1.0085,
      "step": 7780
    },
    {
      "epoch": 311.6,
      "grad_norm": 8.596076965332031,
      "learning_rate": 1.3768000000000001e-05,
      "loss": 1.0584,
      "step": 7790
    },
    {
      "epoch": 312.0,
      "grad_norm": 7.470856666564941,
      "learning_rate": 1.376e-05,
      "loss": 1.0291,
      "step": 7800
    },
    {
      "epoch": 312.4,
      "grad_norm": 5.703867435455322,
      "learning_rate": 1.3752000000000001e-05,
      "loss": 1.0292,
      "step": 7810
    },
    {
      "epoch": 312.8,
      "grad_norm": 6.977392673492432,
      "learning_rate": 1.3744000000000003e-05,
      "loss": 1.0303,
      "step": 7820
    },
    {
      "epoch": 313.2,
      "grad_norm": 8.087815284729004,
      "learning_rate": 1.3736e-05,
      "loss": 1.0367,
      "step": 7830
    },
    {
      "epoch": 313.6,
      "grad_norm": 3.31318736076355,
      "learning_rate": 1.3728000000000001e-05,
      "loss": 1.0172,
      "step": 7840
    },
    {
      "epoch": 314.0,
      "grad_norm": 4.249491214752197,
      "learning_rate": 1.3720000000000002e-05,
      "loss": 1.0417,
      "step": 7850
    },
    {
      "epoch": 314.4,
      "grad_norm": 10.172779083251953,
      "learning_rate": 1.3712e-05,
      "loss": 1.0433,
      "step": 7860
    },
    {
      "epoch": 314.8,
      "grad_norm": 5.327236175537109,
      "learning_rate": 1.3704000000000001e-05,
      "loss": 1.0208,
      "step": 7870
    },
    {
      "epoch": 315.2,
      "grad_norm": 9.48615837097168,
      "learning_rate": 1.3696e-05,
      "loss": 1.0138,
      "step": 7880
    },
    {
      "epoch": 315.6,
      "grad_norm": 8.884446144104004,
      "learning_rate": 1.3688000000000002e-05,
      "loss": 1.0331,
      "step": 7890
    },
    {
      "epoch": 316.0,
      "grad_norm": 8.350706100463867,
      "learning_rate": 1.3680000000000003e-05,
      "loss": 1.0243,
      "step": 7900
    },
    {
      "epoch": 316.4,
      "grad_norm": 3.9988203048706055,
      "learning_rate": 1.3672e-05,
      "loss": 1.0228,
      "step": 7910
    },
    {
      "epoch": 316.8,
      "grad_norm": 16.857196807861328,
      "learning_rate": 1.3664000000000002e-05,
      "loss": 1.0388,
      "step": 7920
    },
    {
      "epoch": 317.2,
      "grad_norm": 4.500136852264404,
      "learning_rate": 1.3656000000000001e-05,
      "loss": 1.0296,
      "step": 7930
    },
    {
      "epoch": 317.6,
      "grad_norm": 7.1910624504089355,
      "learning_rate": 1.3648e-05,
      "loss": 1.0232,
      "step": 7940
    },
    {
      "epoch": 318.0,
      "grad_norm": 4.681326866149902,
      "learning_rate": 1.3640000000000002e-05,
      "loss": 1.0261,
      "step": 7950
    },
    {
      "epoch": 318.4,
      "grad_norm": 5.087606906890869,
      "learning_rate": 1.3632000000000001e-05,
      "loss": 1.0203,
      "step": 7960
    },
    {
      "epoch": 318.8,
      "grad_norm": 6.639813423156738,
      "learning_rate": 1.3624000000000002e-05,
      "loss": 1.0068,
      "step": 7970
    },
    {
      "epoch": 319.2,
      "grad_norm": 8.454648971557617,
      "learning_rate": 1.3616e-05,
      "loss": 1.0445,
      "step": 7980
    },
    {
      "epoch": 319.6,
      "grad_norm": 7.638230323791504,
      "learning_rate": 1.3608e-05,
      "loss": 1.0286,
      "step": 7990
    },
    {
      "epoch": 320.0,
      "grad_norm": 6.0529913902282715,
      "learning_rate": 1.3600000000000002e-05,
      "loss": 1.0412,
      "step": 8000
    },
    {
      "epoch": 320.4,
      "grad_norm": 3.32399845123291,
      "learning_rate": 1.3592000000000001e-05,
      "loss": 1.0107,
      "step": 8010
    },
    {
      "epoch": 320.8,
      "grad_norm": 10.947297096252441,
      "learning_rate": 1.3584000000000002e-05,
      "loss": 1.0458,
      "step": 8020
    },
    {
      "epoch": 321.2,
      "grad_norm": 5.927941799163818,
      "learning_rate": 1.3576e-05,
      "loss": 1.0261,
      "step": 8030
    },
    {
      "epoch": 321.6,
      "grad_norm": 5.4269843101501465,
      "learning_rate": 1.3568000000000001e-05,
      "loss": 1.0297,
      "step": 8040
    },
    {
      "epoch": 322.0,
      "grad_norm": 4.378918647766113,
      "learning_rate": 1.3560000000000002e-05,
      "loss": 1.0468,
      "step": 8050
    },
    {
      "epoch": 322.4,
      "grad_norm": 2.7531626224517822,
      "learning_rate": 1.3552e-05,
      "loss": 1.0166,
      "step": 8060
    },
    {
      "epoch": 322.8,
      "grad_norm": 5.865725517272949,
      "learning_rate": 1.3544000000000001e-05,
      "loss": 1.048,
      "step": 8070
    },
    {
      "epoch": 323.2,
      "grad_norm": 6.895376205444336,
      "learning_rate": 1.3536e-05,
      "loss": 1.0028,
      "step": 8080
    },
    {
      "epoch": 323.6,
      "grad_norm": 5.848382472991943,
      "learning_rate": 1.3528000000000002e-05,
      "loss": 1.0143,
      "step": 8090
    },
    {
      "epoch": 324.0,
      "grad_norm": 4.451082706451416,
      "learning_rate": 1.3520000000000003e-05,
      "loss": 1.0473,
      "step": 8100
    },
    {
      "epoch": 324.4,
      "grad_norm": 5.026927471160889,
      "learning_rate": 1.3512e-05,
      "loss": 1.0188,
      "step": 8110
    },
    {
      "epoch": 324.8,
      "grad_norm": 9.97833251953125,
      "learning_rate": 1.3504000000000001e-05,
      "loss": 1.0347,
      "step": 8120
    },
    {
      "epoch": 325.2,
      "grad_norm": 5.0259175300598145,
      "learning_rate": 1.3496000000000001e-05,
      "loss": 1.0061,
      "step": 8130
    },
    {
      "epoch": 325.6,
      "grad_norm": 4.474656105041504,
      "learning_rate": 1.3488e-05,
      "loss": 1.0307,
      "step": 8140
    },
    {
      "epoch": 326.0,
      "grad_norm": 3.9187707901000977,
      "learning_rate": 1.3480000000000001e-05,
      "loss": 1.0184,
      "step": 8150
    },
    {
      "epoch": 326.4,
      "grad_norm": 5.05064582824707,
      "learning_rate": 1.3472e-05,
      "loss": 1.025,
      "step": 8160
    },
    {
      "epoch": 326.8,
      "grad_norm": 5.361393451690674,
      "learning_rate": 1.3464000000000002e-05,
      "loss": 1.0186,
      "step": 8170
    },
    {
      "epoch": 327.2,
      "grad_norm": 7.456020355224609,
      "learning_rate": 1.3456e-05,
      "loss": 1.0305,
      "step": 8180
    },
    {
      "epoch": 327.6,
      "grad_norm": 9.594243049621582,
      "learning_rate": 1.3448e-05,
      "loss": 1.0072,
      "step": 8190
    },
    {
      "epoch": 328.0,
      "grad_norm": 5.247235298156738,
      "learning_rate": 1.3440000000000002e-05,
      "loss": 1.0323,
      "step": 8200
    },
    {
      "epoch": 328.4,
      "grad_norm": 5.11843204498291,
      "learning_rate": 1.3432000000000001e-05,
      "loss": 1.0148,
      "step": 8210
    },
    {
      "epoch": 328.8,
      "grad_norm": 4.786214351654053,
      "learning_rate": 1.3424000000000002e-05,
      "loss": 1.0026,
      "step": 8220
    },
    {
      "epoch": 329.2,
      "grad_norm": 3.465280771255493,
      "learning_rate": 1.3416e-05,
      "loss": 0.9976,
      "step": 8230
    },
    {
      "epoch": 329.6,
      "grad_norm": 3.2127366065979004,
      "learning_rate": 1.3408000000000001e-05,
      "loss": 1.0523,
      "step": 8240
    },
    {
      "epoch": 330.0,
      "grad_norm": 7.732780933380127,
      "learning_rate": 1.3400000000000002e-05,
      "loss": 1.0135,
      "step": 8250
    },
    {
      "epoch": 330.4,
      "grad_norm": 5.410336971282959,
      "learning_rate": 1.3392e-05,
      "loss": 0.9896,
      "step": 8260
    },
    {
      "epoch": 330.8,
      "grad_norm": 4.897072792053223,
      "learning_rate": 1.3384000000000001e-05,
      "loss": 1.0427,
      "step": 8270
    },
    {
      "epoch": 331.2,
      "grad_norm": 4.701855659484863,
      "learning_rate": 1.3376e-05,
      "loss": 1.0186,
      "step": 8280
    },
    {
      "epoch": 331.6,
      "grad_norm": 4.504973411560059,
      "learning_rate": 1.3368000000000001e-05,
      "loss": 1.0233,
      "step": 8290
    },
    {
      "epoch": 332.0,
      "grad_norm": 4.90302848815918,
      "learning_rate": 1.3360000000000003e-05,
      "loss": 1.0049,
      "step": 8300
    },
    {
      "epoch": 332.4,
      "grad_norm": 4.97213077545166,
      "learning_rate": 1.3352e-05,
      "loss": 1.005,
      "step": 8310
    },
    {
      "epoch": 332.8,
      "grad_norm": 4.583020210266113,
      "learning_rate": 1.3344000000000001e-05,
      "loss": 1.0413,
      "step": 8320
    },
    {
      "epoch": 333.2,
      "grad_norm": 6.085175037384033,
      "learning_rate": 1.3336e-05,
      "loss": 1.0111,
      "step": 8330
    },
    {
      "epoch": 333.6,
      "grad_norm": 6.564201831817627,
      "learning_rate": 1.3328e-05,
      "loss": 1.0104,
      "step": 8340
    },
    {
      "epoch": 334.0,
      "grad_norm": 3.637969493865967,
      "learning_rate": 1.3320000000000001e-05,
      "loss": 1.0028,
      "step": 8350
    },
    {
      "epoch": 334.4,
      "grad_norm": 5.9879302978515625,
      "learning_rate": 1.3312e-05,
      "loss": 1.0209,
      "step": 8360
    },
    {
      "epoch": 334.8,
      "grad_norm": 4.735589027404785,
      "learning_rate": 1.3304000000000002e-05,
      "loss": 0.9764,
      "step": 8370
    },
    {
      "epoch": 335.2,
      "grad_norm": 3.4098780155181885,
      "learning_rate": 1.3296e-05,
      "loss": 1.0415,
      "step": 8380
    },
    {
      "epoch": 335.6,
      "grad_norm": 4.484151840209961,
      "learning_rate": 1.3288e-05,
      "loss": 0.9902,
      "step": 8390
    },
    {
      "epoch": 336.0,
      "grad_norm": 9.419411659240723,
      "learning_rate": 1.3280000000000002e-05,
      "loss": 0.9964,
      "step": 8400
    },
    {
      "epoch": 336.4,
      "grad_norm": 6.065832614898682,
      "learning_rate": 1.3272000000000001e-05,
      "loss": 0.9944,
      "step": 8410
    },
    {
      "epoch": 336.8,
      "grad_norm": 3.3674843311309814,
      "learning_rate": 1.3264000000000002e-05,
      "loss": 1.0174,
      "step": 8420
    },
    {
      "epoch": 337.2,
      "grad_norm": 8.399981498718262,
      "learning_rate": 1.3256e-05,
      "loss": 1.0105,
      "step": 8430
    },
    {
      "epoch": 337.6,
      "grad_norm": 11.083009719848633,
      "learning_rate": 1.3248000000000001e-05,
      "loss": 1.0155,
      "step": 8440
    },
    {
      "epoch": 338.0,
      "grad_norm": 8.323003768920898,
      "learning_rate": 1.3240000000000002e-05,
      "loss": 1.0308,
      "step": 8450
    },
    {
      "epoch": 338.4,
      "grad_norm": 6.850860595703125,
      "learning_rate": 1.3232e-05,
      "loss": 1.0001,
      "step": 8460
    },
    {
      "epoch": 338.8,
      "grad_norm": 3.398287296295166,
      "learning_rate": 1.3224e-05,
      "loss": 0.9975,
      "step": 8470
    },
    {
      "epoch": 339.2,
      "grad_norm": 5.64583683013916,
      "learning_rate": 1.3216000000000002e-05,
      "loss": 0.9974,
      "step": 8480
    },
    {
      "epoch": 339.6,
      "grad_norm": 10.367412567138672,
      "learning_rate": 1.3208000000000001e-05,
      "loss": 1.0007,
      "step": 8490
    },
    {
      "epoch": 340.0,
      "grad_norm": 5.539916038513184,
      "learning_rate": 1.3200000000000002e-05,
      "loss": 1.0043,
      "step": 8500
    },
    {
      "epoch": 340.4,
      "grad_norm": 3.8629448413848877,
      "learning_rate": 1.3192e-05,
      "loss": 0.9873,
      "step": 8510
    },
    {
      "epoch": 340.8,
      "grad_norm": 5.034955024719238,
      "learning_rate": 1.3184000000000001e-05,
      "loss": 0.9988,
      "step": 8520
    },
    {
      "epoch": 341.2,
      "grad_norm": 6.014403343200684,
      "learning_rate": 1.3176000000000002e-05,
      "loss": 1.0265,
      "step": 8530
    },
    {
      "epoch": 341.6,
      "grad_norm": 8.046904563903809,
      "learning_rate": 1.3168e-05,
      "loss": 0.9855,
      "step": 8540
    },
    {
      "epoch": 342.0,
      "grad_norm": 4.0451250076293945,
      "learning_rate": 1.3160000000000001e-05,
      "loss": 0.9823,
      "step": 8550
    },
    {
      "epoch": 342.4,
      "grad_norm": 4.110979080200195,
      "learning_rate": 1.3152e-05,
      "loss": 1.0,
      "step": 8560
    },
    {
      "epoch": 342.8,
      "grad_norm": 3.6149816513061523,
      "learning_rate": 1.3144000000000002e-05,
      "loss": 1.0033,
      "step": 8570
    },
    {
      "epoch": 343.2,
      "grad_norm": 2.9860594272613525,
      "learning_rate": 1.3136000000000003e-05,
      "loss": 1.0249,
      "step": 8580
    },
    {
      "epoch": 343.6,
      "grad_norm": 5.463469982147217,
      "learning_rate": 1.3128e-05,
      "loss": 1.0108,
      "step": 8590
    },
    {
      "epoch": 344.0,
      "grad_norm": 3.463590383529663,
      "learning_rate": 1.3120000000000001e-05,
      "loss": 1.0117,
      "step": 8600
    },
    {
      "epoch": 344.4,
      "grad_norm": 7.278912544250488,
      "learning_rate": 1.3112e-05,
      "loss": 0.9786,
      "step": 8610
    },
    {
      "epoch": 344.8,
      "grad_norm": 11.779464721679688,
      "learning_rate": 1.3104000000000002e-05,
      "loss": 1.0375,
      "step": 8620
    },
    {
      "epoch": 345.2,
      "grad_norm": 4.02013635635376,
      "learning_rate": 1.3096000000000001e-05,
      "loss": 0.9665,
      "step": 8630
    },
    {
      "epoch": 345.6,
      "grad_norm": 7.243017196655273,
      "learning_rate": 1.3088e-05,
      "loss": 1.0044,
      "step": 8640
    },
    {
      "epoch": 346.0,
      "grad_norm": 8.60272216796875,
      "learning_rate": 1.3080000000000002e-05,
      "loss": 1.0014,
      "step": 8650
    },
    {
      "epoch": 346.4,
      "grad_norm": 3.684818744659424,
      "learning_rate": 1.3072e-05,
      "loss": 0.9978,
      "step": 8660
    },
    {
      "epoch": 346.8,
      "grad_norm": 6.883764743804932,
      "learning_rate": 1.3064e-05,
      "loss": 0.9993,
      "step": 8670
    },
    {
      "epoch": 347.2,
      "grad_norm": 10.87877368927002,
      "learning_rate": 1.3056000000000002e-05,
      "loss": 1.0251,
      "step": 8680
    },
    {
      "epoch": 347.6,
      "grad_norm": 11.805407524108887,
      "learning_rate": 1.3048000000000001e-05,
      "loss": 1.0066,
      "step": 8690
    },
    {
      "epoch": 348.0,
      "grad_norm": 4.022735595703125,
      "learning_rate": 1.3040000000000002e-05,
      "loss": 0.9739,
      "step": 8700
    },
    {
      "epoch": 348.4,
      "grad_norm": 4.095163822174072,
      "learning_rate": 1.3032e-05,
      "loss": 0.9784,
      "step": 8710
    },
    {
      "epoch": 348.8,
      "grad_norm": 13.136832237243652,
      "learning_rate": 1.3024000000000001e-05,
      "loss": 1.0259,
      "step": 8720
    },
    {
      "epoch": 349.2,
      "grad_norm": 4.1680755615234375,
      "learning_rate": 1.3016000000000002e-05,
      "loss": 0.9744,
      "step": 8730
    },
    {
      "epoch": 349.6,
      "grad_norm": 9.467179298400879,
      "learning_rate": 1.3008e-05,
      "loss": 1.0007,
      "step": 8740
    },
    {
      "epoch": 350.0,
      "grad_norm": 8.197771072387695,
      "learning_rate": 1.3000000000000001e-05,
      "loss": 1.0212,
      "step": 8750
    },
    {
      "epoch": 350.4,
      "grad_norm": 7.92671012878418,
      "learning_rate": 1.2992e-05,
      "loss": 0.997,
      "step": 8760
    },
    {
      "epoch": 350.8,
      "grad_norm": 8.200563430786133,
      "learning_rate": 1.2984000000000001e-05,
      "loss": 0.9727,
      "step": 8770
    },
    {
      "epoch": 351.2,
      "grad_norm": 4.338281631469727,
      "learning_rate": 1.2976000000000002e-05,
      "loss": 0.9837,
      "step": 8780
    },
    {
      "epoch": 351.6,
      "grad_norm": 4.730131149291992,
      "learning_rate": 1.2968e-05,
      "loss": 0.9776,
      "step": 8790
    },
    {
      "epoch": 352.0,
      "grad_norm": 3.611888885498047,
      "learning_rate": 1.2960000000000001e-05,
      "loss": 1.0112,
      "step": 8800
    },
    {
      "epoch": 352.4,
      "grad_norm": 3.149839401245117,
      "learning_rate": 1.2952e-05,
      "loss": 1.03,
      "step": 8810
    },
    {
      "epoch": 352.8,
      "grad_norm": 2.973783016204834,
      "learning_rate": 1.2944000000000002e-05,
      "loss": 0.973,
      "step": 8820
    },
    {
      "epoch": 353.2,
      "grad_norm": 5.271427631378174,
      "learning_rate": 1.2936000000000001e-05,
      "loss": 1.0092,
      "step": 8830
    },
    {
      "epoch": 353.6,
      "grad_norm": 5.1125617027282715,
      "learning_rate": 1.2928e-05,
      "loss": 1.0005,
      "step": 8840
    },
    {
      "epoch": 354.0,
      "grad_norm": 10.916232109069824,
      "learning_rate": 1.2920000000000002e-05,
      "loss": 0.9993,
      "step": 8850
    },
    {
      "epoch": 354.4,
      "grad_norm": 7.44486141204834,
      "learning_rate": 1.2912e-05,
      "loss": 0.9932,
      "step": 8860
    },
    {
      "epoch": 354.8,
      "grad_norm": 10.759608268737793,
      "learning_rate": 1.2904e-05,
      "loss": 1.0062,
      "step": 8870
    },
    {
      "epoch": 355.2,
      "grad_norm": 5.689671039581299,
      "learning_rate": 1.2896000000000002e-05,
      "loss": 1.0313,
      "step": 8880
    },
    {
      "epoch": 355.6,
      "grad_norm": 4.224239826202393,
      "learning_rate": 1.2888000000000001e-05,
      "loss": 0.9535,
      "step": 8890
    },
    {
      "epoch": 356.0,
      "grad_norm": 3.804302930831909,
      "learning_rate": 1.2880000000000002e-05,
      "loss": 0.9875,
      "step": 8900
    },
    {
      "epoch": 356.4,
      "grad_norm": 4.889528751373291,
      "learning_rate": 1.2872e-05,
      "loss": 1.0,
      "step": 8910
    },
    {
      "epoch": 356.8,
      "grad_norm": 8.26640796661377,
      "learning_rate": 1.2864e-05,
      "loss": 0.9721,
      "step": 8920
    },
    {
      "epoch": 357.2,
      "grad_norm": 4.95395565032959,
      "learning_rate": 1.2856000000000002e-05,
      "loss": 1.0155,
      "step": 8930
    },
    {
      "epoch": 357.6,
      "grad_norm": 6.211400508880615,
      "learning_rate": 1.2848e-05,
      "loss": 0.9934,
      "step": 8940
    },
    {
      "epoch": 358.0,
      "grad_norm": 8.05040168762207,
      "learning_rate": 1.284e-05,
      "loss": 0.9842,
      "step": 8950
    },
    {
      "epoch": 358.4,
      "grad_norm": 4.546441078186035,
      "learning_rate": 1.2832e-05,
      "loss": 0.9809,
      "step": 8960
    },
    {
      "epoch": 358.8,
      "grad_norm": 7.1218061447143555,
      "learning_rate": 1.2824000000000001e-05,
      "loss": 0.9729,
      "step": 8970
    },
    {
      "epoch": 359.2,
      "grad_norm": 3.379420280456543,
      "learning_rate": 1.2816000000000002e-05,
      "loss": 1.0118,
      "step": 8980
    },
    {
      "epoch": 359.6,
      "grad_norm": 10.437049865722656,
      "learning_rate": 1.2808e-05,
      "loss": 0.9916,
      "step": 8990
    },
    {
      "epoch": 360.0,
      "grad_norm": 3.8013007640838623,
      "learning_rate": 1.2800000000000001e-05,
      "loss": 0.9804,
      "step": 9000
    },
    {
      "epoch": 360.4,
      "grad_norm": 4.451315402984619,
      "learning_rate": 1.2792e-05,
      "loss": 0.9968,
      "step": 9010
    },
    {
      "epoch": 360.8,
      "grad_norm": 4.499734878540039,
      "learning_rate": 1.2784000000000002e-05,
      "loss": 0.9606,
      "step": 9020
    },
    {
      "epoch": 361.2,
      "grad_norm": 3.000211000442505,
      "learning_rate": 1.2776000000000001e-05,
      "loss": 0.9977,
      "step": 9030
    },
    {
      "epoch": 361.6,
      "grad_norm": 4.536067962646484,
      "learning_rate": 1.2768e-05,
      "loss": 0.9834,
      "step": 9040
    },
    {
      "epoch": 362.0,
      "grad_norm": 6.675457000732422,
      "learning_rate": 1.2760000000000001e-05,
      "loss": 1.0224,
      "step": 9050
    },
    {
      "epoch": 362.4,
      "grad_norm": 5.918665409088135,
      "learning_rate": 1.2752e-05,
      "loss": 1.0385,
      "step": 9060
    },
    {
      "epoch": 362.8,
      "grad_norm": 4.773753643035889,
      "learning_rate": 1.2744e-05,
      "loss": 0.9705,
      "step": 9070
    },
    {
      "epoch": 363.2,
      "grad_norm": 3.4997000694274902,
      "learning_rate": 1.2736000000000001e-05,
      "loss": 1.0,
      "step": 9080
    },
    {
      "epoch": 363.6,
      "grad_norm": 9.498666763305664,
      "learning_rate": 1.2728e-05,
      "loss": 1.0091,
      "step": 9090
    },
    {
      "epoch": 364.0,
      "grad_norm": 5.082564353942871,
      "learning_rate": 1.2720000000000002e-05,
      "loss": 0.9748,
      "step": 9100
    },
    {
      "epoch": 364.4,
      "grad_norm": 4.686550140380859,
      "learning_rate": 1.2712000000000001e-05,
      "loss": 0.9544,
      "step": 9110
    },
    {
      "epoch": 364.8,
      "grad_norm": 2.93524432182312,
      "learning_rate": 1.2704e-05,
      "loss": 0.997,
      "step": 9120
    },
    {
      "epoch": 365.2,
      "grad_norm": 5.557968616485596,
      "learning_rate": 1.2696000000000002e-05,
      "loss": 0.9866,
      "step": 9130
    },
    {
      "epoch": 365.6,
      "grad_norm": 3.2820560932159424,
      "learning_rate": 1.2688e-05,
      "loss": 1.0017,
      "step": 9140
    },
    {
      "epoch": 366.0,
      "grad_norm": 8.192543029785156,
      "learning_rate": 1.268e-05,
      "loss": 0.9656,
      "step": 9150
    },
    {
      "epoch": 366.4,
      "grad_norm": 7.62580680847168,
      "learning_rate": 1.2672000000000002e-05,
      "loss": 0.9799,
      "step": 9160
    },
    {
      "epoch": 366.8,
      "grad_norm": 8.14166259765625,
      "learning_rate": 1.2664000000000001e-05,
      "loss": 0.989,
      "step": 9170
    },
    {
      "epoch": 367.2,
      "grad_norm": 4.349490165710449,
      "learning_rate": 1.2656000000000002e-05,
      "loss": 0.9732,
      "step": 9180
    },
    {
      "epoch": 367.6,
      "grad_norm": 14.590188026428223,
      "learning_rate": 1.2648e-05,
      "loss": 1.0182,
      "step": 9190
    },
    {
      "epoch": 368.0,
      "grad_norm": 5.560237407684326,
      "learning_rate": 1.2640000000000001e-05,
      "loss": 0.9896,
      "step": 9200
    },
    {
      "epoch": 368.4,
      "grad_norm": 7.701800346374512,
      "learning_rate": 1.2632000000000002e-05,
      "loss": 0.972,
      "step": 9210
    },
    {
      "epoch": 368.8,
      "grad_norm": 6.429575443267822,
      "learning_rate": 1.2624000000000001e-05,
      "loss": 0.988,
      "step": 9220
    },
    {
      "epoch": 369.2,
      "grad_norm": 5.122196674346924,
      "learning_rate": 1.2616e-05,
      "loss": 0.9955,
      "step": 9230
    },
    {
      "epoch": 369.6,
      "grad_norm": 8.84682846069336,
      "learning_rate": 1.2608e-05,
      "loss": 0.9895,
      "step": 9240
    },
    {
      "epoch": 370.0,
      "grad_norm": 4.910820484161377,
      "learning_rate": 1.2600000000000001e-05,
      "loss": 0.9899,
      "step": 9250
    },
    {
      "epoch": 370.4,
      "grad_norm": 2.864879608154297,
      "learning_rate": 1.2592000000000002e-05,
      "loss": 0.9801,
      "step": 9260
    },
    {
      "epoch": 370.8,
      "grad_norm": 5.19351863861084,
      "learning_rate": 1.2584e-05,
      "loss": 0.9983,
      "step": 9270
    },
    {
      "epoch": 371.2,
      "grad_norm": 4.99611234664917,
      "learning_rate": 1.2576000000000001e-05,
      "loss": 0.9505,
      "step": 9280
    },
    {
      "epoch": 371.6,
      "grad_norm": 7.543390274047852,
      "learning_rate": 1.2568e-05,
      "loss": 0.9919,
      "step": 9290
    },
    {
      "epoch": 372.0,
      "grad_norm": 8.801352500915527,
      "learning_rate": 1.2560000000000002e-05,
      "loss": 0.9855,
      "step": 9300
    },
    {
      "epoch": 372.4,
      "grad_norm": 4.582435131072998,
      "learning_rate": 1.2552000000000001e-05,
      "loss": 1.0131,
      "step": 9310
    },
    {
      "epoch": 372.8,
      "grad_norm": 3.7165822982788086,
      "learning_rate": 1.2544e-05,
      "loss": 0.9601,
      "step": 9320
    },
    {
      "epoch": 373.2,
      "grad_norm": 6.125251293182373,
      "learning_rate": 1.2536000000000002e-05,
      "loss": 0.9805,
      "step": 9330
    },
    {
      "epoch": 373.6,
      "grad_norm": 8.766373634338379,
      "learning_rate": 1.2528e-05,
      "loss": 0.9936,
      "step": 9340
    },
    {
      "epoch": 374.0,
      "grad_norm": 5.788326263427734,
      "learning_rate": 1.252e-05,
      "loss": 0.949,
      "step": 9350
    },
    {
      "epoch": 374.4,
      "grad_norm": 5.0163893699646,
      "learning_rate": 1.2512000000000002e-05,
      "loss": 0.9805,
      "step": 9360
    },
    {
      "epoch": 374.8,
      "grad_norm": 4.520804405212402,
      "learning_rate": 1.2504000000000001e-05,
      "loss": 1.0162,
      "step": 9370
    },
    {
      "epoch": 375.2,
      "grad_norm": 6.919525146484375,
      "learning_rate": 1.2496000000000002e-05,
      "loss": 0.9656,
      "step": 9380
    },
    {
      "epoch": 375.6,
      "grad_norm": 6.510801792144775,
      "learning_rate": 1.2488e-05,
      "loss": 0.9807,
      "step": 9390
    },
    {
      "epoch": 376.0,
      "grad_norm": 10.283381462097168,
      "learning_rate": 1.248e-05,
      "loss": 0.953,
      "step": 9400
    },
    {
      "epoch": 376.4,
      "grad_norm": 5.192866802215576,
      "learning_rate": 1.2472000000000002e-05,
      "loss": 0.9587,
      "step": 9410
    },
    {
      "epoch": 376.8,
      "grad_norm": 6.056890487670898,
      "learning_rate": 1.2464000000000001e-05,
      "loss": 0.9756,
      "step": 9420
    },
    {
      "epoch": 377.2,
      "grad_norm": 5.145622253417969,
      "learning_rate": 1.2456e-05,
      "loss": 0.9622,
      "step": 9430
    },
    {
      "epoch": 377.6,
      "grad_norm": 3.685767412185669,
      "learning_rate": 1.2448e-05,
      "loss": 0.9658,
      "step": 9440
    },
    {
      "epoch": 378.0,
      "grad_norm": 6.817389011383057,
      "learning_rate": 1.2440000000000001e-05,
      "loss": 0.9835,
      "step": 9450
    },
    {
      "epoch": 378.4,
      "grad_norm": 8.519165992736816,
      "learning_rate": 1.2432000000000002e-05,
      "loss": 0.9593,
      "step": 9460
    },
    {
      "epoch": 378.8,
      "grad_norm": 4.791851997375488,
      "learning_rate": 1.2424e-05,
      "loss": 0.9928,
      "step": 9470
    },
    {
      "epoch": 379.2,
      "grad_norm": 13.88621997833252,
      "learning_rate": 1.2416000000000001e-05,
      "loss": 0.978,
      "step": 9480
    },
    {
      "epoch": 379.6,
      "grad_norm": 3.2484710216522217,
      "learning_rate": 1.2408e-05,
      "loss": 0.9559,
      "step": 9490
    },
    {
      "epoch": 380.0,
      "grad_norm": 6.912924766540527,
      "learning_rate": 1.2400000000000002e-05,
      "loss": 0.9762,
      "step": 9500
    },
    {
      "epoch": 380.4,
      "grad_norm": 8.681906700134277,
      "learning_rate": 1.2392000000000003e-05,
      "loss": 0.9509,
      "step": 9510
    },
    {
      "epoch": 380.8,
      "grad_norm": 6.949729919433594,
      "learning_rate": 1.2384e-05,
      "loss": 0.9694,
      "step": 9520
    },
    {
      "epoch": 381.2,
      "grad_norm": 9.656327247619629,
      "learning_rate": 1.2376000000000001e-05,
      "loss": 0.9627,
      "step": 9530
    },
    {
      "epoch": 381.6,
      "grad_norm": 4.844057083129883,
      "learning_rate": 1.2368e-05,
      "loss": 0.9565,
      "step": 9540
    },
    {
      "epoch": 382.0,
      "grad_norm": 5.200533390045166,
      "learning_rate": 1.236e-05,
      "loss": 1.0016,
      "step": 9550
    },
    {
      "epoch": 382.4,
      "grad_norm": 4.7688117027282715,
      "learning_rate": 1.2352000000000001e-05,
      "loss": 0.9494,
      "step": 9560
    },
    {
      "epoch": 382.8,
      "grad_norm": 9.42146110534668,
      "learning_rate": 1.2344e-05,
      "loss": 0.9563,
      "step": 9570
    },
    {
      "epoch": 383.2,
      "grad_norm": 4.599044322967529,
      "learning_rate": 1.2336000000000002e-05,
      "loss": 0.9565,
      "step": 9580
    },
    {
      "epoch": 383.6,
      "grad_norm": 4.194133758544922,
      "learning_rate": 1.2328e-05,
      "loss": 0.9576,
      "step": 9590
    },
    {
      "epoch": 384.0,
      "grad_norm": 4.328759670257568,
      "learning_rate": 1.232e-05,
      "loss": 0.9825,
      "step": 9600
    },
    {
      "epoch": 384.4,
      "grad_norm": 11.72895336151123,
      "learning_rate": 1.2312000000000002e-05,
      "loss": 0.95,
      "step": 9610
    },
    {
      "epoch": 384.8,
      "grad_norm": 8.757137298583984,
      "learning_rate": 1.2304000000000001e-05,
      "loss": 0.9654,
      "step": 9620
    },
    {
      "epoch": 385.2,
      "grad_norm": 11.254096031188965,
      "learning_rate": 1.2296e-05,
      "loss": 1.0054,
      "step": 9630
    },
    {
      "epoch": 385.6,
      "grad_norm": 10.861026763916016,
      "learning_rate": 1.2288e-05,
      "loss": 0.9832,
      "step": 9640
    },
    {
      "epoch": 386.0,
      "grad_norm": 5.978557109832764,
      "learning_rate": 1.2280000000000001e-05,
      "loss": 0.9556,
      "step": 9650
    },
    {
      "epoch": 386.4,
      "grad_norm": 4.525641918182373,
      "learning_rate": 1.2272000000000002e-05,
      "loss": 0.9804,
      "step": 9660
    },
    {
      "epoch": 386.8,
      "grad_norm": 4.649071216583252,
      "learning_rate": 1.2264e-05,
      "loss": 0.9688,
      "step": 9670
    },
    {
      "epoch": 387.2,
      "grad_norm": 5.736935138702393,
      "learning_rate": 1.2256000000000001e-05,
      "loss": 0.9762,
      "step": 9680
    },
    {
      "epoch": 387.6,
      "grad_norm": 5.555579662322998,
      "learning_rate": 1.2248000000000002e-05,
      "loss": 0.9517,
      "step": 9690
    },
    {
      "epoch": 388.0,
      "grad_norm": 3.7735159397125244,
      "learning_rate": 1.2240000000000001e-05,
      "loss": 0.9588,
      "step": 9700
    },
    {
      "epoch": 388.4,
      "grad_norm": 7.553955078125,
      "learning_rate": 1.2232000000000002e-05,
      "loss": 0.9819,
      "step": 9710
    },
    {
      "epoch": 388.8,
      "grad_norm": 4.815043926239014,
      "learning_rate": 1.2224e-05,
      "loss": 1.0075,
      "step": 9720
    },
    {
      "epoch": 389.2,
      "grad_norm": 7.917450904846191,
      "learning_rate": 1.2216000000000001e-05,
      "loss": 0.9369,
      "step": 9730
    },
    {
      "epoch": 389.6,
      "grad_norm": 3.5842556953430176,
      "learning_rate": 1.2208000000000002e-05,
      "loss": 0.9696,
      "step": 9740
    },
    {
      "epoch": 390.0,
      "grad_norm": 5.746408939361572,
      "learning_rate": 1.22e-05,
      "loss": 0.9599,
      "step": 9750
    },
    {
      "epoch": 390.4,
      "grad_norm": 10.692543983459473,
      "learning_rate": 1.2192000000000001e-05,
      "loss": 0.9696,
      "step": 9760
    },
    {
      "epoch": 390.8,
      "grad_norm": 3.9014432430267334,
      "learning_rate": 1.2184e-05,
      "loss": 0.9704,
      "step": 9770
    },
    {
      "epoch": 391.2,
      "grad_norm": 5.156250953674316,
      "learning_rate": 1.2176000000000002e-05,
      "loss": 0.9642,
      "step": 9780
    },
    {
      "epoch": 391.6,
      "grad_norm": 3.285398006439209,
      "learning_rate": 1.2168000000000003e-05,
      "loss": 0.9311,
      "step": 9790
    },
    {
      "epoch": 392.0,
      "grad_norm": 5.068403720855713,
      "learning_rate": 1.216e-05,
      "loss": 0.9661,
      "step": 9800
    },
    {
      "epoch": 392.4,
      "grad_norm": 6.0330610275268555,
      "learning_rate": 1.2152000000000002e-05,
      "loss": 0.9717,
      "step": 9810
    },
    {
      "epoch": 392.8,
      "grad_norm": 4.1926045417785645,
      "learning_rate": 1.2144000000000001e-05,
      "loss": 0.9402,
      "step": 9820
    },
    {
      "epoch": 393.2,
      "grad_norm": 4.857780933380127,
      "learning_rate": 1.2136e-05,
      "loss": 1.0113,
      "step": 9830
    },
    {
      "epoch": 393.6,
      "grad_norm": 4.971683979034424,
      "learning_rate": 1.2128000000000001e-05,
      "loss": 0.9865,
      "step": 9840
    },
    {
      "epoch": 394.0,
      "grad_norm": 3.471991777420044,
      "learning_rate": 1.2120000000000001e-05,
      "loss": 0.934,
      "step": 9850
    },
    {
      "epoch": 394.4,
      "grad_norm": 13.73857307434082,
      "learning_rate": 1.2112000000000002e-05,
      "loss": 0.945,
      "step": 9860
    },
    {
      "epoch": 394.8,
      "grad_norm": 8.818862915039062,
      "learning_rate": 1.2104e-05,
      "loss": 0.9569,
      "step": 9870
    },
    {
      "epoch": 395.2,
      "grad_norm": 8.528164863586426,
      "learning_rate": 1.2096e-05,
      "loss": 0.9834,
      "step": 9880
    },
    {
      "epoch": 395.6,
      "grad_norm": 11.962721824645996,
      "learning_rate": 1.2088000000000002e-05,
      "loss": 0.9369,
      "step": 9890
    },
    {
      "epoch": 396.0,
      "grad_norm": 7.918431758880615,
      "learning_rate": 1.2080000000000001e-05,
      "loss": 0.9611,
      "step": 9900
    },
    {
      "epoch": 396.4,
      "grad_norm": 4.454377174377441,
      "learning_rate": 1.2072000000000002e-05,
      "loss": 0.933,
      "step": 9910
    },
    {
      "epoch": 396.8,
      "grad_norm": 17.105880737304688,
      "learning_rate": 1.2064e-05,
      "loss": 0.973,
      "step": 9920
    },
    {
      "epoch": 397.2,
      "grad_norm": 9.563393592834473,
      "learning_rate": 1.2056000000000001e-05,
      "loss": 0.9799,
      "step": 9930
    },
    {
      "epoch": 397.6,
      "grad_norm": 3.379182815551758,
      "learning_rate": 1.2048000000000002e-05,
      "loss": 0.987,
      "step": 9940
    },
    {
      "epoch": 398.0,
      "grad_norm": 5.665893077850342,
      "learning_rate": 1.204e-05,
      "loss": 0.9433,
      "step": 9950
    },
    {
      "epoch": 398.4,
      "grad_norm": 4.662225723266602,
      "learning_rate": 1.2032000000000001e-05,
      "loss": 0.9732,
      "step": 9960
    },
    {
      "epoch": 398.8,
      "grad_norm": 6.818211078643799,
      "learning_rate": 1.2024e-05,
      "loss": 0.9453,
      "step": 9970
    },
    {
      "epoch": 399.2,
      "grad_norm": 6.99910831451416,
      "learning_rate": 1.2016000000000002e-05,
      "loss": 0.9653,
      "step": 9980
    },
    {
      "epoch": 399.6,
      "grad_norm": 9.154886245727539,
      "learning_rate": 1.2008000000000003e-05,
      "loss": 0.9541,
      "step": 9990
    },
    {
      "epoch": 400.0,
      "grad_norm": 13.778736114501953,
      "learning_rate": 1.2e-05,
      "loss": 0.9703,
      "step": 10000
    },
    {
      "epoch": 400.4,
      "grad_norm": 10.797008514404297,
      "learning_rate": 1.1992000000000001e-05,
      "loss": 0.9694,
      "step": 10010
    },
    {
      "epoch": 400.8,
      "grad_norm": 6.892832279205322,
      "learning_rate": 1.1984e-05,
      "loss": 0.9315,
      "step": 10020
    },
    {
      "epoch": 401.2,
      "grad_norm": 7.728419780731201,
      "learning_rate": 1.1976e-05,
      "loss": 0.9676,
      "step": 10030
    },
    {
      "epoch": 401.6,
      "grad_norm": 6.537766933441162,
      "learning_rate": 1.1968000000000001e-05,
      "loss": 0.9576,
      "step": 10040
    },
    {
      "epoch": 402.0,
      "grad_norm": 7.415330410003662,
      "learning_rate": 1.196e-05,
      "loss": 0.9843,
      "step": 10050
    },
    {
      "epoch": 402.4,
      "grad_norm": 14.938562393188477,
      "learning_rate": 1.1952000000000002e-05,
      "loss": 0.9442,
      "step": 10060
    },
    {
      "epoch": 402.8,
      "grad_norm": 6.173710823059082,
      "learning_rate": 1.1944e-05,
      "loss": 0.9615,
      "step": 10070
    },
    {
      "epoch": 403.2,
      "grad_norm": 4.141470909118652,
      "learning_rate": 1.1936e-05,
      "loss": 0.9484,
      "step": 10080
    },
    {
      "epoch": 403.6,
      "grad_norm": 8.00936222076416,
      "learning_rate": 1.1928000000000002e-05,
      "loss": 0.9733,
      "step": 10090
    },
    {
      "epoch": 404.0,
      "grad_norm": 5.332129001617432,
      "learning_rate": 1.1920000000000001e-05,
      "loss": 0.9322,
      "step": 10100
    },
    {
      "epoch": 404.4,
      "grad_norm": 5.0936479568481445,
      "learning_rate": 1.1912000000000002e-05,
      "loss": 0.9664,
      "step": 10110
    },
    {
      "epoch": 404.8,
      "grad_norm": 7.522558689117432,
      "learning_rate": 1.1904e-05,
      "loss": 0.9656,
      "step": 10120
    },
    {
      "epoch": 405.2,
      "grad_norm": 3.083306074142456,
      "learning_rate": 1.1896000000000001e-05,
      "loss": 0.9431,
      "step": 10130
    },
    {
      "epoch": 405.6,
      "grad_norm": 6.407077312469482,
      "learning_rate": 1.1888000000000002e-05,
      "loss": 0.96,
      "step": 10140
    },
    {
      "epoch": 406.0,
      "grad_norm": 5.992641925811768,
      "learning_rate": 1.188e-05,
      "loss": 0.9626,
      "step": 10150
    },
    {
      "epoch": 406.4,
      "grad_norm": 6.314825057983398,
      "learning_rate": 1.1872000000000001e-05,
      "loss": 0.9685,
      "step": 10160
    },
    {
      "epoch": 406.8,
      "grad_norm": 4.137392520904541,
      "learning_rate": 1.1864e-05,
      "loss": 0.9482,
      "step": 10170
    },
    {
      "epoch": 407.2,
      "grad_norm": 3.5593044757843018,
      "learning_rate": 1.1856000000000001e-05,
      "loss": 0.9833,
      "step": 10180
    },
    {
      "epoch": 407.6,
      "grad_norm": 6.469707012176514,
      "learning_rate": 1.1848000000000002e-05,
      "loss": 0.9894,
      "step": 10190
    },
    {
      "epoch": 408.0,
      "grad_norm": 5.9863362312316895,
      "learning_rate": 1.184e-05,
      "loss": 0.9467,
      "step": 10200
    },
    {
      "epoch": 408.4,
      "grad_norm": 4.788320541381836,
      "learning_rate": 1.1832000000000001e-05,
      "loss": 0.9431,
      "step": 10210
    },
    {
      "epoch": 408.8,
      "grad_norm": 4.139087200164795,
      "learning_rate": 1.1824e-05,
      "loss": 0.9741,
      "step": 10220
    },
    {
      "epoch": 409.2,
      "grad_norm": 5.652913570404053,
      "learning_rate": 1.1816e-05,
      "loss": 0.937,
      "step": 10230
    },
    {
      "epoch": 409.6,
      "grad_norm": 5.60554313659668,
      "learning_rate": 1.1808000000000001e-05,
      "loss": 0.9321,
      "step": 10240
    },
    {
      "epoch": 410.0,
      "grad_norm": 6.052803993225098,
      "learning_rate": 1.18e-05,
      "loss": 0.9687,
      "step": 10250
    },
    {
      "epoch": 410.4,
      "grad_norm": 13.651032447814941,
      "learning_rate": 1.1792000000000002e-05,
      "loss": 0.9492,
      "step": 10260
    },
    {
      "epoch": 410.8,
      "grad_norm": 5.534634113311768,
      "learning_rate": 1.1784e-05,
      "loss": 0.9313,
      "step": 10270
    },
    {
      "epoch": 411.2,
      "grad_norm": 7.2393479347229,
      "learning_rate": 1.1776e-05,
      "loss": 0.97,
      "step": 10280
    },
    {
      "epoch": 411.6,
      "grad_norm": 5.046730995178223,
      "learning_rate": 1.1768000000000002e-05,
      "loss": 0.9629,
      "step": 10290
    },
    {
      "epoch": 412.0,
      "grad_norm": 13.081900596618652,
      "learning_rate": 1.1760000000000001e-05,
      "loss": 0.9524,
      "step": 10300
    },
    {
      "epoch": 412.4,
      "grad_norm": 5.414816379547119,
      "learning_rate": 1.1752000000000002e-05,
      "loss": 0.9811,
      "step": 10310
    },
    {
      "epoch": 412.8,
      "grad_norm": 7.4517621994018555,
      "learning_rate": 1.1744000000000001e-05,
      "loss": 0.9553,
      "step": 10320
    },
    {
      "epoch": 413.2,
      "grad_norm": 4.558158874511719,
      "learning_rate": 1.1736e-05,
      "loss": 0.9339,
      "step": 10330
    },
    {
      "epoch": 413.6,
      "grad_norm": 10.811718940734863,
      "learning_rate": 1.1728000000000002e-05,
      "loss": 0.9666,
      "step": 10340
    },
    {
      "epoch": 414.0,
      "grad_norm": 12.938631057739258,
      "learning_rate": 1.172e-05,
      "loss": 0.9913,
      "step": 10350
    },
    {
      "epoch": 414.4,
      "grad_norm": 6.369314670562744,
      "learning_rate": 1.1712e-05,
      "loss": 0.9347,
      "step": 10360
    },
    {
      "epoch": 414.8,
      "grad_norm": 4.384631156921387,
      "learning_rate": 1.1704000000000002e-05,
      "loss": 0.9235,
      "step": 10370
    },
    {
      "epoch": 415.2,
      "grad_norm": 7.184499263763428,
      "learning_rate": 1.1696000000000001e-05,
      "loss": 0.9335,
      "step": 10380
    },
    {
      "epoch": 415.6,
      "grad_norm": 6.789320945739746,
      "learning_rate": 1.1688000000000002e-05,
      "loss": 0.9561,
      "step": 10390
    },
    {
      "epoch": 416.0,
      "grad_norm": 8.687326431274414,
      "learning_rate": 1.168e-05,
      "loss": 0.9514,
      "step": 10400
    },
    {
      "epoch": 416.4,
      "grad_norm": 15.534889221191406,
      "learning_rate": 1.1672000000000001e-05,
      "loss": 0.9282,
      "step": 10410
    },
    {
      "epoch": 416.8,
      "grad_norm": 3.806025743484497,
      "learning_rate": 1.1664000000000002e-05,
      "loss": 0.9364,
      "step": 10420
    },
    {
      "epoch": 417.2,
      "grad_norm": 7.191806793212891,
      "learning_rate": 1.1656e-05,
      "loss": 0.9283,
      "step": 10430
    },
    {
      "epoch": 417.6,
      "grad_norm": 5.948311805725098,
      "learning_rate": 1.1648000000000001e-05,
      "loss": 0.959,
      "step": 10440
    },
    {
      "epoch": 418.0,
      "grad_norm": 6.148470878601074,
      "learning_rate": 1.164e-05,
      "loss": 0.9504,
      "step": 10450
    },
    {
      "epoch": 418.4,
      "grad_norm": 6.780117988586426,
      "learning_rate": 1.1632000000000001e-05,
      "loss": 0.9589,
      "step": 10460
    },
    {
      "epoch": 418.8,
      "grad_norm": 5.526956081390381,
      "learning_rate": 1.1624000000000003e-05,
      "loss": 0.9489,
      "step": 10470
    },
    {
      "epoch": 419.2,
      "grad_norm": 7.00840950012207,
      "learning_rate": 1.1616e-05,
      "loss": 0.9502,
      "step": 10480
    },
    {
      "epoch": 419.6,
      "grad_norm": 6.725921154022217,
      "learning_rate": 1.1608000000000001e-05,
      "loss": 0.9191,
      "step": 10490
    },
    {
      "epoch": 420.0,
      "grad_norm": 8.058233261108398,
      "learning_rate": 1.16e-05,
      "loss": 0.9453,
      "step": 10500
    },
    {
      "epoch": 420.4,
      "grad_norm": 14.446602821350098,
      "learning_rate": 1.1592000000000002e-05,
      "loss": 0.9551,
      "step": 10510
    },
    {
      "epoch": 420.8,
      "grad_norm": 9.185981750488281,
      "learning_rate": 1.1584000000000001e-05,
      "loss": 0.9287,
      "step": 10520
    },
    {
      "epoch": 421.2,
      "grad_norm": 11.29232406616211,
      "learning_rate": 1.1576e-05,
      "loss": 0.9561,
      "step": 10530
    },
    {
      "epoch": 421.6,
      "grad_norm": 2.915651559829712,
      "learning_rate": 1.1568000000000002e-05,
      "loss": 0.9397,
      "step": 10540
    },
    {
      "epoch": 422.0,
      "grad_norm": 10.599884986877441,
      "learning_rate": 1.156e-05,
      "loss": 0.9601,
      "step": 10550
    },
    {
      "epoch": 422.4,
      "grad_norm": 4.774236679077148,
      "learning_rate": 1.1552e-05,
      "loss": 0.9335,
      "step": 10560
    },
    {
      "epoch": 422.8,
      "grad_norm": 3.6200592517852783,
      "learning_rate": 1.1544000000000002e-05,
      "loss": 0.9322,
      "step": 10570
    },
    {
      "epoch": 423.2,
      "grad_norm": 5.457190990447998,
      "learning_rate": 1.1536000000000001e-05,
      "loss": 0.9606,
      "step": 10580
    },
    {
      "epoch": 423.6,
      "grad_norm": 4.495684623718262,
      "learning_rate": 1.1528000000000002e-05,
      "loss": 0.9331,
      "step": 10590
    },
    {
      "epoch": 424.0,
      "grad_norm": 3.9925389289855957,
      "learning_rate": 1.152e-05,
      "loss": 0.9512,
      "step": 10600
    },
    {
      "epoch": 424.4,
      "grad_norm": 12.313750267028809,
      "learning_rate": 1.1512000000000001e-05,
      "loss": 0.9278,
      "step": 10610
    },
    {
      "epoch": 424.8,
      "grad_norm": 3.8086628913879395,
      "learning_rate": 1.1504000000000002e-05,
      "loss": 0.9565,
      "step": 10620
    },
    {
      "epoch": 425.2,
      "grad_norm": 3.7893640995025635,
      "learning_rate": 1.1496e-05,
      "loss": 0.9541,
      "step": 10630
    },
    {
      "epoch": 425.6,
      "grad_norm": 6.614411354064941,
      "learning_rate": 1.1488e-05,
      "loss": 0.9737,
      "step": 10640
    },
    {
      "epoch": 426.0,
      "grad_norm": 8.565954208374023,
      "learning_rate": 1.148e-05,
      "loss": 0.9384,
      "step": 10650
    },
    {
      "epoch": 426.4,
      "grad_norm": 8.077295303344727,
      "learning_rate": 1.1472000000000001e-05,
      "loss": 0.9064,
      "step": 10660
    },
    {
      "epoch": 426.8,
      "grad_norm": 7.496288776397705,
      "learning_rate": 1.1464000000000002e-05,
      "loss": 0.9376,
      "step": 10670
    },
    {
      "epoch": 427.2,
      "grad_norm": 10.318161964416504,
      "learning_rate": 1.1456e-05,
      "loss": 0.9361,
      "step": 10680
    },
    {
      "epoch": 427.6,
      "grad_norm": 7.6413164138793945,
      "learning_rate": 1.1448000000000001e-05,
      "loss": 0.9377,
      "step": 10690
    },
    {
      "epoch": 428.0,
      "grad_norm": 7.73715353012085,
      "learning_rate": 1.144e-05,
      "loss": 0.9634,
      "step": 10700
    },
    {
      "epoch": 428.4,
      "grad_norm": 5.895069599151611,
      "learning_rate": 1.1432000000000002e-05,
      "loss": 0.9337,
      "step": 10710
    },
    {
      "epoch": 428.8,
      "grad_norm": 7.301431179046631,
      "learning_rate": 1.1424000000000001e-05,
      "loss": 0.9409,
      "step": 10720
    },
    {
      "epoch": 429.2,
      "grad_norm": 5.884690761566162,
      "learning_rate": 1.1416e-05,
      "loss": 0.9506,
      "step": 10730
    },
    {
      "epoch": 429.6,
      "grad_norm": 9.645252227783203,
      "learning_rate": 1.1408000000000002e-05,
      "loss": 0.9436,
      "step": 10740
    },
    {
      "epoch": 430.0,
      "grad_norm": 6.4546685218811035,
      "learning_rate": 1.14e-05,
      "loss": 0.9165,
      "step": 10750
    },
    {
      "epoch": 430.4,
      "grad_norm": 12.349905967712402,
      "learning_rate": 1.1392e-05,
      "loss": 0.9406,
      "step": 10760
    },
    {
      "epoch": 430.8,
      "grad_norm": 7.410367488861084,
      "learning_rate": 1.1384000000000001e-05,
      "loss": 0.9261,
      "step": 10770
    },
    {
      "epoch": 431.2,
      "grad_norm": 9.335704803466797,
      "learning_rate": 1.1376000000000001e-05,
      "loss": 0.9489,
      "step": 10780
    },
    {
      "epoch": 431.6,
      "grad_norm": 7.407405853271484,
      "learning_rate": 1.1368000000000002e-05,
      "loss": 0.9211,
      "step": 10790
    },
    {
      "epoch": 432.0,
      "grad_norm": 4.240903854370117,
      "learning_rate": 1.136e-05,
      "loss": 0.9433,
      "step": 10800
    },
    {
      "epoch": 432.4,
      "grad_norm": 8.298331260681152,
      "learning_rate": 1.1352e-05,
      "loss": 0.9464,
      "step": 10810
    },
    {
      "epoch": 432.8,
      "grad_norm": 6.0573320388793945,
      "learning_rate": 1.1344000000000002e-05,
      "loss": 0.9448,
      "step": 10820
    },
    {
      "epoch": 433.2,
      "grad_norm": 9.114208221435547,
      "learning_rate": 1.1336e-05,
      "loss": 0.9125,
      "step": 10830
    },
    {
      "epoch": 433.6,
      "grad_norm": 6.217509746551514,
      "learning_rate": 1.1328e-05,
      "loss": 0.9109,
      "step": 10840
    },
    {
      "epoch": 434.0,
      "grad_norm": 5.651286602020264,
      "learning_rate": 1.132e-05,
      "loss": 0.9228,
      "step": 10850
    },
    {
      "epoch": 434.4,
      "grad_norm": 10.157960891723633,
      "learning_rate": 1.1312000000000001e-05,
      "loss": 0.9257,
      "step": 10860
    },
    {
      "epoch": 434.8,
      "grad_norm": 5.367369651794434,
      "learning_rate": 1.1304000000000002e-05,
      "loss": 0.9327,
      "step": 10870
    },
    {
      "epoch": 435.2,
      "grad_norm": 8.517744064331055,
      "learning_rate": 1.1296e-05,
      "loss": 0.9166,
      "step": 10880
    },
    {
      "epoch": 435.6,
      "grad_norm": 6.302770614624023,
      "learning_rate": 1.1288000000000001e-05,
      "loss": 0.9764,
      "step": 10890
    },
    {
      "epoch": 436.0,
      "grad_norm": 4.021233558654785,
      "learning_rate": 1.128e-05,
      "loss": 0.9386,
      "step": 10900
    },
    {
      "epoch": 436.4,
      "grad_norm": 8.247451782226562,
      "learning_rate": 1.1272000000000002e-05,
      "loss": 0.9453,
      "step": 10910
    },
    {
      "epoch": 436.8,
      "grad_norm": 10.485445976257324,
      "learning_rate": 1.1264000000000001e-05,
      "loss": 0.914,
      "step": 10920
    },
    {
      "epoch": 437.2,
      "grad_norm": 13.583755493164062,
      "learning_rate": 1.1256e-05,
      "loss": 0.9227,
      "step": 10930
    },
    {
      "epoch": 437.6,
      "grad_norm": 9.79736042022705,
      "learning_rate": 1.1248000000000001e-05,
      "loss": 0.9319,
      "step": 10940
    },
    {
      "epoch": 438.0,
      "grad_norm": 4.26670503616333,
      "learning_rate": 1.1240000000000002e-05,
      "loss": 0.9243,
      "step": 10950
    },
    {
      "epoch": 438.4,
      "grad_norm": 9.008101463317871,
      "learning_rate": 1.1232e-05,
      "loss": 0.9239,
      "step": 10960
    },
    {
      "epoch": 438.8,
      "grad_norm": 7.263104438781738,
      "learning_rate": 1.1224000000000001e-05,
      "loss": 0.917,
      "step": 10970
    },
    {
      "epoch": 439.2,
      "grad_norm": 5.301129341125488,
      "learning_rate": 1.1216e-05,
      "loss": 0.9494,
      "step": 10980
    },
    {
      "epoch": 439.6,
      "grad_norm": 4.51262092590332,
      "learning_rate": 1.1208000000000002e-05,
      "loss": 0.913,
      "step": 10990
    },
    {
      "epoch": 440.0,
      "grad_norm": 5.015806198120117,
      "learning_rate": 1.1200000000000001e-05,
      "loss": 0.9213,
      "step": 11000
    },
    {
      "epoch": 440.4,
      "grad_norm": 7.045461654663086,
      "learning_rate": 1.1192e-05,
      "loss": 0.9337,
      "step": 11010
    },
    {
      "epoch": 440.8,
      "grad_norm": 5.470759391784668,
      "learning_rate": 1.1184000000000002e-05,
      "loss": 0.9105,
      "step": 11020
    },
    {
      "epoch": 441.2,
      "grad_norm": 4.65891695022583,
      "learning_rate": 1.1176e-05,
      "loss": 0.9068,
      "step": 11030
    },
    {
      "epoch": 441.6,
      "grad_norm": 6.082299709320068,
      "learning_rate": 1.1168e-05,
      "loss": 0.8955,
      "step": 11040
    },
    {
      "epoch": 442.0,
      "grad_norm": 4.7729644775390625,
      "learning_rate": 1.1160000000000002e-05,
      "loss": 0.978,
      "step": 11050
    },
    {
      "epoch": 442.4,
      "grad_norm": 5.147998809814453,
      "learning_rate": 1.1152000000000001e-05,
      "loss": 0.9173,
      "step": 11060
    },
    {
      "epoch": 442.8,
      "grad_norm": 10.547391891479492,
      "learning_rate": 1.1144000000000002e-05,
      "loss": 0.9178,
      "step": 11070
    },
    {
      "epoch": 443.2,
      "grad_norm": 7.878571510314941,
      "learning_rate": 1.1136e-05,
      "loss": 0.9245,
      "step": 11080
    },
    {
      "epoch": 443.6,
      "grad_norm": 6.902313709259033,
      "learning_rate": 1.1128000000000001e-05,
      "loss": 0.9581,
      "step": 11090
    },
    {
      "epoch": 444.0,
      "grad_norm": 5.133594036102295,
      "learning_rate": 1.1120000000000002e-05,
      "loss": 0.9549,
      "step": 11100
    },
    {
      "epoch": 444.4,
      "grad_norm": 16.797103881835938,
      "learning_rate": 1.1112000000000001e-05,
      "loss": 0.9448,
      "step": 11110
    },
    {
      "epoch": 444.8,
      "grad_norm": 6.324178695678711,
      "learning_rate": 1.1104e-05,
      "loss": 0.9229,
      "step": 11120
    },
    {
      "epoch": 445.2,
      "grad_norm": 6.603699684143066,
      "learning_rate": 1.1096e-05,
      "loss": 0.9162,
      "step": 11130
    },
    {
      "epoch": 445.6,
      "grad_norm": 11.638371467590332,
      "learning_rate": 1.1088000000000001e-05,
      "loss": 0.9149,
      "step": 11140
    },
    {
      "epoch": 446.0,
      "grad_norm": 7.946211814880371,
      "learning_rate": 1.1080000000000002e-05,
      "loss": 0.9249,
      "step": 11150
    },
    {
      "epoch": 446.4,
      "grad_norm": 9.219162940979004,
      "learning_rate": 1.1072e-05,
      "loss": 0.955,
      "step": 11160
    },
    {
      "epoch": 446.8,
      "grad_norm": 9.230554580688477,
      "learning_rate": 1.1064000000000001e-05,
      "loss": 0.9418,
      "step": 11170
    },
    {
      "epoch": 447.2,
      "grad_norm": 10.908109664916992,
      "learning_rate": 1.1056e-05,
      "loss": 0.9358,
      "step": 11180
    },
    {
      "epoch": 447.6,
      "grad_norm": 8.66069507598877,
      "learning_rate": 1.1048000000000002e-05,
      "loss": 0.9315,
      "step": 11190
    },
    {
      "epoch": 448.0,
      "grad_norm": 8.149948120117188,
      "learning_rate": 1.1040000000000001e-05,
      "loss": 0.9226,
      "step": 11200
    },
    {
      "epoch": 448.4,
      "grad_norm": 6.42592191696167,
      "learning_rate": 1.1032e-05,
      "loss": 0.8948,
      "step": 11210
    },
    {
      "epoch": 448.8,
      "grad_norm": 3.4263877868652344,
      "learning_rate": 1.1024000000000002e-05,
      "loss": 0.9567,
      "step": 11220
    },
    {
      "epoch": 449.2,
      "grad_norm": 6.988955974578857,
      "learning_rate": 1.1016e-05,
      "loss": 0.9476,
      "step": 11230
    },
    {
      "epoch": 449.6,
      "grad_norm": 8.513665199279785,
      "learning_rate": 1.1008e-05,
      "loss": 0.9523,
      "step": 11240
    },
    {
      "epoch": 450.0,
      "grad_norm": 8.355485916137695,
      "learning_rate": 1.1000000000000001e-05,
      "loss": 0.9458,
      "step": 11250
    },
    {
      "epoch": 450.4,
      "grad_norm": 4.044344902038574,
      "learning_rate": 1.0992e-05,
      "loss": 0.9149,
      "step": 11260
    },
    {
      "epoch": 450.8,
      "grad_norm": 6.647277355194092,
      "learning_rate": 1.0984000000000002e-05,
      "loss": 0.9066,
      "step": 11270
    },
    {
      "epoch": 451.2,
      "grad_norm": 7.685773849487305,
      "learning_rate": 1.0976e-05,
      "loss": 0.9483,
      "step": 11280
    },
    {
      "epoch": 451.6,
      "grad_norm": 9.215953826904297,
      "learning_rate": 1.0968e-05,
      "loss": 0.9393,
      "step": 11290
    },
    {
      "epoch": 452.0,
      "grad_norm": 9.589088439941406,
      "learning_rate": 1.0960000000000002e-05,
      "loss": 0.9108,
      "step": 11300
    },
    {
      "epoch": 452.4,
      "grad_norm": 3.4536678791046143,
      "learning_rate": 1.0952000000000001e-05,
      "loss": 0.8963,
      "step": 11310
    },
    {
      "epoch": 452.8,
      "grad_norm": 9.320198059082031,
      "learning_rate": 1.0944e-05,
      "loss": 0.9397,
      "step": 11320
    },
    {
      "epoch": 453.2,
      "grad_norm": 5.436698913574219,
      "learning_rate": 1.0936e-05,
      "loss": 0.9191,
      "step": 11330
    },
    {
      "epoch": 453.6,
      "grad_norm": 8.519853591918945,
      "learning_rate": 1.0928000000000001e-05,
      "loss": 0.9138,
      "step": 11340
    },
    {
      "epoch": 454.0,
      "grad_norm": 4.016661167144775,
      "learning_rate": 1.0920000000000002e-05,
      "loss": 0.8993,
      "step": 11350
    },
    {
      "epoch": 454.4,
      "grad_norm": 3.2941641807556152,
      "learning_rate": 1.0912e-05,
      "loss": 0.9403,
      "step": 11360
    },
    {
      "epoch": 454.8,
      "grad_norm": 5.668547630310059,
      "learning_rate": 1.0904000000000001e-05,
      "loss": 0.9313,
      "step": 11370
    },
    {
      "epoch": 455.2,
      "grad_norm": 8.55693244934082,
      "learning_rate": 1.0896e-05,
      "loss": 0.9036,
      "step": 11380
    },
    {
      "epoch": 455.6,
      "grad_norm": 11.908750534057617,
      "learning_rate": 1.0888000000000001e-05,
      "loss": 0.9354,
      "step": 11390
    },
    {
      "epoch": 456.0,
      "grad_norm": 7.5994791984558105,
      "learning_rate": 1.0880000000000001e-05,
      "loss": 0.9297,
      "step": 11400
    },
    {
      "epoch": 456.4,
      "grad_norm": 7.07451868057251,
      "learning_rate": 1.0872e-05,
      "loss": 0.9047,
      "step": 11410
    },
    {
      "epoch": 456.8,
      "grad_norm": 3.0735130310058594,
      "learning_rate": 1.0864000000000001e-05,
      "loss": 0.9519,
      "step": 11420
    },
    {
      "epoch": 457.2,
      "grad_norm": 8.090380668640137,
      "learning_rate": 1.0855999999999999e-05,
      "loss": 0.9519,
      "step": 11430
    },
    {
      "epoch": 457.6,
      "grad_norm": 8.0433349609375,
      "learning_rate": 1.0848e-05,
      "loss": 0.9059,
      "step": 11440
    },
    {
      "epoch": 458.0,
      "grad_norm": 9.494144439697266,
      "learning_rate": 1.0840000000000001e-05,
      "loss": 0.954,
      "step": 11450
    },
    {
      "epoch": 458.4,
      "grad_norm": 5.556251525878906,
      "learning_rate": 1.0832e-05,
      "loss": 0.9062,
      "step": 11460
    },
    {
      "epoch": 458.8,
      "grad_norm": 4.03452205657959,
      "learning_rate": 1.0824000000000002e-05,
      "loss": 0.9367,
      "step": 11470
    },
    {
      "epoch": 459.2,
      "grad_norm": 4.201216697692871,
      "learning_rate": 1.0816e-05,
      "loss": 0.8921,
      "step": 11480
    },
    {
      "epoch": 459.6,
      "grad_norm": 3.175889253616333,
      "learning_rate": 1.0808e-05,
      "loss": 0.9108,
      "step": 11490
    },
    {
      "epoch": 460.0,
      "grad_norm": 6.652249813079834,
      "learning_rate": 1.0800000000000002e-05,
      "loss": 0.943,
      "step": 11500
    },
    {
      "epoch": 460.4,
      "grad_norm": 9.819724082946777,
      "learning_rate": 1.0792000000000001e-05,
      "loss": 0.9329,
      "step": 11510
    },
    {
      "epoch": 460.8,
      "grad_norm": 5.254106521606445,
      "learning_rate": 1.0784e-05,
      "loss": 0.8903,
      "step": 11520
    },
    {
      "epoch": 461.2,
      "grad_norm": 5.5867018699646,
      "learning_rate": 1.0776e-05,
      "loss": 0.9308,
      "step": 11530
    },
    {
      "epoch": 461.6,
      "grad_norm": 10.98245906829834,
      "learning_rate": 1.0768000000000001e-05,
      "loss": 0.9255,
      "step": 11540
    },
    {
      "epoch": 462.0,
      "grad_norm": 6.728368282318115,
      "learning_rate": 1.0760000000000002e-05,
      "loss": 0.9247,
      "step": 11550
    },
    {
      "epoch": 462.4,
      "grad_norm": 5.662182807922363,
      "learning_rate": 1.0752e-05,
      "loss": 0.9304,
      "step": 11560
    },
    {
      "epoch": 462.8,
      "grad_norm": 11.187726020812988,
      "learning_rate": 1.0744e-05,
      "loss": 0.9205,
      "step": 11570
    },
    {
      "epoch": 463.2,
      "grad_norm": 14.555002212524414,
      "learning_rate": 1.0736000000000002e-05,
      "loss": 0.9177,
      "step": 11580
    },
    {
      "epoch": 463.6,
      "grad_norm": 10.433767318725586,
      "learning_rate": 1.0728000000000001e-05,
      "loss": 0.9033,
      "step": 11590
    },
    {
      "epoch": 464.0,
      "grad_norm": 4.8765082359313965,
      "learning_rate": 1.072e-05,
      "loss": 0.916,
      "step": 11600
    },
    {
      "epoch": 464.4,
      "grad_norm": 4.900721549987793,
      "learning_rate": 1.0712e-05,
      "loss": 0.9148,
      "step": 11610
    },
    {
      "epoch": 464.8,
      "grad_norm": 6.633571624755859,
      "learning_rate": 1.0704000000000001e-05,
      "loss": 0.9543,
      "step": 11620
    },
    {
      "epoch": 465.2,
      "grad_norm": 9.904447555541992,
      "learning_rate": 1.0696000000000002e-05,
      "loss": 0.9018,
      "step": 11630
    },
    {
      "epoch": 465.6,
      "grad_norm": 3.724461317062378,
      "learning_rate": 1.0688e-05,
      "loss": 0.9119,
      "step": 11640
    },
    {
      "epoch": 466.0,
      "grad_norm": 5.2551727294921875,
      "learning_rate": 1.0680000000000001e-05,
      "loss": 0.9329,
      "step": 11650
    },
    {
      "epoch": 466.4,
      "grad_norm": 6.956455707550049,
      "learning_rate": 1.0672e-05,
      "loss": 0.9026,
      "step": 11660
    },
    {
      "epoch": 466.8,
      "grad_norm": 9.538843154907227,
      "learning_rate": 1.0664000000000002e-05,
      "loss": 0.9151,
      "step": 11670
    },
    {
      "epoch": 467.2,
      "grad_norm": 4.21243143081665,
      "learning_rate": 1.0656000000000003e-05,
      "loss": 0.9398,
      "step": 11680
    },
    {
      "epoch": 467.6,
      "grad_norm": 7.728923797607422,
      "learning_rate": 1.0648e-05,
      "loss": 0.9114,
      "step": 11690
    },
    {
      "epoch": 468.0,
      "grad_norm": 7.547252655029297,
      "learning_rate": 1.0640000000000001e-05,
      "loss": 0.9244,
      "step": 11700
    },
    {
      "epoch": 468.4,
      "grad_norm": 4.912901401519775,
      "learning_rate": 1.0632000000000001e-05,
      "loss": 0.8941,
      "step": 11710
    },
    {
      "epoch": 468.8,
      "grad_norm": 12.001790046691895,
      "learning_rate": 1.0624e-05,
      "loss": 0.9018,
      "step": 11720
    },
    {
      "epoch": 469.2,
      "grad_norm": 3.4661262035369873,
      "learning_rate": 1.0616000000000001e-05,
      "loss": 0.9251,
      "step": 11730
    },
    {
      "epoch": 469.6,
      "grad_norm": 13.48709487915039,
      "learning_rate": 1.0608e-05,
      "loss": 0.9053,
      "step": 11740
    },
    {
      "epoch": 470.0,
      "grad_norm": 12.788851737976074,
      "learning_rate": 1.0600000000000002e-05,
      "loss": 0.8842,
      "step": 11750
    },
    {
      "epoch": 470.4,
      "grad_norm": 10.84079647064209,
      "learning_rate": 1.0592e-05,
      "loss": 0.9418,
      "step": 11760
    },
    {
      "epoch": 470.8,
      "grad_norm": 11.947476387023926,
      "learning_rate": 1.0584e-05,
      "loss": 0.9113,
      "step": 11770
    },
    {
      "epoch": 471.2,
      "grad_norm": 8.76794147491455,
      "learning_rate": 1.0576000000000002e-05,
      "loss": 0.8982,
      "step": 11780
    },
    {
      "epoch": 471.6,
      "grad_norm": 10.614767074584961,
      "learning_rate": 1.0568000000000001e-05,
      "loss": 0.9155,
      "step": 11790
    },
    {
      "epoch": 472.0,
      "grad_norm": 4.853029727935791,
      "learning_rate": 1.056e-05,
      "loss": 0.9215,
      "step": 11800
    },
    {
      "epoch": 472.4,
      "grad_norm": 5.21024227142334,
      "learning_rate": 1.0552e-05,
      "loss": 0.8915,
      "step": 11810
    },
    {
      "epoch": 472.8,
      "grad_norm": 5.297689437866211,
      "learning_rate": 1.0544000000000001e-05,
      "loss": 0.8841,
      "step": 11820
    },
    {
      "epoch": 473.2,
      "grad_norm": 9.174338340759277,
      "learning_rate": 1.0536000000000002e-05,
      "loss": 0.9294,
      "step": 11830
    },
    {
      "epoch": 473.6,
      "grad_norm": 8.72472858428955,
      "learning_rate": 1.0528e-05,
      "loss": 0.9379,
      "step": 11840
    },
    {
      "epoch": 474.0,
      "grad_norm": 10.70469856262207,
      "learning_rate": 1.0520000000000001e-05,
      "loss": 0.9151,
      "step": 11850
    },
    {
      "epoch": 474.4,
      "grad_norm": 11.128141403198242,
      "learning_rate": 1.0512e-05,
      "loss": 0.9285,
      "step": 11860
    },
    {
      "epoch": 474.8,
      "grad_norm": 5.079032897949219,
      "learning_rate": 1.0504000000000001e-05,
      "loss": 0.9118,
      "step": 11870
    },
    {
      "epoch": 475.2,
      "grad_norm": 12.66551399230957,
      "learning_rate": 1.0496000000000003e-05,
      "loss": 0.9117,
      "step": 11880
    },
    {
      "epoch": 475.6,
      "grad_norm": 18.483654022216797,
      "learning_rate": 1.0488e-05,
      "loss": 0.9262,
      "step": 11890
    },
    {
      "epoch": 476.0,
      "grad_norm": 9.570357322692871,
      "learning_rate": 1.0480000000000001e-05,
      "loss": 0.9049,
      "step": 11900
    },
    {
      "epoch": 476.4,
      "grad_norm": 7.874514579772949,
      "learning_rate": 1.0472e-05,
      "loss": 0.8773,
      "step": 11910
    },
    {
      "epoch": 476.8,
      "grad_norm": 8.950155258178711,
      "learning_rate": 1.0464e-05,
      "loss": 0.912,
      "step": 11920
    },
    {
      "epoch": 477.2,
      "grad_norm": 11.52975082397461,
      "learning_rate": 1.0456000000000001e-05,
      "loss": 0.9095,
      "step": 11930
    },
    {
      "epoch": 477.6,
      "grad_norm": 19.059284210205078,
      "learning_rate": 1.0448e-05,
      "loss": 0.9239,
      "step": 11940
    },
    {
      "epoch": 478.0,
      "grad_norm": 5.302560329437256,
      "learning_rate": 1.0440000000000002e-05,
      "loss": 0.9013,
      "step": 11950
    },
    {
      "epoch": 478.4,
      "grad_norm": 5.748201370239258,
      "learning_rate": 1.0432e-05,
      "loss": 0.906,
      "step": 11960
    },
    {
      "epoch": 478.8,
      "grad_norm": 5.215132236480713,
      "learning_rate": 1.0424e-05,
      "loss": 0.8801,
      "step": 11970
    },
    {
      "epoch": 479.2,
      "grad_norm": 6.43977689743042,
      "learning_rate": 1.0416000000000002e-05,
      "loss": 0.9079,
      "step": 11980
    },
    {
      "epoch": 479.6,
      "grad_norm": 5.046307563781738,
      "learning_rate": 1.0408000000000001e-05,
      "loss": 0.9144,
      "step": 11990
    },
    {
      "epoch": 480.0,
      "grad_norm": 10.81861686706543,
      "learning_rate": 1.04e-05,
      "loss": 0.8946,
      "step": 12000
    },
    {
      "epoch": 480.4,
      "grad_norm": 3.8506977558135986,
      "learning_rate": 1.0392e-05,
      "loss": 0.9151,
      "step": 12010
    },
    {
      "epoch": 480.8,
      "grad_norm": 6.464861869812012,
      "learning_rate": 1.0384000000000001e-05,
      "loss": 0.8918,
      "step": 12020
    },
    {
      "epoch": 481.2,
      "grad_norm": 9.515730857849121,
      "learning_rate": 1.0376000000000002e-05,
      "loss": 0.8635,
      "step": 12030
    },
    {
      "epoch": 481.6,
      "grad_norm": 8.732199668884277,
      "learning_rate": 1.0368e-05,
      "loss": 0.9255,
      "step": 12040
    },
    {
      "epoch": 482.0,
      "grad_norm": 13.856972694396973,
      "learning_rate": 1.036e-05,
      "loss": 0.9445,
      "step": 12050
    },
    {
      "epoch": 482.4,
      "grad_norm": 14.025249481201172,
      "learning_rate": 1.0352e-05,
      "loss": 0.9151,
      "step": 12060
    },
    {
      "epoch": 482.8,
      "grad_norm": 4.947164535522461,
      "learning_rate": 1.0344000000000001e-05,
      "loss": 0.9238,
      "step": 12070
    },
    {
      "epoch": 483.2,
      "grad_norm": 4.603700637817383,
      "learning_rate": 1.0336000000000002e-05,
      "loss": 0.912,
      "step": 12080
    },
    {
      "epoch": 483.6,
      "grad_norm": 10.798381805419922,
      "learning_rate": 1.0328e-05,
      "loss": 0.9095,
      "step": 12090
    },
    {
      "epoch": 484.0,
      "grad_norm": 11.722487449645996,
      "learning_rate": 1.0320000000000001e-05,
      "loss": 0.8912,
      "step": 12100
    },
    {
      "epoch": 484.4,
      "grad_norm": 3.804624080657959,
      "learning_rate": 1.0312e-05,
      "loss": 0.8879,
      "step": 12110
    },
    {
      "epoch": 484.8,
      "grad_norm": 10.502052307128906,
      "learning_rate": 1.0304e-05,
      "loss": 0.9007,
      "step": 12120
    },
    {
      "epoch": 485.2,
      "grad_norm": 4.4810895919799805,
      "learning_rate": 1.0296000000000001e-05,
      "loss": 0.878,
      "step": 12130
    },
    {
      "epoch": 485.6,
      "grad_norm": 4.98706579208374,
      "learning_rate": 1.0288e-05,
      "loss": 0.8856,
      "step": 12140
    },
    {
      "epoch": 486.0,
      "grad_norm": 11.356196403503418,
      "learning_rate": 1.0280000000000002e-05,
      "loss": 0.9218,
      "step": 12150
    },
    {
      "epoch": 486.4,
      "grad_norm": 4.799768924713135,
      "learning_rate": 1.0272e-05,
      "loss": 0.8994,
      "step": 12160
    },
    {
      "epoch": 486.8,
      "grad_norm": 11.511622428894043,
      "learning_rate": 1.0264e-05,
      "loss": 0.8819,
      "step": 12170
    },
    {
      "epoch": 487.2,
      "grad_norm": 4.569256782531738,
      "learning_rate": 1.0256000000000001e-05,
      "loss": 0.9124,
      "step": 12180
    },
    {
      "epoch": 487.6,
      "grad_norm": 11.422649383544922,
      "learning_rate": 1.0248e-05,
      "loss": 0.9222,
      "step": 12190
    },
    {
      "epoch": 488.0,
      "grad_norm": 13.629220962524414,
      "learning_rate": 1.024e-05,
      "loss": 0.9102,
      "step": 12200
    },
    {
      "epoch": 488.4,
      "grad_norm": 7.200799942016602,
      "learning_rate": 1.0232000000000001e-05,
      "loss": 0.8678,
      "step": 12210
    },
    {
      "epoch": 488.8,
      "grad_norm": 9.766206741333008,
      "learning_rate": 1.0224e-05,
      "loss": 0.9171,
      "step": 12220
    },
    {
      "epoch": 489.2,
      "grad_norm": 13.010137557983398,
      "learning_rate": 1.0216000000000002e-05,
      "loss": 0.8907,
      "step": 12230
    },
    {
      "epoch": 489.6,
      "grad_norm": 12.265397071838379,
      "learning_rate": 1.0208e-05,
      "loss": 0.8764,
      "step": 12240
    },
    {
      "epoch": 490.0,
      "grad_norm": 10.373847007751465,
      "learning_rate": 1.02e-05,
      "loss": 0.9038,
      "step": 12250
    },
    {
      "epoch": 490.4,
      "grad_norm": 9.038689613342285,
      "learning_rate": 1.0192000000000002e-05,
      "loss": 0.9049,
      "step": 12260
    },
    {
      "epoch": 490.8,
      "grad_norm": 8.018638610839844,
      "learning_rate": 1.0184000000000001e-05,
      "loss": 0.9065,
      "step": 12270
    },
    {
      "epoch": 491.2,
      "grad_norm": 4.366204738616943,
      "learning_rate": 1.0176000000000002e-05,
      "loss": 0.8768,
      "step": 12280
    },
    {
      "epoch": 491.6,
      "grad_norm": 9.044641494750977,
      "learning_rate": 1.0168e-05,
      "loss": 0.9333,
      "step": 12290
    },
    {
      "epoch": 492.0,
      "grad_norm": 4.907347202301025,
      "learning_rate": 1.0160000000000001e-05,
      "loss": 0.9105,
      "step": 12300
    },
    {
      "epoch": 492.4,
      "grad_norm": 5.850327014923096,
      "learning_rate": 1.0152000000000002e-05,
      "loss": 0.9076,
      "step": 12310
    },
    {
      "epoch": 492.8,
      "grad_norm": 4.021200656890869,
      "learning_rate": 1.0144e-05,
      "loss": 0.8953,
      "step": 12320
    },
    {
      "epoch": 493.2,
      "grad_norm": 11.94911003112793,
      "learning_rate": 1.0136000000000001e-05,
      "loss": 0.8991,
      "step": 12330
    },
    {
      "epoch": 493.6,
      "grad_norm": 7.2105793952941895,
      "learning_rate": 1.0128e-05,
      "loss": 0.9099,
      "step": 12340
    },
    {
      "epoch": 494.0,
      "grad_norm": 6.174600601196289,
      "learning_rate": 1.0120000000000001e-05,
      "loss": 0.9028,
      "step": 12350
    },
    {
      "epoch": 494.4,
      "grad_norm": 4.323512077331543,
      "learning_rate": 1.0112000000000002e-05,
      "loss": 0.8962,
      "step": 12360
    },
    {
      "epoch": 494.8,
      "grad_norm": 4.71349573135376,
      "learning_rate": 1.0104e-05,
      "loss": 0.8873,
      "step": 12370
    },
    {
      "epoch": 495.2,
      "grad_norm": 10.439464569091797,
      "learning_rate": 1.0096000000000001e-05,
      "loss": 0.9013,
      "step": 12380
    },
    {
      "epoch": 495.6,
      "grad_norm": 6.707018852233887,
      "learning_rate": 1.0088e-05,
      "loss": 0.8949,
      "step": 12390
    },
    {
      "epoch": 496.0,
      "grad_norm": 13.141215324401855,
      "learning_rate": 1.008e-05,
      "loss": 0.8906,
      "step": 12400
    },
    {
      "epoch": 496.4,
      "grad_norm": 9.39615535736084,
      "learning_rate": 1.0072000000000001e-05,
      "loss": 0.9012,
      "step": 12410
    },
    {
      "epoch": 496.8,
      "grad_norm": 10.619864463806152,
      "learning_rate": 1.0064e-05,
      "loss": 0.9067,
      "step": 12420
    },
    {
      "epoch": 497.2,
      "grad_norm": 16.682655334472656,
      "learning_rate": 1.0056000000000002e-05,
      "loss": 0.9396,
      "step": 12430
    },
    {
      "epoch": 497.6,
      "grad_norm": 12.803886413574219,
      "learning_rate": 1.0048e-05,
      "loss": 0.8818,
      "step": 12440
    },
    {
      "epoch": 498.0,
      "grad_norm": 7.019305229187012,
      "learning_rate": 1.004e-05,
      "loss": 0.8743,
      "step": 12450
    },
    {
      "epoch": 498.4,
      "grad_norm": 4.791135311126709,
      "learning_rate": 1.0032000000000002e-05,
      "loss": 0.892,
      "step": 12460
    },
    {
      "epoch": 498.8,
      "grad_norm": 6.02333927154541,
      "learning_rate": 1.0024000000000001e-05,
      "loss": 0.9119,
      "step": 12470
    },
    {
      "epoch": 499.2,
      "grad_norm": 9.41310977935791,
      "learning_rate": 1.0016000000000002e-05,
      "loss": 0.8834,
      "step": 12480
    },
    {
      "epoch": 499.6,
      "grad_norm": 6.443389892578125,
      "learning_rate": 1.0008e-05,
      "loss": 0.8972,
      "step": 12490
    },
    {
      "epoch": 500.0,
      "grad_norm": 6.076493740081787,
      "learning_rate": 1e-05,
      "loss": 0.9109,
      "step": 12500
    },
    {
      "epoch": 500.4,
      "grad_norm": 13.899380683898926,
      "learning_rate": 9.992e-06,
      "loss": 0.877,
      "step": 12510
    },
    {
      "epoch": 500.8,
      "grad_norm": 8.452393531799316,
      "learning_rate": 9.984e-06,
      "loss": 0.8785,
      "step": 12520
    },
    {
      "epoch": 501.2,
      "grad_norm": 13.46312427520752,
      "learning_rate": 9.976e-06,
      "loss": 0.8856,
      "step": 12530
    },
    {
      "epoch": 501.6,
      "grad_norm": 16.73456382751465,
      "learning_rate": 9.968000000000002e-06,
      "loss": 0.9066,
      "step": 12540
    },
    {
      "epoch": 502.0,
      "grad_norm": 4.146510601043701,
      "learning_rate": 9.960000000000001e-06,
      "loss": 0.8691,
      "step": 12550
    },
    {
      "epoch": 502.4,
      "grad_norm": 9.944252967834473,
      "learning_rate": 9.952e-06,
      "loss": 0.8666,
      "step": 12560
    },
    {
      "epoch": 502.8,
      "grad_norm": 16.337827682495117,
      "learning_rate": 9.944e-06,
      "loss": 0.9289,
      "step": 12570
    },
    {
      "epoch": 503.2,
      "grad_norm": 8.566640853881836,
      "learning_rate": 9.936000000000001e-06,
      "loss": 0.911,
      "step": 12580
    },
    {
      "epoch": 503.6,
      "grad_norm": 6.952681541442871,
      "learning_rate": 9.928e-06,
      "loss": 0.8878,
      "step": 12590
    },
    {
      "epoch": 504.0,
      "grad_norm": 3.5436716079711914,
      "learning_rate": 9.920000000000002e-06,
      "loss": 0.9107,
      "step": 12600
    },
    {
      "epoch": 504.4,
      "grad_norm": 19.634796142578125,
      "learning_rate": 9.912000000000001e-06,
      "loss": 0.9053,
      "step": 12610
    },
    {
      "epoch": 504.8,
      "grad_norm": 5.981155872344971,
      "learning_rate": 9.904e-06,
      "loss": 0.9075,
      "step": 12620
    },
    {
      "epoch": 505.2,
      "grad_norm": 18.4377498626709,
      "learning_rate": 9.896000000000001e-06,
      "loss": 0.9029,
      "step": 12630
    },
    {
      "epoch": 505.6,
      "grad_norm": 5.380837440490723,
      "learning_rate": 9.888000000000001e-06,
      "loss": 0.8831,
      "step": 12640
    },
    {
      "epoch": 506.0,
      "grad_norm": 10.800287246704102,
      "learning_rate": 9.88e-06,
      "loss": 0.9221,
      "step": 12650
    },
    {
      "epoch": 506.4,
      "grad_norm": 9.492287635803223,
      "learning_rate": 9.872e-06,
      "loss": 0.8834,
      "step": 12660
    },
    {
      "epoch": 506.8,
      "grad_norm": 9.495424270629883,
      "learning_rate": 9.864e-06,
      "loss": 0.9158,
      "step": 12670
    },
    {
      "epoch": 507.2,
      "grad_norm": 8.530467987060547,
      "learning_rate": 9.856000000000002e-06,
      "loss": 0.8939,
      "step": 12680
    },
    {
      "epoch": 507.6,
      "grad_norm": 11.118013381958008,
      "learning_rate": 9.848000000000001e-06,
      "loss": 0.8762,
      "step": 12690
    },
    {
      "epoch": 508.0,
      "grad_norm": 12.974164009094238,
      "learning_rate": 9.84e-06,
      "loss": 0.8869,
      "step": 12700
    },
    {
      "epoch": 508.4,
      "grad_norm": 8.76916790008545,
      "learning_rate": 9.832e-06,
      "loss": 0.9061,
      "step": 12710
    },
    {
      "epoch": 508.8,
      "grad_norm": 4.811650276184082,
      "learning_rate": 9.824000000000001e-06,
      "loss": 0.8966,
      "step": 12720
    },
    {
      "epoch": 509.2,
      "grad_norm": 15.843213081359863,
      "learning_rate": 9.816e-06,
      "loss": 0.8825,
      "step": 12730
    },
    {
      "epoch": 509.6,
      "grad_norm": 13.821710586547852,
      "learning_rate": 9.808000000000002e-06,
      "loss": 0.8914,
      "step": 12740
    },
    {
      "epoch": 510.0,
      "grad_norm": 9.5587158203125,
      "learning_rate": 9.800000000000001e-06,
      "loss": 0.8846,
      "step": 12750
    },
    {
      "epoch": 510.4,
      "grad_norm": 8.001797676086426,
      "learning_rate": 9.792e-06,
      "loss": 0.9029,
      "step": 12760
    },
    {
      "epoch": 510.8,
      "grad_norm": 7.308315753936768,
      "learning_rate": 9.784000000000002e-06,
      "loss": 0.894,
      "step": 12770
    },
    {
      "epoch": 511.2,
      "grad_norm": 11.978203773498535,
      "learning_rate": 9.776000000000001e-06,
      "loss": 0.8544,
      "step": 12780
    },
    {
      "epoch": 511.6,
      "grad_norm": 4.253579139709473,
      "learning_rate": 9.768e-06,
      "loss": 0.9005,
      "step": 12790
    },
    {
      "epoch": 512.0,
      "grad_norm": 5.992495536804199,
      "learning_rate": 9.760000000000001e-06,
      "loss": 0.8904,
      "step": 12800
    },
    {
      "epoch": 512.4,
      "grad_norm": 6.097031116485596,
      "learning_rate": 9.752e-06,
      "loss": 0.9203,
      "step": 12810
    },
    {
      "epoch": 512.8,
      "grad_norm": 4.008457183837891,
      "learning_rate": 9.744000000000002e-06,
      "loss": 0.8519,
      "step": 12820
    },
    {
      "epoch": 513.2,
      "grad_norm": 5.77723503112793,
      "learning_rate": 9.736000000000001e-06,
      "loss": 0.9086,
      "step": 12830
    },
    {
      "epoch": 513.6,
      "grad_norm": 18.31639862060547,
      "learning_rate": 9.728e-06,
      "loss": 0.8482,
      "step": 12840
    },
    {
      "epoch": 514.0,
      "grad_norm": 10.491823196411133,
      "learning_rate": 9.72e-06,
      "loss": 0.882,
      "step": 12850
    },
    {
      "epoch": 514.4,
      "grad_norm": 5.889298439025879,
      "learning_rate": 9.712e-06,
      "loss": 0.9143,
      "step": 12860
    },
    {
      "epoch": 514.8,
      "grad_norm": 5.273370742797852,
      "learning_rate": 9.704e-06,
      "loss": 0.8556,
      "step": 12870
    },
    {
      "epoch": 515.2,
      "grad_norm": 5.4930806159973145,
      "learning_rate": 9.696000000000002e-06,
      "loss": 0.8936,
      "step": 12880
    },
    {
      "epoch": 515.6,
      "grad_norm": 5.777167320251465,
      "learning_rate": 9.688000000000001e-06,
      "loss": 0.8964,
      "step": 12890
    },
    {
      "epoch": 516.0,
      "grad_norm": 7.970645904541016,
      "learning_rate": 9.68e-06,
      "loss": 0.8962,
      "step": 12900
    },
    {
      "epoch": 516.4,
      "grad_norm": 7.946073532104492,
      "learning_rate": 9.672e-06,
      "loss": 0.877,
      "step": 12910
    },
    {
      "epoch": 516.8,
      "grad_norm": 14.581869125366211,
      "learning_rate": 9.664000000000001e-06,
      "loss": 0.8791,
      "step": 12920
    },
    {
      "epoch": 517.2,
      "grad_norm": 12.242156028747559,
      "learning_rate": 9.656e-06,
      "loss": 0.9018,
      "step": 12930
    },
    {
      "epoch": 517.6,
      "grad_norm": 11.753714561462402,
      "learning_rate": 9.648000000000001e-06,
      "loss": 0.8966,
      "step": 12940
    },
    {
      "epoch": 518.0,
      "grad_norm": 10.472282409667969,
      "learning_rate": 9.640000000000001e-06,
      "loss": 0.8975,
      "step": 12950
    },
    {
      "epoch": 518.4,
      "grad_norm": 21.454761505126953,
      "learning_rate": 9.632e-06,
      "loss": 0.9025,
      "step": 12960
    },
    {
      "epoch": 518.8,
      "grad_norm": 5.813298225402832,
      "learning_rate": 9.624000000000001e-06,
      "loss": 0.9079,
      "step": 12970
    },
    {
      "epoch": 519.2,
      "grad_norm": 6.84686279296875,
      "learning_rate": 9.616e-06,
      "loss": 0.8637,
      "step": 12980
    },
    {
      "epoch": 519.6,
      "grad_norm": 5.684178829193115,
      "learning_rate": 9.608e-06,
      "loss": 0.8896,
      "step": 12990
    },
    {
      "epoch": 520.0,
      "grad_norm": 7.3037004470825195,
      "learning_rate": 9.600000000000001e-06,
      "loss": 0.8836,
      "step": 13000
    },
    {
      "epoch": 520.4,
      "grad_norm": 10.583893775939941,
      "learning_rate": 9.592e-06,
      "loss": 0.8863,
      "step": 13010
    },
    {
      "epoch": 520.8,
      "grad_norm": 4.4502410888671875,
      "learning_rate": 9.584000000000002e-06,
      "loss": 0.9072,
      "step": 13020
    },
    {
      "epoch": 521.2,
      "grad_norm": 7.843777179718018,
      "learning_rate": 9.576000000000001e-06,
      "loss": 0.8778,
      "step": 13030
    },
    {
      "epoch": 521.6,
      "grad_norm": 17.96234130859375,
      "learning_rate": 9.568e-06,
      "loss": 0.9024,
      "step": 13040
    },
    {
      "epoch": 522.0,
      "grad_norm": 15.087343215942383,
      "learning_rate": 9.56e-06,
      "loss": 0.8766,
      "step": 13050
    },
    {
      "epoch": 522.4,
      "grad_norm": 2.867504358291626,
      "learning_rate": 9.552000000000001e-06,
      "loss": 0.905,
      "step": 13060
    },
    {
      "epoch": 522.8,
      "grad_norm": 15.08719253540039,
      "learning_rate": 9.544e-06,
      "loss": 0.8866,
      "step": 13070
    },
    {
      "epoch": 523.2,
      "grad_norm": 5.576446056365967,
      "learning_rate": 9.536000000000002e-06,
      "loss": 0.9248,
      "step": 13080
    },
    {
      "epoch": 523.6,
      "grad_norm": 7.183653831481934,
      "learning_rate": 9.528000000000001e-06,
      "loss": 0.8853,
      "step": 13090
    },
    {
      "epoch": 524.0,
      "grad_norm": 7.255715370178223,
      "learning_rate": 9.52e-06,
      "loss": 0.9075,
      "step": 13100
    },
    {
      "epoch": 524.4,
      "grad_norm": 8.658432960510254,
      "learning_rate": 9.512000000000001e-06,
      "loss": 0.9009,
      "step": 13110
    },
    {
      "epoch": 524.8,
      "grad_norm": 7.773467540740967,
      "learning_rate": 9.504e-06,
      "loss": 0.8786,
      "step": 13120
    },
    {
      "epoch": 525.2,
      "grad_norm": 11.483962059020996,
      "learning_rate": 9.496e-06,
      "loss": 0.9,
      "step": 13130
    },
    {
      "epoch": 525.6,
      "grad_norm": 5.012441635131836,
      "learning_rate": 9.488000000000001e-06,
      "loss": 0.8568,
      "step": 13140
    },
    {
      "epoch": 526.0,
      "grad_norm": 4.61551570892334,
      "learning_rate": 9.48e-06,
      "loss": 0.9052,
      "step": 13150
    },
    {
      "epoch": 526.4,
      "grad_norm": 5.856467247009277,
      "learning_rate": 9.472000000000002e-06,
      "loss": 0.9295,
      "step": 13160
    },
    {
      "epoch": 526.8,
      "grad_norm": 8.433521270751953,
      "learning_rate": 9.464000000000001e-06,
      "loss": 0.8593,
      "step": 13170
    },
    {
      "epoch": 527.2,
      "grad_norm": 10.034496307373047,
      "learning_rate": 9.456e-06,
      "loss": 0.8714,
      "step": 13180
    },
    {
      "epoch": 527.6,
      "grad_norm": 4.153810977935791,
      "learning_rate": 9.448e-06,
      "loss": 0.9032,
      "step": 13190
    },
    {
      "epoch": 528.0,
      "grad_norm": 11.204243659973145,
      "learning_rate": 9.440000000000001e-06,
      "loss": 0.8914,
      "step": 13200
    },
    {
      "epoch": 528.4,
      "grad_norm": 12.724311828613281,
      "learning_rate": 9.432e-06,
      "loss": 0.9017,
      "step": 13210
    },
    {
      "epoch": 528.8,
      "grad_norm": 5.138707160949707,
      "learning_rate": 9.424000000000002e-06,
      "loss": 0.8735,
      "step": 13220
    },
    {
      "epoch": 529.2,
      "grad_norm": 6.54359769821167,
      "learning_rate": 9.416000000000001e-06,
      "loss": 0.8861,
      "step": 13230
    },
    {
      "epoch": 529.6,
      "grad_norm": 6.796546459197998,
      "learning_rate": 9.408e-06,
      "loss": 0.8694,
      "step": 13240
    },
    {
      "epoch": 530.0,
      "grad_norm": 6.301628112792969,
      "learning_rate": 9.4e-06,
      "loss": 0.8937,
      "step": 13250
    },
    {
      "epoch": 530.4,
      "grad_norm": 6.06142520904541,
      "learning_rate": 9.392000000000001e-06,
      "loss": 0.8698,
      "step": 13260
    },
    {
      "epoch": 530.8,
      "grad_norm": 11.555991172790527,
      "learning_rate": 9.384e-06,
      "loss": 0.8845,
      "step": 13270
    },
    {
      "epoch": 531.2,
      "grad_norm": 15.195313453674316,
      "learning_rate": 9.376000000000001e-06,
      "loss": 0.8796,
      "step": 13280
    },
    {
      "epoch": 531.6,
      "grad_norm": 11.334672927856445,
      "learning_rate": 9.368e-06,
      "loss": 0.8983,
      "step": 13290
    },
    {
      "epoch": 532.0,
      "grad_norm": 7.987259864807129,
      "learning_rate": 9.360000000000002e-06,
      "loss": 0.8952,
      "step": 13300
    },
    {
      "epoch": 532.4,
      "grad_norm": 13.416183471679688,
      "learning_rate": 9.352000000000001e-06,
      "loss": 0.8962,
      "step": 13310
    },
    {
      "epoch": 532.8,
      "grad_norm": 13.021594047546387,
      "learning_rate": 9.344e-06,
      "loss": 0.8949,
      "step": 13320
    },
    {
      "epoch": 533.2,
      "grad_norm": 5.820119380950928,
      "learning_rate": 9.336e-06,
      "loss": 0.8615,
      "step": 13330
    },
    {
      "epoch": 533.6,
      "grad_norm": 11.102261543273926,
      "learning_rate": 9.328000000000001e-06,
      "loss": 0.9029,
      "step": 13340
    },
    {
      "epoch": 534.0,
      "grad_norm": 6.729076385498047,
      "learning_rate": 9.32e-06,
      "loss": 0.8609,
      "step": 13350
    },
    {
      "epoch": 534.4,
      "grad_norm": 11.072589874267578,
      "learning_rate": 9.312000000000002e-06,
      "loss": 0.8767,
      "step": 13360
    },
    {
      "epoch": 534.8,
      "grad_norm": 6.640346527099609,
      "learning_rate": 9.304000000000001e-06,
      "loss": 0.8578,
      "step": 13370
    },
    {
      "epoch": 535.2,
      "grad_norm": 10.281270980834961,
      "learning_rate": 9.296e-06,
      "loss": 0.9082,
      "step": 13380
    },
    {
      "epoch": 535.6,
      "grad_norm": 17.37676239013672,
      "learning_rate": 9.288e-06,
      "loss": 0.8898,
      "step": 13390
    },
    {
      "epoch": 536.0,
      "grad_norm": 4.47998046875,
      "learning_rate": 9.280000000000001e-06,
      "loss": 0.8589,
      "step": 13400
    },
    {
      "epoch": 536.4,
      "grad_norm": 5.831613063812256,
      "learning_rate": 9.272e-06,
      "loss": 0.8499,
      "step": 13410
    },
    {
      "epoch": 536.8,
      "grad_norm": 13.312509536743164,
      "learning_rate": 9.264000000000001e-06,
      "loss": 0.9163,
      "step": 13420
    },
    {
      "epoch": 537.2,
      "grad_norm": 16.6314640045166,
      "learning_rate": 9.256e-06,
      "loss": 0.8794,
      "step": 13430
    },
    {
      "epoch": 537.6,
      "grad_norm": 9.84798812866211,
      "learning_rate": 9.248e-06,
      "loss": 0.9058,
      "step": 13440
    },
    {
      "epoch": 538.0,
      "grad_norm": 7.25494909286499,
      "learning_rate": 9.240000000000001e-06,
      "loss": 0.8835,
      "step": 13450
    },
    {
      "epoch": 538.4,
      "grad_norm": 6.868442535400391,
      "learning_rate": 9.232e-06,
      "loss": 0.8593,
      "step": 13460
    },
    {
      "epoch": 538.8,
      "grad_norm": 23.08885383605957,
      "learning_rate": 9.224e-06,
      "loss": 0.9086,
      "step": 13470
    },
    {
      "epoch": 539.2,
      "grad_norm": 7.928859233856201,
      "learning_rate": 9.216000000000001e-06,
      "loss": 0.8693,
      "step": 13480
    },
    {
      "epoch": 539.6,
      "grad_norm": 9.978812217712402,
      "learning_rate": 9.208e-06,
      "loss": 0.864,
      "step": 13490
    },
    {
      "epoch": 540.0,
      "grad_norm": 12.337718963623047,
      "learning_rate": 9.200000000000002e-06,
      "loss": 0.863,
      "step": 13500
    },
    {
      "epoch": 540.4,
      "grad_norm": 12.076803207397461,
      "learning_rate": 9.192000000000001e-06,
      "loss": 0.8694,
      "step": 13510
    },
    {
      "epoch": 540.8,
      "grad_norm": 3.0250155925750732,
      "learning_rate": 9.184e-06,
      "loss": 0.9109,
      "step": 13520
    },
    {
      "epoch": 541.2,
      "grad_norm": 5.751957893371582,
      "learning_rate": 9.176e-06,
      "loss": 0.8666,
      "step": 13530
    },
    {
      "epoch": 541.6,
      "grad_norm": 7.850746154785156,
      "learning_rate": 9.168000000000001e-06,
      "loss": 0.8931,
      "step": 13540
    },
    {
      "epoch": 542.0,
      "grad_norm": 10.337506294250488,
      "learning_rate": 9.16e-06,
      "loss": 0.9025,
      "step": 13550
    },
    {
      "epoch": 542.4,
      "grad_norm": 14.638459205627441,
      "learning_rate": 9.152000000000001e-06,
      "loss": 0.9075,
      "step": 13560
    },
    {
      "epoch": 542.8,
      "grad_norm": 12.60014533996582,
      "learning_rate": 9.144000000000001e-06,
      "loss": 0.8346,
      "step": 13570
    },
    {
      "epoch": 543.2,
      "grad_norm": 4.778097152709961,
      "learning_rate": 9.136e-06,
      "loss": 0.8767,
      "step": 13580
    },
    {
      "epoch": 543.6,
      "grad_norm": 5.4419779777526855,
      "learning_rate": 9.128e-06,
      "loss": 0.8846,
      "step": 13590
    },
    {
      "epoch": 544.0,
      "grad_norm": 6.89874267578125,
      "learning_rate": 9.12e-06,
      "loss": 0.8758,
      "step": 13600
    },
    {
      "epoch": 544.4,
      "grad_norm": 8.69095516204834,
      "learning_rate": 9.112e-06,
      "loss": 0.892,
      "step": 13610
    },
    {
      "epoch": 544.8,
      "grad_norm": 8.833858489990234,
      "learning_rate": 9.104000000000001e-06,
      "loss": 0.86,
      "step": 13620
    },
    {
      "epoch": 545.2,
      "grad_norm": 7.116419792175293,
      "learning_rate": 9.096e-06,
      "loss": 0.8763,
      "step": 13630
    },
    {
      "epoch": 545.6,
      "grad_norm": 11.831418991088867,
      "learning_rate": 9.088000000000002e-06,
      "loss": 0.9214,
      "step": 13640
    },
    {
      "epoch": 546.0,
      "grad_norm": 9.191890716552734,
      "learning_rate": 9.080000000000001e-06,
      "loss": 0.8775,
      "step": 13650
    },
    {
      "epoch": 546.4,
      "grad_norm": 10.40404224395752,
      "learning_rate": 9.072e-06,
      "loss": 0.846,
      "step": 13660
    },
    {
      "epoch": 546.8,
      "grad_norm": 5.147704124450684,
      "learning_rate": 9.064e-06,
      "loss": 0.8767,
      "step": 13670
    },
    {
      "epoch": 547.2,
      "grad_norm": 4.820046901702881,
      "learning_rate": 9.056000000000001e-06,
      "loss": 0.8833,
      "step": 13680
    },
    {
      "epoch": 547.6,
      "grad_norm": 3.7268879413604736,
      "learning_rate": 9.048e-06,
      "loss": 0.8465,
      "step": 13690
    },
    {
      "epoch": 548.0,
      "grad_norm": 15.2811279296875,
      "learning_rate": 9.040000000000002e-06,
      "loss": 0.8953,
      "step": 13700
    },
    {
      "epoch": 548.4,
      "grad_norm": 15.636187553405762,
      "learning_rate": 9.032000000000001e-06,
      "loss": 0.8925,
      "step": 13710
    },
    {
      "epoch": 548.8,
      "grad_norm": 8.872188568115234,
      "learning_rate": 9.024e-06,
      "loss": 0.8804,
      "step": 13720
    },
    {
      "epoch": 549.2,
      "grad_norm": 13.66865348815918,
      "learning_rate": 9.016e-06,
      "loss": 0.8867,
      "step": 13730
    },
    {
      "epoch": 549.6,
      "grad_norm": 9.231043815612793,
      "learning_rate": 9.008e-06,
      "loss": 0.8957,
      "step": 13740
    },
    {
      "epoch": 550.0,
      "grad_norm": 7.747725009918213,
      "learning_rate": 9e-06,
      "loss": 0.8875,
      "step": 13750
    },
    {
      "epoch": 550.4,
      "grad_norm": 5.784396648406982,
      "learning_rate": 8.992000000000001e-06,
      "loss": 0.86,
      "step": 13760
    },
    {
      "epoch": 550.8,
      "grad_norm": 6.914877891540527,
      "learning_rate": 8.984e-06,
      "loss": 0.8772,
      "step": 13770
    },
    {
      "epoch": 551.2,
      "grad_norm": 11.301239013671875,
      "learning_rate": 8.976e-06,
      "loss": 0.8764,
      "step": 13780
    },
    {
      "epoch": 551.6,
      "grad_norm": 3.8021984100341797,
      "learning_rate": 8.968000000000001e-06,
      "loss": 0.8498,
      "step": 13790
    },
    {
      "epoch": 552.0,
      "grad_norm": 9.532174110412598,
      "learning_rate": 8.96e-06,
      "loss": 0.8874,
      "step": 13800
    },
    {
      "epoch": 552.4,
      "grad_norm": 11.517864227294922,
      "learning_rate": 8.952e-06,
      "loss": 0.9024,
      "step": 13810
    },
    {
      "epoch": 552.8,
      "grad_norm": 14.48818588256836,
      "learning_rate": 8.944000000000001e-06,
      "loss": 0.859,
      "step": 13820
    },
    {
      "epoch": 553.2,
      "grad_norm": 4.146002292633057,
      "learning_rate": 8.936e-06,
      "loss": 0.8667,
      "step": 13830
    },
    {
      "epoch": 553.6,
      "grad_norm": 6.440272331237793,
      "learning_rate": 8.928000000000002e-06,
      "loss": 0.8493,
      "step": 13840
    },
    {
      "epoch": 554.0,
      "grad_norm": 10.681675910949707,
      "learning_rate": 8.920000000000001e-06,
      "loss": 0.9274,
      "step": 13850
    },
    {
      "epoch": 554.4,
      "grad_norm": 4.941792011260986,
      "learning_rate": 8.912e-06,
      "loss": 0.867,
      "step": 13860
    },
    {
      "epoch": 554.8,
      "grad_norm": 5.577365398406982,
      "learning_rate": 8.904e-06,
      "loss": 0.8703,
      "step": 13870
    },
    {
      "epoch": 555.2,
      "grad_norm": 13.308069229125977,
      "learning_rate": 8.896000000000001e-06,
      "loss": 0.8885,
      "step": 13880
    },
    {
      "epoch": 555.6,
      "grad_norm": 12.256113052368164,
      "learning_rate": 8.888e-06,
      "loss": 0.8637,
      "step": 13890
    },
    {
      "epoch": 556.0,
      "grad_norm": 9.278809547424316,
      "learning_rate": 8.880000000000001e-06,
      "loss": 0.8935,
      "step": 13900
    },
    {
      "epoch": 556.4,
      "grad_norm": 8.867048263549805,
      "learning_rate": 8.872e-06,
      "loss": 0.8539,
      "step": 13910
    },
    {
      "epoch": 556.8,
      "grad_norm": 16.686342239379883,
      "learning_rate": 8.864e-06,
      "loss": 0.8766,
      "step": 13920
    },
    {
      "epoch": 557.2,
      "grad_norm": 10.410504341125488,
      "learning_rate": 8.856000000000001e-06,
      "loss": 0.851,
      "step": 13930
    },
    {
      "epoch": 557.6,
      "grad_norm": 11.576412200927734,
      "learning_rate": 8.848e-06,
      "loss": 0.8577,
      "step": 13940
    },
    {
      "epoch": 558.0,
      "grad_norm": 5.582925796508789,
      "learning_rate": 8.84e-06,
      "loss": 0.8979,
      "step": 13950
    },
    {
      "epoch": 558.4,
      "grad_norm": 9.250428199768066,
      "learning_rate": 8.832000000000001e-06,
      "loss": 0.8893,
      "step": 13960
    },
    {
      "epoch": 558.8,
      "grad_norm": 5.89945125579834,
      "learning_rate": 8.824e-06,
      "loss": 0.8704,
      "step": 13970
    },
    {
      "epoch": 559.2,
      "grad_norm": 4.798609733581543,
      "learning_rate": 8.816000000000002e-06,
      "loss": 0.8804,
      "step": 13980
    },
    {
      "epoch": 559.6,
      "grad_norm": 14.63565444946289,
      "learning_rate": 8.808000000000001e-06,
      "loss": 0.8646,
      "step": 13990
    },
    {
      "epoch": 560.0,
      "grad_norm": 20.586111068725586,
      "learning_rate": 8.8e-06,
      "loss": 0.8782,
      "step": 14000
    },
    {
      "epoch": 560.4,
      "grad_norm": 6.415002346038818,
      "learning_rate": 8.792e-06,
      "loss": 0.8819,
      "step": 14010
    },
    {
      "epoch": 560.8,
      "grad_norm": 3.9314937591552734,
      "learning_rate": 8.784000000000001e-06,
      "loss": 0.8896,
      "step": 14020
    },
    {
      "epoch": 561.2,
      "grad_norm": 9.681351661682129,
      "learning_rate": 8.776e-06,
      "loss": 0.8325,
      "step": 14030
    },
    {
      "epoch": 561.6,
      "grad_norm": 11.025677680969238,
      "learning_rate": 8.768000000000001e-06,
      "loss": 0.8517,
      "step": 14040
    },
    {
      "epoch": 562.0,
      "grad_norm": 7.012393951416016,
      "learning_rate": 8.76e-06,
      "loss": 0.889,
      "step": 14050
    },
    {
      "epoch": 562.4,
      "grad_norm": 4.379410743713379,
      "learning_rate": 8.752e-06,
      "loss": 0.8456,
      "step": 14060
    },
    {
      "epoch": 562.8,
      "grad_norm": 6.63783073425293,
      "learning_rate": 8.744e-06,
      "loss": 0.8849,
      "step": 14070
    },
    {
      "epoch": 563.2,
      "grad_norm": 6.06328821182251,
      "learning_rate": 8.736e-06,
      "loss": 0.8832,
      "step": 14080
    },
    {
      "epoch": 563.6,
      "grad_norm": 8.143397331237793,
      "learning_rate": 8.728e-06,
      "loss": 0.8498,
      "step": 14090
    },
    {
      "epoch": 564.0,
      "grad_norm": 4.221874713897705,
      "learning_rate": 8.720000000000001e-06,
      "loss": 0.8761,
      "step": 14100
    },
    {
      "epoch": 564.4,
      "grad_norm": 11.313651084899902,
      "learning_rate": 8.712e-06,
      "loss": 0.8803,
      "step": 14110
    },
    {
      "epoch": 564.8,
      "grad_norm": 14.484600067138672,
      "learning_rate": 8.704e-06,
      "loss": 0.8628,
      "step": 14120
    },
    {
      "epoch": 565.2,
      "grad_norm": 13.644070625305176,
      "learning_rate": 8.696000000000001e-06,
      "loss": 0.8821,
      "step": 14130
    },
    {
      "epoch": 565.6,
      "grad_norm": 14.341347694396973,
      "learning_rate": 8.688e-06,
      "loss": 0.8651,
      "step": 14140
    },
    {
      "epoch": 566.0,
      "grad_norm": 4.577977657318115,
      "learning_rate": 8.68e-06,
      "loss": 0.8592,
      "step": 14150
    },
    {
      "epoch": 566.4,
      "grad_norm": 7.552850246429443,
      "learning_rate": 8.672000000000001e-06,
      "loss": 0.8679,
      "step": 14160
    },
    {
      "epoch": 566.8,
      "grad_norm": 9.24893569946289,
      "learning_rate": 8.664e-06,
      "loss": 0.8659,
      "step": 14170
    },
    {
      "epoch": 567.2,
      "grad_norm": 7.504626274108887,
      "learning_rate": 8.656000000000001e-06,
      "loss": 0.873,
      "step": 14180
    },
    {
      "epoch": 567.6,
      "grad_norm": 19.80154037475586,
      "learning_rate": 8.648000000000001e-06,
      "loss": 0.8811,
      "step": 14190
    },
    {
      "epoch": 568.0,
      "grad_norm": 8.547883987426758,
      "learning_rate": 8.64e-06,
      "loss": 0.8552,
      "step": 14200
    },
    {
      "epoch": 568.4,
      "grad_norm": 9.56821060180664,
      "learning_rate": 8.632e-06,
      "loss": 0.8507,
      "step": 14210
    },
    {
      "epoch": 568.8,
      "grad_norm": 9.759039878845215,
      "learning_rate": 8.624e-06,
      "loss": 0.8594,
      "step": 14220
    },
    {
      "epoch": 569.2,
      "grad_norm": 7.9711012840271,
      "learning_rate": 8.616000000000002e-06,
      "loss": 0.8828,
      "step": 14230
    },
    {
      "epoch": 569.6,
      "grad_norm": 7.9355950355529785,
      "learning_rate": 8.608000000000001e-06,
      "loss": 0.8253,
      "step": 14240
    },
    {
      "epoch": 570.0,
      "grad_norm": 16.039594650268555,
      "learning_rate": 8.6e-06,
      "loss": 0.8674,
      "step": 14250
    },
    {
      "epoch": 570.4,
      "grad_norm": 8.614150047302246,
      "learning_rate": 8.592e-06,
      "loss": 0.8551,
      "step": 14260
    },
    {
      "epoch": 570.8,
      "grad_norm": 18.34187889099121,
      "learning_rate": 8.584000000000001e-06,
      "loss": 0.8594,
      "step": 14270
    },
    {
      "epoch": 571.2,
      "grad_norm": 7.334246635437012,
      "learning_rate": 8.576e-06,
      "loss": 0.8354,
      "step": 14280
    },
    {
      "epoch": 571.6,
      "grad_norm": 8.978401184082031,
      "learning_rate": 8.568e-06,
      "loss": 0.8729,
      "step": 14290
    },
    {
      "epoch": 572.0,
      "grad_norm": 9.09780216217041,
      "learning_rate": 8.560000000000001e-06,
      "loss": 0.8701,
      "step": 14300
    },
    {
      "epoch": 572.4,
      "grad_norm": 7.628665924072266,
      "learning_rate": 8.552e-06,
      "loss": 0.8374,
      "step": 14310
    },
    {
      "epoch": 572.8,
      "grad_norm": 25.410747528076172,
      "learning_rate": 8.544000000000002e-06,
      "loss": 0.8625,
      "step": 14320
    },
    {
      "epoch": 573.2,
      "grad_norm": 4.104129791259766,
      "learning_rate": 8.536000000000001e-06,
      "loss": 0.8761,
      "step": 14330
    },
    {
      "epoch": 573.6,
      "grad_norm": 3.733412504196167,
      "learning_rate": 8.528e-06,
      "loss": 0.9017,
      "step": 14340
    },
    {
      "epoch": 574.0,
      "grad_norm": 4.8572516441345215,
      "learning_rate": 8.52e-06,
      "loss": 0.8094,
      "step": 14350
    },
    {
      "epoch": 574.4,
      "grad_norm": 5.167449474334717,
      "learning_rate": 8.512e-06,
      "loss": 0.8444,
      "step": 14360
    },
    {
      "epoch": 574.8,
      "grad_norm": 14.013117790222168,
      "learning_rate": 8.504000000000002e-06,
      "loss": 0.8425,
      "step": 14370
    },
    {
      "epoch": 575.2,
      "grad_norm": 4.436425685882568,
      "learning_rate": 8.496000000000001e-06,
      "loss": 0.8686,
      "step": 14380
    },
    {
      "epoch": 575.6,
      "grad_norm": 6.6839423179626465,
      "learning_rate": 8.488e-06,
      "loss": 0.8564,
      "step": 14390
    },
    {
      "epoch": 576.0,
      "grad_norm": 10.924957275390625,
      "learning_rate": 8.48e-06,
      "loss": 0.8919,
      "step": 14400
    },
    {
      "epoch": 576.4,
      "grad_norm": 17.373376846313477,
      "learning_rate": 8.472e-06,
      "loss": 0.86,
      "step": 14410
    },
    {
      "epoch": 576.8,
      "grad_norm": 22.133607864379883,
      "learning_rate": 8.464e-06,
      "loss": 0.8935,
      "step": 14420
    },
    {
      "epoch": 577.2,
      "grad_norm": 5.20790958404541,
      "learning_rate": 8.456000000000002e-06,
      "loss": 0.8507,
      "step": 14430
    },
    {
      "epoch": 577.6,
      "grad_norm": 3.6218199729919434,
      "learning_rate": 8.448000000000001e-06,
      "loss": 0.8353,
      "step": 14440
    },
    {
      "epoch": 578.0,
      "grad_norm": 8.268694877624512,
      "learning_rate": 8.44e-06,
      "loss": 0.8313,
      "step": 14450
    },
    {
      "epoch": 578.4,
      "grad_norm": 12.183540344238281,
      "learning_rate": 8.432e-06,
      "loss": 0.8604,
      "step": 14460
    },
    {
      "epoch": 578.8,
      "grad_norm": 7.19550085067749,
      "learning_rate": 8.424000000000001e-06,
      "loss": 0.8489,
      "step": 14470
    },
    {
      "epoch": 579.2,
      "grad_norm": 13.578193664550781,
      "learning_rate": 8.416e-06,
      "loss": 0.8689,
      "step": 14480
    },
    {
      "epoch": 579.6,
      "grad_norm": 6.93412446975708,
      "learning_rate": 8.408e-06,
      "loss": 0.8933,
      "step": 14490
    },
    {
      "epoch": 580.0,
      "grad_norm": 8.283157348632812,
      "learning_rate": 8.400000000000001e-06,
      "loss": 0.8466,
      "step": 14500
    },
    {
      "epoch": 580.4,
      "grad_norm": 5.3089070320129395,
      "learning_rate": 8.392e-06,
      "loss": 0.8716,
      "step": 14510
    },
    {
      "epoch": 580.8,
      "grad_norm": 8.296586990356445,
      "learning_rate": 8.384000000000001e-06,
      "loss": 0.8513,
      "step": 14520
    },
    {
      "epoch": 581.2,
      "grad_norm": 10.207820892333984,
      "learning_rate": 8.376e-06,
      "loss": 0.8716,
      "step": 14530
    },
    {
      "epoch": 581.6,
      "grad_norm": 3.8651554584503174,
      "learning_rate": 8.368e-06,
      "loss": 0.8452,
      "step": 14540
    },
    {
      "epoch": 582.0,
      "grad_norm": 8.725317001342773,
      "learning_rate": 8.36e-06,
      "loss": 0.8851,
      "step": 14550
    },
    {
      "epoch": 582.4,
      "grad_norm": 6.345531940460205,
      "learning_rate": 8.352e-06,
      "loss": 0.8454,
      "step": 14560
    },
    {
      "epoch": 582.8,
      "grad_norm": 7.380474090576172,
      "learning_rate": 8.344000000000002e-06,
      "loss": 0.8855,
      "step": 14570
    },
    {
      "epoch": 583.2,
      "grad_norm": 22.482210159301758,
      "learning_rate": 8.336000000000001e-06,
      "loss": 0.8661,
      "step": 14580
    },
    {
      "epoch": 583.6,
      "grad_norm": 3.458836555480957,
      "learning_rate": 8.328e-06,
      "loss": 0.8641,
      "step": 14590
    },
    {
      "epoch": 584.0,
      "grad_norm": 7.00483512878418,
      "learning_rate": 8.32e-06,
      "loss": 0.8969,
      "step": 14600
    },
    {
      "epoch": 584.4,
      "grad_norm": 10.496152877807617,
      "learning_rate": 8.312000000000001e-06,
      "loss": 0.8404,
      "step": 14610
    },
    {
      "epoch": 584.8,
      "grad_norm": 7.501565933227539,
      "learning_rate": 8.304e-06,
      "loss": 0.8443,
      "step": 14620
    },
    {
      "epoch": 585.2,
      "grad_norm": 9.828014373779297,
      "learning_rate": 8.296000000000002e-06,
      "loss": 0.8882,
      "step": 14630
    },
    {
      "epoch": 585.6,
      "grad_norm": 6.039316177368164,
      "learning_rate": 8.288000000000001e-06,
      "loss": 0.8482,
      "step": 14640
    },
    {
      "epoch": 586.0,
      "grad_norm": 4.899113655090332,
      "learning_rate": 8.28e-06,
      "loss": 0.827,
      "step": 14650
    },
    {
      "epoch": 586.4,
      "grad_norm": 11.244202613830566,
      "learning_rate": 8.272000000000001e-06,
      "loss": 0.8788,
      "step": 14660
    },
    {
      "epoch": 586.8,
      "grad_norm": 21.268728256225586,
      "learning_rate": 8.264e-06,
      "loss": 0.8439,
      "step": 14670
    },
    {
      "epoch": 587.2,
      "grad_norm": 9.536255836486816,
      "learning_rate": 8.256e-06,
      "loss": 0.8787,
      "step": 14680
    },
    {
      "epoch": 587.6,
      "grad_norm": 15.591742515563965,
      "learning_rate": 8.248e-06,
      "loss": 0.8623,
      "step": 14690
    },
    {
      "epoch": 588.0,
      "grad_norm": 10.615228652954102,
      "learning_rate": 8.24e-06,
      "loss": 0.8813,
      "step": 14700
    },
    {
      "epoch": 588.4,
      "grad_norm": 8.201112747192383,
      "learning_rate": 8.232000000000002e-06,
      "loss": 0.8747,
      "step": 14710
    },
    {
      "epoch": 588.8,
      "grad_norm": 3.7968242168426514,
      "learning_rate": 8.224000000000001e-06,
      "loss": 0.852,
      "step": 14720
    },
    {
      "epoch": 589.2,
      "grad_norm": 7.007127285003662,
      "learning_rate": 8.216e-06,
      "loss": 0.8444,
      "step": 14730
    },
    {
      "epoch": 589.6,
      "grad_norm": 5.7699294090271,
      "learning_rate": 8.208e-06,
      "loss": 0.8393,
      "step": 14740
    },
    {
      "epoch": 590.0,
      "grad_norm": 4.487429618835449,
      "learning_rate": 8.2e-06,
      "loss": 0.8731,
      "step": 14750
    },
    {
      "epoch": 590.4,
      "grad_norm": 10.157243728637695,
      "learning_rate": 8.192e-06,
      "loss": 0.8646,
      "step": 14760
    },
    {
      "epoch": 590.8,
      "grad_norm": 8.845224380493164,
      "learning_rate": 8.184000000000002e-06,
      "loss": 0.8412,
      "step": 14770
    },
    {
      "epoch": 591.2,
      "grad_norm": 7.786910057067871,
      "learning_rate": 8.176000000000001e-06,
      "loss": 0.8662,
      "step": 14780
    },
    {
      "epoch": 591.6,
      "grad_norm": 3.76308274269104,
      "learning_rate": 8.168e-06,
      "loss": 0.8354,
      "step": 14790
    },
    {
      "epoch": 592.0,
      "grad_norm": 20.30074119567871,
      "learning_rate": 8.16e-06,
      "loss": 0.8531,
      "step": 14800
    },
    {
      "epoch": 592.4,
      "grad_norm": 12.377435684204102,
      "learning_rate": 8.152000000000001e-06,
      "loss": 0.8662,
      "step": 14810
    },
    {
      "epoch": 592.8,
      "grad_norm": 12.920748710632324,
      "learning_rate": 8.144e-06,
      "loss": 0.8611,
      "step": 14820
    },
    {
      "epoch": 593.2,
      "grad_norm": 6.445702075958252,
      "learning_rate": 8.136000000000001e-06,
      "loss": 0.8518,
      "step": 14830
    },
    {
      "epoch": 593.6,
      "grad_norm": 4.007016658782959,
      "learning_rate": 8.128e-06,
      "loss": 0.8743,
      "step": 14840
    },
    {
      "epoch": 594.0,
      "grad_norm": 8.910480499267578,
      "learning_rate": 8.120000000000002e-06,
      "loss": 0.8657,
      "step": 14850
    },
    {
      "epoch": 594.4,
      "grad_norm": 10.668063163757324,
      "learning_rate": 8.112000000000001e-06,
      "loss": 0.8791,
      "step": 14860
    },
    {
      "epoch": 594.8,
      "grad_norm": 8.949254035949707,
      "learning_rate": 8.104e-06,
      "loss": 0.844,
      "step": 14870
    },
    {
      "epoch": 595.2,
      "grad_norm": 18.84697914123535,
      "learning_rate": 8.096e-06,
      "loss": 0.8671,
      "step": 14880
    },
    {
      "epoch": 595.6,
      "grad_norm": 13.01651668548584,
      "learning_rate": 8.088e-06,
      "loss": 0.8824,
      "step": 14890
    },
    {
      "epoch": 596.0,
      "grad_norm": 3.185497760772705,
      "learning_rate": 8.08e-06,
      "loss": 0.8541,
      "step": 14900
    },
    {
      "epoch": 596.4,
      "grad_norm": 18.003358840942383,
      "learning_rate": 8.072000000000002e-06,
      "loss": 0.8495,
      "step": 14910
    },
    {
      "epoch": 596.8,
      "grad_norm": 13.82239818572998,
      "learning_rate": 8.064000000000001e-06,
      "loss": 0.8656,
      "step": 14920
    },
    {
      "epoch": 597.2,
      "grad_norm": 7.2384843826293945,
      "learning_rate": 8.056e-06,
      "loss": 0.8843,
      "step": 14930
    },
    {
      "epoch": 597.6,
      "grad_norm": 16.742956161499023,
      "learning_rate": 8.048e-06,
      "loss": 0.8745,
      "step": 14940
    },
    {
      "epoch": 598.0,
      "grad_norm": 3.0945870876312256,
      "learning_rate": 8.040000000000001e-06,
      "loss": 0.8613,
      "step": 14950
    },
    {
      "epoch": 598.4,
      "grad_norm": 10.901922225952148,
      "learning_rate": 8.032e-06,
      "loss": 0.8503,
      "step": 14960
    },
    {
      "epoch": 598.8,
      "grad_norm": 4.762634754180908,
      "learning_rate": 8.024000000000001e-06,
      "loss": 0.8362,
      "step": 14970
    },
    {
      "epoch": 599.2,
      "grad_norm": 9.76478385925293,
      "learning_rate": 8.016e-06,
      "loss": 0.8489,
      "step": 14980
    },
    {
      "epoch": 599.6,
      "grad_norm": 7.065228462219238,
      "learning_rate": 8.008e-06,
      "loss": 0.8611,
      "step": 14990
    },
    {
      "epoch": 600.0,
      "grad_norm": 8.799386978149414,
      "learning_rate": 8.000000000000001e-06,
      "loss": 0.8742,
      "step": 15000
    },
    {
      "epoch": 600.4,
      "grad_norm": 14.306159019470215,
      "learning_rate": 7.992e-06,
      "loss": 0.8553,
      "step": 15010
    },
    {
      "epoch": 600.8,
      "grad_norm": 8.962359428405762,
      "learning_rate": 7.984e-06,
      "loss": 0.863,
      "step": 15020
    },
    {
      "epoch": 601.2,
      "grad_norm": 13.805878639221191,
      "learning_rate": 7.976000000000001e-06,
      "loss": 0.8367,
      "step": 15030
    },
    {
      "epoch": 601.6,
      "grad_norm": 8.244589805603027,
      "learning_rate": 7.968e-06,
      "loss": 0.8486,
      "step": 15040
    },
    {
      "epoch": 602.0,
      "grad_norm": 6.403875827789307,
      "learning_rate": 7.960000000000002e-06,
      "loss": 0.8293,
      "step": 15050
    },
    {
      "epoch": 602.4,
      "grad_norm": 6.010328769683838,
      "learning_rate": 7.952000000000001e-06,
      "loss": 0.8331,
      "step": 15060
    },
    {
      "epoch": 602.8,
      "grad_norm": 19.3532657623291,
      "learning_rate": 7.944e-06,
      "loss": 0.822,
      "step": 15070
    },
    {
      "epoch": 603.2,
      "grad_norm": 10.438911437988281,
      "learning_rate": 7.936e-06,
      "loss": 0.8851,
      "step": 15080
    },
    {
      "epoch": 603.6,
      "grad_norm": 8.825093269348145,
      "learning_rate": 7.928e-06,
      "loss": 0.8433,
      "step": 15090
    },
    {
      "epoch": 604.0,
      "grad_norm": 17.5601863861084,
      "learning_rate": 7.92e-06,
      "loss": 0.8768,
      "step": 15100
    },
    {
      "epoch": 604.4,
      "grad_norm": 8.364358901977539,
      "learning_rate": 7.912000000000001e-06,
      "loss": 0.8309,
      "step": 15110
    },
    {
      "epoch": 604.8,
      "grad_norm": 3.658057928085327,
      "learning_rate": 7.904000000000001e-06,
      "loss": 0.8436,
      "step": 15120
    },
    {
      "epoch": 605.2,
      "grad_norm": 4.955475330352783,
      "learning_rate": 7.896e-06,
      "loss": 0.8627,
      "step": 15130
    },
    {
      "epoch": 605.6,
      "grad_norm": 7.6239752769470215,
      "learning_rate": 7.888e-06,
      "loss": 0.8346,
      "step": 15140
    },
    {
      "epoch": 606.0,
      "grad_norm": 4.418459892272949,
      "learning_rate": 7.88e-06,
      "loss": 0.8722,
      "step": 15150
    },
    {
      "epoch": 606.4,
      "grad_norm": 11.35360050201416,
      "learning_rate": 7.872e-06,
      "loss": 0.867,
      "step": 15160
    },
    {
      "epoch": 606.8,
      "grad_norm": 8.809636116027832,
      "learning_rate": 7.864000000000001e-06,
      "loss": 0.7896,
      "step": 15170
    },
    {
      "epoch": 607.2,
      "grad_norm": 5.2603559494018555,
      "learning_rate": 7.856e-06,
      "loss": 0.8716,
      "step": 15180
    },
    {
      "epoch": 607.6,
      "grad_norm": 6.260395526885986,
      "learning_rate": 7.848000000000002e-06,
      "loss": 0.8433,
      "step": 15190
    },
    {
      "epoch": 608.0,
      "grad_norm": 5.028436660766602,
      "learning_rate": 7.840000000000001e-06,
      "loss": 0.8428,
      "step": 15200
    },
    {
      "epoch": 608.4,
      "grad_norm": 7.914331912994385,
      "learning_rate": 7.832e-06,
      "loss": 0.8366,
      "step": 15210
    },
    {
      "epoch": 608.8,
      "grad_norm": 15.29159164428711,
      "learning_rate": 7.824e-06,
      "loss": 0.8565,
      "step": 15220
    },
    {
      "epoch": 609.2,
      "grad_norm": 7.632678985595703,
      "learning_rate": 7.816000000000001e-06,
      "loss": 0.858,
      "step": 15230
    },
    {
      "epoch": 609.6,
      "grad_norm": 12.646095275878906,
      "learning_rate": 7.808e-06,
      "loss": 0.861,
      "step": 15240
    },
    {
      "epoch": 610.0,
      "grad_norm": 8.578381538391113,
      "learning_rate": 7.800000000000002e-06,
      "loss": 0.8343,
      "step": 15250
    },
    {
      "epoch": 610.4,
      "grad_norm": 13.292436599731445,
      "learning_rate": 7.792000000000001e-06,
      "loss": 0.8249,
      "step": 15260
    },
    {
      "epoch": 610.8,
      "grad_norm": 6.819680213928223,
      "learning_rate": 7.784e-06,
      "loss": 0.8372,
      "step": 15270
    },
    {
      "epoch": 611.2,
      "grad_norm": 20.130382537841797,
      "learning_rate": 7.776e-06,
      "loss": 0.8517,
      "step": 15280
    },
    {
      "epoch": 611.6,
      "grad_norm": 13.01620864868164,
      "learning_rate": 7.768e-06,
      "loss": 0.871,
      "step": 15290
    },
    {
      "epoch": 612.0,
      "grad_norm": 11.377680778503418,
      "learning_rate": 7.76e-06,
      "loss": 0.8513,
      "step": 15300
    },
    {
      "epoch": 612.4,
      "grad_norm": 12.199827194213867,
      "learning_rate": 7.752000000000001e-06,
      "loss": 0.8959,
      "step": 15310
    },
    {
      "epoch": 612.8,
      "grad_norm": 18.92876625061035,
      "learning_rate": 7.744e-06,
      "loss": 0.8336,
      "step": 15320
    },
    {
      "epoch": 613.2,
      "grad_norm": 11.800538063049316,
      "learning_rate": 7.736e-06,
      "loss": 0.842,
      "step": 15330
    },
    {
      "epoch": 613.6,
      "grad_norm": 9.932098388671875,
      "learning_rate": 7.728000000000001e-06,
      "loss": 0.8037,
      "step": 15340
    },
    {
      "epoch": 614.0,
      "grad_norm": 6.9611663818359375,
      "learning_rate": 7.72e-06,
      "loss": 0.8778,
      "step": 15350
    },
    {
      "epoch": 614.4,
      "grad_norm": 14.30254077911377,
      "learning_rate": 7.712e-06,
      "loss": 0.8514,
      "step": 15360
    },
    {
      "epoch": 614.8,
      "grad_norm": 14.691046714782715,
      "learning_rate": 7.704000000000001e-06,
      "loss": 0.8956,
      "step": 15370
    },
    {
      "epoch": 615.2,
      "grad_norm": 8.68889331817627,
      "learning_rate": 7.696e-06,
      "loss": 0.9118,
      "step": 15380
    },
    {
      "epoch": 615.6,
      "grad_norm": 10.573847770690918,
      "learning_rate": 7.688000000000002e-06,
      "loss": 0.843,
      "step": 15390
    },
    {
      "epoch": 616.0,
      "grad_norm": 5.153927326202393,
      "learning_rate": 7.680000000000001e-06,
      "loss": 0.8215,
      "step": 15400
    },
    {
      "epoch": 616.4,
      "grad_norm": 4.562064170837402,
      "learning_rate": 7.672e-06,
      "loss": 0.8789,
      "step": 15410
    },
    {
      "epoch": 616.8,
      "grad_norm": 8.739479064941406,
      "learning_rate": 7.664e-06,
      "loss": 0.831,
      "step": 15420
    },
    {
      "epoch": 617.2,
      "grad_norm": 5.792355537414551,
      "learning_rate": 7.656000000000001e-06,
      "loss": 0.8538,
      "step": 15430
    },
    {
      "epoch": 617.6,
      "grad_norm": 8.046076774597168,
      "learning_rate": 7.648e-06,
      "loss": 0.8573,
      "step": 15440
    },
    {
      "epoch": 618.0,
      "grad_norm": 12.009147644042969,
      "learning_rate": 7.640000000000001e-06,
      "loss": 0.8184,
      "step": 15450
    },
    {
      "epoch": 618.4,
      "grad_norm": 4.354818344116211,
      "learning_rate": 7.632e-06,
      "loss": 0.8421,
      "step": 15460
    },
    {
      "epoch": 618.8,
      "grad_norm": 11.706282615661621,
      "learning_rate": 7.624e-06,
      "loss": 0.8442,
      "step": 15470
    },
    {
      "epoch": 619.2,
      "grad_norm": 21.290143966674805,
      "learning_rate": 7.616000000000001e-06,
      "loss": 0.8384,
      "step": 15480
    },
    {
      "epoch": 619.6,
      "grad_norm": 9.944242477416992,
      "learning_rate": 7.608000000000001e-06,
      "loss": 0.8495,
      "step": 15490
    },
    {
      "epoch": 620.0,
      "grad_norm": 17.078847885131836,
      "learning_rate": 7.600000000000001e-06,
      "loss": 0.8788,
      "step": 15500
    },
    {
      "epoch": 620.4,
      "grad_norm": 7.316634654998779,
      "learning_rate": 7.592e-06,
      "loss": 0.8531,
      "step": 15510
    },
    {
      "epoch": 620.8,
      "grad_norm": 19.974660873413086,
      "learning_rate": 7.5840000000000006e-06,
      "loss": 0.8467,
      "step": 15520
    },
    {
      "epoch": 621.2,
      "grad_norm": 10.53148365020752,
      "learning_rate": 7.576000000000001e-06,
      "loss": 0.8216,
      "step": 15530
    },
    {
      "epoch": 621.6,
      "grad_norm": 8.26844310760498,
      "learning_rate": 7.568000000000001e-06,
      "loss": 0.8794,
      "step": 15540
    },
    {
      "epoch": 622.0,
      "grad_norm": 15.318859100341797,
      "learning_rate": 7.5600000000000005e-06,
      "loss": 0.8637,
      "step": 15550
    },
    {
      "epoch": 622.4,
      "grad_norm": 11.21357250213623,
      "learning_rate": 7.552000000000001e-06,
      "loss": 0.8181,
      "step": 15560
    },
    {
      "epoch": 622.8,
      "grad_norm": 5.270163059234619,
      "learning_rate": 7.544e-06,
      "loss": 0.8822,
      "step": 15570
    },
    {
      "epoch": 623.2,
      "grad_norm": 6.624963283538818,
      "learning_rate": 7.536000000000001e-06,
      "loss": 0.8391,
      "step": 15580
    },
    {
      "epoch": 623.6,
      "grad_norm": 6.860299110412598,
      "learning_rate": 7.528000000000001e-06,
      "loss": 0.8489,
      "step": 15590
    },
    {
      "epoch": 624.0,
      "grad_norm": 13.907328605651855,
      "learning_rate": 7.520000000000001e-06,
      "loss": 0.8489,
      "step": 15600
    },
    {
      "epoch": 624.4,
      "grad_norm": 5.033468246459961,
      "learning_rate": 7.512e-06,
      "loss": 0.8688,
      "step": 15610
    },
    {
      "epoch": 624.8,
      "grad_norm": 15.11563491821289,
      "learning_rate": 7.5040000000000005e-06,
      "loss": 0.8636,
      "step": 15620
    },
    {
      "epoch": 625.2,
      "grad_norm": 9.598593711853027,
      "learning_rate": 7.496000000000001e-06,
      "loss": 0.8638,
      "step": 15630
    },
    {
      "epoch": 625.6,
      "grad_norm": 10.864627838134766,
      "learning_rate": 7.488000000000001e-06,
      "loss": 0.8273,
      "step": 15640
    },
    {
      "epoch": 626.0,
      "grad_norm": 10.007101058959961,
      "learning_rate": 7.48e-06,
      "loss": 0.8421,
      "step": 15650
    },
    {
      "epoch": 626.4,
      "grad_norm": 8.393251419067383,
      "learning_rate": 7.472000000000001e-06,
      "loss": 0.8388,
      "step": 15660
    },
    {
      "epoch": 626.8,
      "grad_norm": 8.76080322265625,
      "learning_rate": 7.464e-06,
      "loss": 0.8575,
      "step": 15670
    },
    {
      "epoch": 627.2,
      "grad_norm": 5.398766994476318,
      "learning_rate": 7.456000000000001e-06,
      "loss": 0.8522,
      "step": 15680
    },
    {
      "epoch": 627.6,
      "grad_norm": 4.775735855102539,
      "learning_rate": 7.4480000000000005e-06,
      "loss": 0.8478,
      "step": 15690
    },
    {
      "epoch": 628.0,
      "grad_norm": 4.219979286193848,
      "learning_rate": 7.440000000000001e-06,
      "loss": 0.8418,
      "step": 15700
    },
    {
      "epoch": 628.4,
      "grad_norm": 5.922671318054199,
      "learning_rate": 7.432e-06,
      "loss": 0.8472,
      "step": 15710
    },
    {
      "epoch": 628.8,
      "grad_norm": 12.421805381774902,
      "learning_rate": 7.424e-06,
      "loss": 0.8501,
      "step": 15720
    },
    {
      "epoch": 629.2,
      "grad_norm": 9.952494621276855,
      "learning_rate": 7.416000000000001e-06,
      "loss": 0.8433,
      "step": 15730
    },
    {
      "epoch": 629.6,
      "grad_norm": 6.956532955169678,
      "learning_rate": 7.408000000000001e-06,
      "loss": 0.8821,
      "step": 15740
    },
    {
      "epoch": 630.0,
      "grad_norm": 5.082825183868408,
      "learning_rate": 7.4e-06,
      "loss": 0.8543,
      "step": 15750
    },
    {
      "epoch": 630.4,
      "grad_norm": 4.2277326583862305,
      "learning_rate": 7.3920000000000005e-06,
      "loss": 0.8323,
      "step": 15760
    },
    {
      "epoch": 630.8,
      "grad_norm": 8.452459335327148,
      "learning_rate": 7.384e-06,
      "loss": 0.8544,
      "step": 15770
    },
    {
      "epoch": 631.2,
      "grad_norm": 11.08241081237793,
      "learning_rate": 7.376000000000001e-06,
      "loss": 0.8463,
      "step": 15780
    },
    {
      "epoch": 631.6,
      "grad_norm": 8.8667573928833,
      "learning_rate": 7.3680000000000004e-06,
      "loss": 0.8634,
      "step": 15790
    },
    {
      "epoch": 632.0,
      "grad_norm": 12.494677543640137,
      "learning_rate": 7.360000000000001e-06,
      "loss": 0.8486,
      "step": 15800
    },
    {
      "epoch": 632.4,
      "grad_norm": 6.084909439086914,
      "learning_rate": 7.352e-06,
      "loss": 0.8491,
      "step": 15810
    },
    {
      "epoch": 632.8,
      "grad_norm": 11.11130428314209,
      "learning_rate": 7.344000000000001e-06,
      "loss": 0.8227,
      "step": 15820
    },
    {
      "epoch": 633.2,
      "grad_norm": 11.446487426757812,
      "learning_rate": 7.3360000000000006e-06,
      "loss": 0.8183,
      "step": 15830
    },
    {
      "epoch": 633.6,
      "grad_norm": 5.831069469451904,
      "learning_rate": 7.328000000000001e-06,
      "loss": 0.8331,
      "step": 15840
    },
    {
      "epoch": 634.0,
      "grad_norm": 4.179806709289551,
      "learning_rate": 7.32e-06,
      "loss": 0.8622,
      "step": 15850
    },
    {
      "epoch": 634.4,
      "grad_norm": 6.599213123321533,
      "learning_rate": 7.3120000000000005e-06,
      "loss": 0.819,
      "step": 15860
    },
    {
      "epoch": 634.8,
      "grad_norm": 12.909339904785156,
      "learning_rate": 7.304000000000001e-06,
      "loss": 0.8256,
      "step": 15870
    },
    {
      "epoch": 635.2,
      "grad_norm": 10.528226852416992,
      "learning_rate": 7.296000000000001e-06,
      "loss": 0.8589,
      "step": 15880
    },
    {
      "epoch": 635.6,
      "grad_norm": 16.208173751831055,
      "learning_rate": 7.288e-06,
      "loss": 0.8435,
      "step": 15890
    },
    {
      "epoch": 636.0,
      "grad_norm": 10.921027183532715,
      "learning_rate": 7.280000000000001e-06,
      "loss": 0.8441,
      "step": 15900
    },
    {
      "epoch": 636.4,
      "grad_norm": 9.983242988586426,
      "learning_rate": 7.272e-06,
      "loss": 0.8215,
      "step": 15910
    },
    {
      "epoch": 636.8,
      "grad_norm": 17.493362426757812,
      "learning_rate": 7.264000000000001e-06,
      "loss": 0.8514,
      "step": 15920
    },
    {
      "epoch": 637.2,
      "grad_norm": 3.8090121746063232,
      "learning_rate": 7.2560000000000005e-06,
      "loss": 0.8554,
      "step": 15930
    },
    {
      "epoch": 637.6,
      "grad_norm": 7.953671455383301,
      "learning_rate": 7.248000000000001e-06,
      "loss": 0.8177,
      "step": 15940
    },
    {
      "epoch": 638.0,
      "grad_norm": 14.57579231262207,
      "learning_rate": 7.24e-06,
      "loss": 0.8574,
      "step": 15950
    },
    {
      "epoch": 638.4,
      "grad_norm": 18.307491302490234,
      "learning_rate": 7.232e-06,
      "loss": 0.8595,
      "step": 15960
    },
    {
      "epoch": 638.8,
      "grad_norm": 6.319178104400635,
      "learning_rate": 7.224000000000001e-06,
      "loss": 0.8532,
      "step": 15970
    },
    {
      "epoch": 639.2,
      "grad_norm": 18.908870697021484,
      "learning_rate": 7.216000000000001e-06,
      "loss": 0.8496,
      "step": 15980
    },
    {
      "epoch": 639.6,
      "grad_norm": 15.418571472167969,
      "learning_rate": 7.208e-06,
      "loss": 0.8216,
      "step": 15990
    },
    {
      "epoch": 640.0,
      "grad_norm": 9.508858680725098,
      "learning_rate": 7.2000000000000005e-06,
      "loss": 0.8511,
      "step": 16000
    },
    {
      "epoch": 640.4,
      "grad_norm": 15.296965599060059,
      "learning_rate": 7.192e-06,
      "loss": 0.8518,
      "step": 16010
    },
    {
      "epoch": 640.8,
      "grad_norm": 4.000645637512207,
      "learning_rate": 7.184000000000001e-06,
      "loss": 0.8217,
      "step": 16020
    },
    {
      "epoch": 641.2,
      "grad_norm": 4.898793697357178,
      "learning_rate": 7.176e-06,
      "loss": 0.8421,
      "step": 16030
    },
    {
      "epoch": 641.6,
      "grad_norm": 9.947763442993164,
      "learning_rate": 7.168000000000001e-06,
      "loss": 0.829,
      "step": 16040
    },
    {
      "epoch": 642.0,
      "grad_norm": 10.621735572814941,
      "learning_rate": 7.16e-06,
      "loss": 0.8194,
      "step": 16050
    },
    {
      "epoch": 642.4,
      "grad_norm": 5.193614482879639,
      "learning_rate": 7.152e-06,
      "loss": 0.839,
      "step": 16060
    },
    {
      "epoch": 642.8,
      "grad_norm": 10.206703186035156,
      "learning_rate": 7.1440000000000005e-06,
      "loss": 0.8698,
      "step": 16070
    },
    {
      "epoch": 643.2,
      "grad_norm": 7.686091423034668,
      "learning_rate": 7.136000000000001e-06,
      "loss": 0.8523,
      "step": 16080
    },
    {
      "epoch": 643.6,
      "grad_norm": 12.377053260803223,
      "learning_rate": 7.128e-06,
      "loss": 0.8454,
      "step": 16090
    },
    {
      "epoch": 644.0,
      "grad_norm": 15.400941848754883,
      "learning_rate": 7.1200000000000004e-06,
      "loss": 0.8605,
      "step": 16100
    },
    {
      "epoch": 644.4,
      "grad_norm": 14.581403732299805,
      "learning_rate": 7.1120000000000015e-06,
      "loss": 0.8373,
      "step": 16110
    },
    {
      "epoch": 644.8,
      "grad_norm": 7.32087516784668,
      "learning_rate": 7.104000000000001e-06,
      "loss": 0.846,
      "step": 16120
    },
    {
      "epoch": 645.2,
      "grad_norm": 9.19419002532959,
      "learning_rate": 7.096e-06,
      "loss": 0.8884,
      "step": 16130
    },
    {
      "epoch": 645.6,
      "grad_norm": 10.503159523010254,
      "learning_rate": 7.088000000000001e-06,
      "loss": 0.8295,
      "step": 16140
    },
    {
      "epoch": 646.0,
      "grad_norm": 9.116560935974121,
      "learning_rate": 7.08e-06,
      "loss": 0.8294,
      "step": 16150
    },
    {
      "epoch": 646.4,
      "grad_norm": 7.377784252166748,
      "learning_rate": 7.072000000000001e-06,
      "loss": 0.826,
      "step": 16160
    },
    {
      "epoch": 646.8,
      "grad_norm": 6.646035194396973,
      "learning_rate": 7.0640000000000005e-06,
      "loss": 0.8694,
      "step": 16170
    },
    {
      "epoch": 647.2,
      "grad_norm": 15.867865562438965,
      "learning_rate": 7.056000000000001e-06,
      "loss": 0.8483,
      "step": 16180
    },
    {
      "epoch": 647.6,
      "grad_norm": 7.53503942489624,
      "learning_rate": 7.048e-06,
      "loss": 0.8437,
      "step": 16190
    },
    {
      "epoch": 648.0,
      "grad_norm": 5.99908447265625,
      "learning_rate": 7.04e-06,
      "loss": 0.8578,
      "step": 16200
    },
    {
      "epoch": 648.4,
      "grad_norm": 7.463236331939697,
      "learning_rate": 7.0320000000000015e-06,
      "loss": 0.8315,
      "step": 16210
    },
    {
      "epoch": 648.8,
      "grad_norm": 10.32532787322998,
      "learning_rate": 7.024000000000001e-06,
      "loss": 0.8159,
      "step": 16220
    },
    {
      "epoch": 649.2,
      "grad_norm": 4.571612358093262,
      "learning_rate": 7.016e-06,
      "loss": 0.8767,
      "step": 16230
    },
    {
      "epoch": 649.6,
      "grad_norm": 10.825468063354492,
      "learning_rate": 7.0080000000000005e-06,
      "loss": 0.8438,
      "step": 16240
    },
    {
      "epoch": 650.0,
      "grad_norm": 14.763949394226074,
      "learning_rate": 7e-06,
      "loss": 0.8089,
      "step": 16250
    },
    {
      "epoch": 650.4,
      "grad_norm": 13.427189826965332,
      "learning_rate": 6.992000000000001e-06,
      "loss": 0.8477,
      "step": 16260
    },
    {
      "epoch": 650.8,
      "grad_norm": 3.814687967300415,
      "learning_rate": 6.984e-06,
      "loss": 0.8452,
      "step": 16270
    },
    {
      "epoch": 651.2,
      "grad_norm": 7.659644603729248,
      "learning_rate": 6.976000000000001e-06,
      "loss": 0.8559,
      "step": 16280
    },
    {
      "epoch": 651.6,
      "grad_norm": 6.217891693115234,
      "learning_rate": 6.968e-06,
      "loss": 0.8301,
      "step": 16290
    },
    {
      "epoch": 652.0,
      "grad_norm": 7.476480960845947,
      "learning_rate": 6.96e-06,
      "loss": 0.8329,
      "step": 16300
    },
    {
      "epoch": 652.4,
      "grad_norm": 10.409856796264648,
      "learning_rate": 6.952000000000001e-06,
      "loss": 0.8505,
      "step": 16310
    },
    {
      "epoch": 652.8,
      "grad_norm": 20.454402923583984,
      "learning_rate": 6.944000000000001e-06,
      "loss": 0.8523,
      "step": 16320
    },
    {
      "epoch": 653.2,
      "grad_norm": 6.825918197631836,
      "learning_rate": 6.936e-06,
      "loss": 0.8151,
      "step": 16330
    },
    {
      "epoch": 653.6,
      "grad_norm": 16.899972915649414,
      "learning_rate": 6.928e-06,
      "loss": 0.8308,
      "step": 16340
    },
    {
      "epoch": 654.0,
      "grad_norm": 7.62197732925415,
      "learning_rate": 6.92e-06,
      "loss": 0.8488,
      "step": 16350
    },
    {
      "epoch": 654.4,
      "grad_norm": 6.837217330932617,
      "learning_rate": 6.912000000000001e-06,
      "loss": 0.8548,
      "step": 16360
    },
    {
      "epoch": 654.8,
      "grad_norm": 14.720815658569336,
      "learning_rate": 6.904e-06,
      "loss": 0.8325,
      "step": 16370
    },
    {
      "epoch": 655.2,
      "grad_norm": 2.997769594192505,
      "learning_rate": 6.8960000000000006e-06,
      "loss": 0.8292,
      "step": 16380
    },
    {
      "epoch": 655.6,
      "grad_norm": 5.72370719909668,
      "learning_rate": 6.888e-06,
      "loss": 0.8605,
      "step": 16390
    },
    {
      "epoch": 656.0,
      "grad_norm": 3.143996477127075,
      "learning_rate": 6.88e-06,
      "loss": 0.8333,
      "step": 16400
    },
    {
      "epoch": 656.4,
      "grad_norm": 7.512335777282715,
      "learning_rate": 6.872000000000001e-06,
      "loss": 0.8375,
      "step": 16410
    },
    {
      "epoch": 656.8,
      "grad_norm": 15.577533721923828,
      "learning_rate": 6.864000000000001e-06,
      "loss": 0.8342,
      "step": 16420
    },
    {
      "epoch": 657.2,
      "grad_norm": 4.439093112945557,
      "learning_rate": 6.856e-06,
      "loss": 0.8295,
      "step": 16430
    },
    {
      "epoch": 657.6,
      "grad_norm": 11.057913780212402,
      "learning_rate": 6.848e-06,
      "loss": 0.8748,
      "step": 16440
    },
    {
      "epoch": 658.0,
      "grad_norm": 5.918006896972656,
      "learning_rate": 6.8400000000000014e-06,
      "loss": 0.8319,
      "step": 16450
    },
    {
      "epoch": 658.4,
      "grad_norm": 19.32427406311035,
      "learning_rate": 6.832000000000001e-06,
      "loss": 0.8325,
      "step": 16460
    },
    {
      "epoch": 658.8,
      "grad_norm": 3.5532643795013428,
      "learning_rate": 6.824e-06,
      "loss": 0.8291,
      "step": 16470
    },
    {
      "epoch": 659.2,
      "grad_norm": 4.384736061096191,
      "learning_rate": 6.8160000000000005e-06,
      "loss": 0.8441,
      "step": 16480
    },
    {
      "epoch": 659.6,
      "grad_norm": 3.801422357559204,
      "learning_rate": 6.808e-06,
      "loss": 0.8538,
      "step": 16490
    },
    {
      "epoch": 660.0,
      "grad_norm": 10.270151138305664,
      "learning_rate": 6.800000000000001e-06,
      "loss": 0.8376,
      "step": 16500
    },
    {
      "epoch": 660.4,
      "grad_norm": 5.634085655212402,
      "learning_rate": 6.792000000000001e-06,
      "loss": 0.8257,
      "step": 16510
    },
    {
      "epoch": 660.8,
      "grad_norm": 9.715544700622559,
      "learning_rate": 6.784000000000001e-06,
      "loss": 0.8445,
      "step": 16520
    },
    {
      "epoch": 661.2,
      "grad_norm": 11.006190299987793,
      "learning_rate": 6.776e-06,
      "loss": 0.8559,
      "step": 16530
    },
    {
      "epoch": 661.6,
      "grad_norm": 8.52719497680664,
      "learning_rate": 6.768e-06,
      "loss": 0.8474,
      "step": 16540
    },
    {
      "epoch": 662.0,
      "grad_norm": 12.567617416381836,
      "learning_rate": 6.760000000000001e-06,
      "loss": 0.823,
      "step": 16550
    },
    {
      "epoch": 662.4,
      "grad_norm": 6.046614170074463,
      "learning_rate": 6.752000000000001e-06,
      "loss": 0.8295,
      "step": 16560
    },
    {
      "epoch": 662.8,
      "grad_norm": 14.834522247314453,
      "learning_rate": 6.744e-06,
      "loss": 0.8787,
      "step": 16570
    },
    {
      "epoch": 663.2,
      "grad_norm": 17.737930297851562,
      "learning_rate": 6.736e-06,
      "loss": 0.8505,
      "step": 16580
    },
    {
      "epoch": 663.6,
      "grad_norm": 12.366992950439453,
      "learning_rate": 6.728e-06,
      "loss": 0.8432,
      "step": 16590
    },
    {
      "epoch": 664.0,
      "grad_norm": 6.3093132972717285,
      "learning_rate": 6.720000000000001e-06,
      "loss": 0.7976,
      "step": 16600
    },
    {
      "epoch": 664.4,
      "grad_norm": 13.225804328918457,
      "learning_rate": 6.712000000000001e-06,
      "loss": 0.8286,
      "step": 16610
    },
    {
      "epoch": 664.8,
      "grad_norm": 5.375145435333252,
      "learning_rate": 6.7040000000000005e-06,
      "loss": 0.8238,
      "step": 16620
    },
    {
      "epoch": 665.2,
      "grad_norm": 10.761441230773926,
      "learning_rate": 6.696e-06,
      "loss": 0.8619,
      "step": 16630
    },
    {
      "epoch": 665.6,
      "grad_norm": 4.57529354095459,
      "learning_rate": 6.688e-06,
      "loss": 0.8291,
      "step": 16640
    },
    {
      "epoch": 666.0,
      "grad_norm": 17.655088424682617,
      "learning_rate": 6.680000000000001e-06,
      "loss": 0.8311,
      "step": 16650
    },
    {
      "epoch": 666.4,
      "grad_norm": 16.24751091003418,
      "learning_rate": 6.672000000000001e-06,
      "loss": 0.8343,
      "step": 16660
    },
    {
      "epoch": 666.8,
      "grad_norm": 8.48068904876709,
      "learning_rate": 6.664e-06,
      "loss": 0.822,
      "step": 16670
    },
    {
      "epoch": 667.2,
      "grad_norm": 19.41931915283203,
      "learning_rate": 6.656e-06,
      "loss": 0.8462,
      "step": 16680
    },
    {
      "epoch": 667.6,
      "grad_norm": 6.347987174987793,
      "learning_rate": 6.648e-06,
      "loss": 0.8163,
      "step": 16690
    },
    {
      "epoch": 668.0,
      "grad_norm": 4.693879127502441,
      "learning_rate": 6.640000000000001e-06,
      "loss": 0.8097,
      "step": 16700
    },
    {
      "epoch": 668.4,
      "grad_norm": 8.856457710266113,
      "learning_rate": 6.632000000000001e-06,
      "loss": 0.8456,
      "step": 16710
    },
    {
      "epoch": 668.8,
      "grad_norm": 16.085975646972656,
      "learning_rate": 6.6240000000000004e-06,
      "loss": 0.8625,
      "step": 16720
    },
    {
      "epoch": 669.2,
      "grad_norm": 6.87312126159668,
      "learning_rate": 6.616e-06,
      "loss": 0.8189,
      "step": 16730
    },
    {
      "epoch": 669.6,
      "grad_norm": 7.97838830947876,
      "learning_rate": 6.608000000000001e-06,
      "loss": 0.8209,
      "step": 16740
    },
    {
      "epoch": 670.0,
      "grad_norm": 10.590948104858398,
      "learning_rate": 6.600000000000001e-06,
      "loss": 0.8514,
      "step": 16750
    },
    {
      "epoch": 670.4,
      "grad_norm": 4.6431779861450195,
      "learning_rate": 6.592000000000001e-06,
      "loss": 0.8498,
      "step": 16760
    },
    {
      "epoch": 670.8,
      "grad_norm": 13.316217422485352,
      "learning_rate": 6.584e-06,
      "loss": 0.8366,
      "step": 16770
    },
    {
      "epoch": 671.2,
      "grad_norm": 9.976520538330078,
      "learning_rate": 6.576e-06,
      "loss": 0.8396,
      "step": 16780
    },
    {
      "epoch": 671.6,
      "grad_norm": 14.69931411743164,
      "learning_rate": 6.568000000000001e-06,
      "loss": 0.8219,
      "step": 16790
    },
    {
      "epoch": 672.0,
      "grad_norm": 8.521327018737793,
      "learning_rate": 6.560000000000001e-06,
      "loss": 0.8278,
      "step": 16800
    },
    {
      "epoch": 672.4,
      "grad_norm": 7.343911170959473,
      "learning_rate": 6.552000000000001e-06,
      "loss": 0.859,
      "step": 16810
    },
    {
      "epoch": 672.8,
      "grad_norm": 7.496482849121094,
      "learning_rate": 6.544e-06,
      "loss": 0.8286,
      "step": 16820
    },
    {
      "epoch": 673.2,
      "grad_norm": 30.485504150390625,
      "learning_rate": 6.536e-06,
      "loss": 0.86,
      "step": 16830
    },
    {
      "epoch": 673.6,
      "grad_norm": 21.548444747924805,
      "learning_rate": 6.528000000000001e-06,
      "loss": 0.8441,
      "step": 16840
    },
    {
      "epoch": 674.0,
      "grad_norm": 4.477307319641113,
      "learning_rate": 6.520000000000001e-06,
      "loss": 0.8247,
      "step": 16850
    },
    {
      "epoch": 674.4,
      "grad_norm": 7.967494487762451,
      "learning_rate": 6.5120000000000005e-06,
      "loss": 0.8422,
      "step": 16860
    },
    {
      "epoch": 674.8,
      "grad_norm": 7.151843547821045,
      "learning_rate": 6.504e-06,
      "loss": 0.8299,
      "step": 16870
    },
    {
      "epoch": 675.2,
      "grad_norm": 19.324308395385742,
      "learning_rate": 6.496e-06,
      "loss": 0.8438,
      "step": 16880
    },
    {
      "epoch": 675.6,
      "grad_norm": 2.930842638015747,
      "learning_rate": 6.488000000000001e-06,
      "loss": 0.8099,
      "step": 16890
    },
    {
      "epoch": 676.0,
      "grad_norm": 22.104175567626953,
      "learning_rate": 6.480000000000001e-06,
      "loss": 0.853,
      "step": 16900
    },
    {
      "epoch": 676.4,
      "grad_norm": 14.857338905334473,
      "learning_rate": 6.472000000000001e-06,
      "loss": 0.8387,
      "step": 16910
    },
    {
      "epoch": 676.8,
      "grad_norm": 4.553919315338135,
      "learning_rate": 6.464e-06,
      "loss": 0.841,
      "step": 16920
    },
    {
      "epoch": 677.2,
      "grad_norm": 9.983805656433105,
      "learning_rate": 6.456e-06,
      "loss": 0.8301,
      "step": 16930
    },
    {
      "epoch": 677.6,
      "grad_norm": 14.385824203491211,
      "learning_rate": 6.448000000000001e-06,
      "loss": 0.8547,
      "step": 16940
    },
    {
      "epoch": 678.0,
      "grad_norm": 8.633440971374512,
      "learning_rate": 6.440000000000001e-06,
      "loss": 0.8573,
      "step": 16950
    },
    {
      "epoch": 678.4,
      "grad_norm": 6.5085062980651855,
      "learning_rate": 6.432e-06,
      "loss": 0.8252,
      "step": 16960
    },
    {
      "epoch": 678.8,
      "grad_norm": 12.156920433044434,
      "learning_rate": 6.424e-06,
      "loss": 0.8209,
      "step": 16970
    },
    {
      "epoch": 679.2,
      "grad_norm": 6.706252098083496,
      "learning_rate": 6.416e-06,
      "loss": 0.8327,
      "step": 16980
    },
    {
      "epoch": 679.6,
      "grad_norm": 13.411703109741211,
      "learning_rate": 6.408000000000001e-06,
      "loss": 0.8324,
      "step": 16990
    },
    {
      "epoch": 680.0,
      "grad_norm": 8.422663688659668,
      "learning_rate": 6.4000000000000006e-06,
      "loss": 0.8704,
      "step": 17000
    },
    {
      "epoch": 680.4,
      "grad_norm": 7.058432102203369,
      "learning_rate": 6.392000000000001e-06,
      "loss": 0.8483,
      "step": 17010
    },
    {
      "epoch": 680.8,
      "grad_norm": 22.6542911529541,
      "learning_rate": 6.384e-06,
      "loss": 0.8484,
      "step": 17020
    },
    {
      "epoch": 681.2,
      "grad_norm": 6.958534240722656,
      "learning_rate": 6.376e-06,
      "loss": 0.8456,
      "step": 17030
    },
    {
      "epoch": 681.6,
      "grad_norm": 9.683058738708496,
      "learning_rate": 6.368000000000001e-06,
      "loss": 0.8041,
      "step": 17040
    },
    {
      "epoch": 682.0,
      "grad_norm": 5.971777439117432,
      "learning_rate": 6.360000000000001e-06,
      "loss": 0.8344,
      "step": 17050
    },
    {
      "epoch": 682.4,
      "grad_norm": 18.074127197265625,
      "learning_rate": 6.352e-06,
      "loss": 0.8342,
      "step": 17060
    },
    {
      "epoch": 682.8,
      "grad_norm": 15.076314926147461,
      "learning_rate": 6.344e-06,
      "loss": 0.8405,
      "step": 17070
    },
    {
      "epoch": 683.2,
      "grad_norm": 13.458945274353027,
      "learning_rate": 6.336000000000001e-06,
      "loss": 0.8054,
      "step": 17080
    },
    {
      "epoch": 683.6,
      "grad_norm": 5.897821426391602,
      "learning_rate": 6.328000000000001e-06,
      "loss": 0.8332,
      "step": 17090
    },
    {
      "epoch": 684.0,
      "grad_norm": 13.040266990661621,
      "learning_rate": 6.3200000000000005e-06,
      "loss": 0.8231,
      "step": 17100
    },
    {
      "epoch": 684.4,
      "grad_norm": 3.5454633235931396,
      "learning_rate": 6.312000000000001e-06,
      "loss": 0.8619,
      "step": 17110
    },
    {
      "epoch": 684.8,
      "grad_norm": 6.8105974197387695,
      "learning_rate": 6.304e-06,
      "loss": 0.8139,
      "step": 17120
    },
    {
      "epoch": 685.2,
      "grad_norm": 5.820456027984619,
      "learning_rate": 6.296000000000001e-06,
      "loss": 0.8615,
      "step": 17130
    },
    {
      "epoch": 685.6,
      "grad_norm": 14.965657234191895,
      "learning_rate": 6.288000000000001e-06,
      "loss": 0.8201,
      "step": 17140
    },
    {
      "epoch": 686.0,
      "grad_norm": 11.279664993286133,
      "learning_rate": 6.280000000000001e-06,
      "loss": 0.8438,
      "step": 17150
    },
    {
      "epoch": 686.4,
      "grad_norm": 6.911928653717041,
      "learning_rate": 6.272e-06,
      "loss": 0.8081,
      "step": 17160
    },
    {
      "epoch": 686.8,
      "grad_norm": 6.833512783050537,
      "learning_rate": 6.264e-06,
      "loss": 0.8188,
      "step": 17170
    },
    {
      "epoch": 687.2,
      "grad_norm": 9.356614112854004,
      "learning_rate": 6.256000000000001e-06,
      "loss": 0.8436,
      "step": 17180
    },
    {
      "epoch": 687.6,
      "grad_norm": 5.42434549331665,
      "learning_rate": 6.248000000000001e-06,
      "loss": 0.8224,
      "step": 17190
    },
    {
      "epoch": 688.0,
      "grad_norm": 11.663512229919434,
      "learning_rate": 6.24e-06,
      "loss": 0.826,
      "step": 17200
    },
    {
      "epoch": 688.4,
      "grad_norm": 31.291996002197266,
      "learning_rate": 6.232000000000001e-06,
      "loss": 0.8622,
      "step": 17210
    },
    {
      "epoch": 688.8,
      "grad_norm": 7.1076178550720215,
      "learning_rate": 6.224e-06,
      "loss": 0.8466,
      "step": 17220
    },
    {
      "epoch": 689.2,
      "grad_norm": 6.1764397621154785,
      "learning_rate": 6.216000000000001e-06,
      "loss": 0.8226,
      "step": 17230
    },
    {
      "epoch": 689.6,
      "grad_norm": 3.906834602355957,
      "learning_rate": 6.2080000000000005e-06,
      "loss": 0.8655,
      "step": 17240
    },
    {
      "epoch": 690.0,
      "grad_norm": 14.042564392089844,
      "learning_rate": 6.200000000000001e-06,
      "loss": 0.8203,
      "step": 17250
    },
    {
      "epoch": 690.4,
      "grad_norm": 16.904773712158203,
      "learning_rate": 6.192e-06,
      "loss": 0.8415,
      "step": 17260
    },
    {
      "epoch": 690.8,
      "grad_norm": 6.125152111053467,
      "learning_rate": 6.184e-06,
      "loss": 0.8628,
      "step": 17270
    },
    {
      "epoch": 691.2,
      "grad_norm": 8.900650024414062,
      "learning_rate": 6.176000000000001e-06,
      "loss": 0.8067,
      "step": 17280
    },
    {
      "epoch": 691.6,
      "grad_norm": 11.253036499023438,
      "learning_rate": 6.168000000000001e-06,
      "loss": 0.8389,
      "step": 17290
    },
    {
      "epoch": 692.0,
      "grad_norm": 7.948082447052002,
      "learning_rate": 6.16e-06,
      "loss": 0.8296,
      "step": 17300
    },
    {
      "epoch": 692.4,
      "grad_norm": 8.261507034301758,
      "learning_rate": 6.1520000000000006e-06,
      "loss": 0.8606,
      "step": 17310
    },
    {
      "epoch": 692.8,
      "grad_norm": 19.655853271484375,
      "learning_rate": 6.144e-06,
      "loss": 0.8374,
      "step": 17320
    },
    {
      "epoch": 693.2,
      "grad_norm": 11.267560005187988,
      "learning_rate": 6.136000000000001e-06,
      "loss": 0.7959,
      "step": 17330
    },
    {
      "epoch": 693.6,
      "grad_norm": 4.065171718597412,
      "learning_rate": 6.1280000000000005e-06,
      "loss": 0.8233,
      "step": 17340
    },
    {
      "epoch": 694.0,
      "grad_norm": 19.377681732177734,
      "learning_rate": 6.120000000000001e-06,
      "loss": 0.8589,
      "step": 17350
    },
    {
      "epoch": 694.4,
      "grad_norm": 15.628274917602539,
      "learning_rate": 6.112e-06,
      "loss": 0.8589,
      "step": 17360
    },
    {
      "epoch": 694.8,
      "grad_norm": 11.70522403717041,
      "learning_rate": 6.104000000000001e-06,
      "loss": 0.8211,
      "step": 17370
    },
    {
      "epoch": 695.2,
      "grad_norm": 13.321576118469238,
      "learning_rate": 6.096000000000001e-06,
      "loss": 0.8058,
      "step": 17380
    },
    {
      "epoch": 695.6,
      "grad_norm": 6.251302719116211,
      "learning_rate": 6.088000000000001e-06,
      "loss": 0.8127,
      "step": 17390
    },
    {
      "epoch": 696.0,
      "grad_norm": 6.57713508605957,
      "learning_rate": 6.08e-06,
      "loss": 0.8554,
      "step": 17400
    },
    {
      "epoch": 696.4,
      "grad_norm": 7.110960006713867,
      "learning_rate": 6.0720000000000005e-06,
      "loss": 0.8416,
      "step": 17410
    },
    {
      "epoch": 696.8,
      "grad_norm": 7.987377166748047,
      "learning_rate": 6.064000000000001e-06,
      "loss": 0.8627,
      "step": 17420
    },
    {
      "epoch": 697.2,
      "grad_norm": 11.695592880249023,
      "learning_rate": 6.056000000000001e-06,
      "loss": 0.7883,
      "step": 17430
    },
    {
      "epoch": 697.6,
      "grad_norm": 9.28343391418457,
      "learning_rate": 6.048e-06,
      "loss": 0.8433,
      "step": 17440
    },
    {
      "epoch": 698.0,
      "grad_norm": 10.393367767333984,
      "learning_rate": 6.040000000000001e-06,
      "loss": 0.7932,
      "step": 17450
    },
    {
      "epoch": 698.4,
      "grad_norm": 9.53101634979248,
      "learning_rate": 6.032e-06,
      "loss": 0.8277,
      "step": 17460
    },
    {
      "epoch": 698.8,
      "grad_norm": 5.1436309814453125,
      "learning_rate": 6.024000000000001e-06,
      "loss": 0.8145,
      "step": 17470
    },
    {
      "epoch": 699.2,
      "grad_norm": 13.272014617919922,
      "learning_rate": 6.0160000000000005e-06,
      "loss": 0.8355,
      "step": 17480
    },
    {
      "epoch": 699.6,
      "grad_norm": 8.356684684753418,
      "learning_rate": 6.008000000000001e-06,
      "loss": 0.7934,
      "step": 17490
    },
    {
      "epoch": 700.0,
      "grad_norm": 16.545269012451172,
      "learning_rate": 6e-06,
      "loss": 0.8034,
      "step": 17500
    },
    {
      "epoch": 700.4,
      "grad_norm": 6.925008773803711,
      "learning_rate": 5.992e-06,
      "loss": 0.8475,
      "step": 17510
    },
    {
      "epoch": 700.8,
      "grad_norm": 6.050734043121338,
      "learning_rate": 5.984000000000001e-06,
      "loss": 0.8256,
      "step": 17520
    },
    {
      "epoch": 701.2,
      "grad_norm": 6.296371936798096,
      "learning_rate": 5.976000000000001e-06,
      "loss": 0.815,
      "step": 17530
    },
    {
      "epoch": 701.6,
      "grad_norm": 10.770489692687988,
      "learning_rate": 5.968e-06,
      "loss": 0.8144,
      "step": 17540
    },
    {
      "epoch": 702.0,
      "grad_norm": 18.46950340270996,
      "learning_rate": 5.9600000000000005e-06,
      "loss": 0.8431,
      "step": 17550
    },
    {
      "epoch": 702.4,
      "grad_norm": 10.455205917358398,
      "learning_rate": 5.952e-06,
      "loss": 0.8456,
      "step": 17560
    },
    {
      "epoch": 702.8,
      "grad_norm": 4.126293659210205,
      "learning_rate": 5.944000000000001e-06,
      "loss": 0.7939,
      "step": 17570
    },
    {
      "epoch": 703.2,
      "grad_norm": 5.830748558044434,
      "learning_rate": 5.9360000000000004e-06,
      "loss": 0.811,
      "step": 17580
    },
    {
      "epoch": 703.6,
      "grad_norm": 9.087323188781738,
      "learning_rate": 5.928000000000001e-06,
      "loss": 0.8126,
      "step": 17590
    },
    {
      "epoch": 704.0,
      "grad_norm": 13.761924743652344,
      "learning_rate": 5.92e-06,
      "loss": 0.8573,
      "step": 17600
    },
    {
      "epoch": 704.4,
      "grad_norm": 8.2489013671875,
      "learning_rate": 5.912e-06,
      "loss": 0.8316,
      "step": 17610
    },
    {
      "epoch": 704.8,
      "grad_norm": 5.173110008239746,
      "learning_rate": 5.9040000000000006e-06,
      "loss": 0.8102,
      "step": 17620
    },
    {
      "epoch": 705.2,
      "grad_norm": 4.299678325653076,
      "learning_rate": 5.896000000000001e-06,
      "loss": 0.8313,
      "step": 17630
    },
    {
      "epoch": 705.6,
      "grad_norm": 5.143426418304443,
      "learning_rate": 5.888e-06,
      "loss": 0.8285,
      "step": 17640
    },
    {
      "epoch": 706.0,
      "grad_norm": 14.130826950073242,
      "learning_rate": 5.8800000000000005e-06,
      "loss": 0.829,
      "step": 17650
    },
    {
      "epoch": 706.4,
      "grad_norm": 14.511556625366211,
      "learning_rate": 5.872000000000001e-06,
      "loss": 0.8184,
      "step": 17660
    },
    {
      "epoch": 706.8,
      "grad_norm": 9.416423797607422,
      "learning_rate": 5.864000000000001e-06,
      "loss": 0.8267,
      "step": 17670
    },
    {
      "epoch": 707.2,
      "grad_norm": 18.314849853515625,
      "learning_rate": 5.856e-06,
      "loss": 0.8242,
      "step": 17680
    },
    {
      "epoch": 707.6,
      "grad_norm": 22.67991828918457,
      "learning_rate": 5.848000000000001e-06,
      "loss": 0.8645,
      "step": 17690
    },
    {
      "epoch": 708.0,
      "grad_norm": 33.8486442565918,
      "learning_rate": 5.84e-06,
      "loss": 0.8343,
      "step": 17700
    },
    {
      "epoch": 708.4,
      "grad_norm": 11.286436080932617,
      "learning_rate": 5.832000000000001e-06,
      "loss": 0.7851,
      "step": 17710
    },
    {
      "epoch": 708.8,
      "grad_norm": 14.30686092376709,
      "learning_rate": 5.8240000000000005e-06,
      "loss": 0.8751,
      "step": 17720
    },
    {
      "epoch": 709.2,
      "grad_norm": 8.087483406066895,
      "learning_rate": 5.816000000000001e-06,
      "loss": 0.8576,
      "step": 17730
    },
    {
      "epoch": 709.6,
      "grad_norm": 5.475753307342529,
      "learning_rate": 5.808e-06,
      "loss": 0.7811,
      "step": 17740
    },
    {
      "epoch": 710.0,
      "grad_norm": 20.5253849029541,
      "learning_rate": 5.8e-06,
      "loss": 0.8465,
      "step": 17750
    },
    {
      "epoch": 710.4,
      "grad_norm": 5.090210914611816,
      "learning_rate": 5.792000000000001e-06,
      "loss": 0.8165,
      "step": 17760
    },
    {
      "epoch": 710.8,
      "grad_norm": 6.322272300720215,
      "learning_rate": 5.784000000000001e-06,
      "loss": 0.8024,
      "step": 17770
    },
    {
      "epoch": 711.2,
      "grad_norm": 11.015230178833008,
      "learning_rate": 5.776e-06,
      "loss": 0.8092,
      "step": 17780
    },
    {
      "epoch": 711.6,
      "grad_norm": 6.10325288772583,
      "learning_rate": 5.7680000000000005e-06,
      "loss": 0.8505,
      "step": 17790
    },
    {
      "epoch": 712.0,
      "grad_norm": 18.660505294799805,
      "learning_rate": 5.76e-06,
      "loss": 0.8165,
      "step": 17800
    },
    {
      "epoch": 712.4,
      "grad_norm": 7.952960968017578,
      "learning_rate": 5.752000000000001e-06,
      "loss": 0.8373,
      "step": 17810
    },
    {
      "epoch": 712.8,
      "grad_norm": 5.7766265869140625,
      "learning_rate": 5.744e-06,
      "loss": 0.7969,
      "step": 17820
    },
    {
      "epoch": 713.2,
      "grad_norm": 11.052560806274414,
      "learning_rate": 5.736000000000001e-06,
      "loss": 0.8251,
      "step": 17830
    },
    {
      "epoch": 713.6,
      "grad_norm": 6.189337730407715,
      "learning_rate": 5.728e-06,
      "loss": 0.7964,
      "step": 17840
    },
    {
      "epoch": 714.0,
      "grad_norm": 9.271439552307129,
      "learning_rate": 5.72e-06,
      "loss": 0.8164,
      "step": 17850
    },
    {
      "epoch": 714.4,
      "grad_norm": 16.93704605102539,
      "learning_rate": 5.7120000000000005e-06,
      "loss": 0.8419,
      "step": 17860
    },
    {
      "epoch": 714.8,
      "grad_norm": 7.704946517944336,
      "learning_rate": 5.704000000000001e-06,
      "loss": 0.8048,
      "step": 17870
    },
    {
      "epoch": 715.2,
      "grad_norm": 4.305048942565918,
      "learning_rate": 5.696e-06,
      "loss": 0.8593,
      "step": 17880
    },
    {
      "epoch": 715.6,
      "grad_norm": 9.034791946411133,
      "learning_rate": 5.6880000000000004e-06,
      "loss": 0.8038,
      "step": 17890
    },
    {
      "epoch": 716.0,
      "grad_norm": 14.312392234802246,
      "learning_rate": 5.68e-06,
      "loss": 0.8152,
      "step": 17900
    },
    {
      "epoch": 716.4,
      "grad_norm": 24.36630630493164,
      "learning_rate": 5.672000000000001e-06,
      "loss": 0.803,
      "step": 17910
    },
    {
      "epoch": 716.8,
      "grad_norm": 5.818095684051514,
      "learning_rate": 5.664e-06,
      "loss": 0.8277,
      "step": 17920
    },
    {
      "epoch": 717.2,
      "grad_norm": 8.777472496032715,
      "learning_rate": 5.6560000000000006e-06,
      "loss": 0.8583,
      "step": 17930
    },
    {
      "epoch": 717.6,
      "grad_norm": 13.7881441116333,
      "learning_rate": 5.648e-06,
      "loss": 0.8397,
      "step": 17940
    },
    {
      "epoch": 718.0,
      "grad_norm": 11.051136016845703,
      "learning_rate": 5.64e-06,
      "loss": 0.7954,
      "step": 17950
    },
    {
      "epoch": 718.4,
      "grad_norm": 6.82755184173584,
      "learning_rate": 5.6320000000000005e-06,
      "loss": 0.825,
      "step": 17960
    },
    {
      "epoch": 718.8,
      "grad_norm": 8.62199592590332,
      "learning_rate": 5.624000000000001e-06,
      "loss": 0.8145,
      "step": 17970
    },
    {
      "epoch": 719.2,
      "grad_norm": 16.576292037963867,
      "learning_rate": 5.616e-06,
      "loss": 0.834,
      "step": 17980
    },
    {
      "epoch": 719.6,
      "grad_norm": 19.55027198791504,
      "learning_rate": 5.608e-06,
      "loss": 0.8056,
      "step": 17990
    },
    {
      "epoch": 720.0,
      "grad_norm": 11.073349952697754,
      "learning_rate": 5.600000000000001e-06,
      "loss": 0.8518,
      "step": 18000
    },
    {
      "epoch": 720.4,
      "grad_norm": 10.956095695495605,
      "learning_rate": 5.592000000000001e-06,
      "loss": 0.8015,
      "step": 18010
    },
    {
      "epoch": 720.8,
      "grad_norm": 12.336374282836914,
      "learning_rate": 5.584e-06,
      "loss": 0.8079,
      "step": 18020
    },
    {
      "epoch": 721.2,
      "grad_norm": 16.2200927734375,
      "learning_rate": 5.5760000000000005e-06,
      "loss": 0.8377,
      "step": 18030
    },
    {
      "epoch": 721.6,
      "grad_norm": 7.134943962097168,
      "learning_rate": 5.568e-06,
      "loss": 0.8008,
      "step": 18040
    },
    {
      "epoch": 722.0,
      "grad_norm": 21.729251861572266,
      "learning_rate": 5.560000000000001e-06,
      "loss": 0.7993,
      "step": 18050
    },
    {
      "epoch": 722.4,
      "grad_norm": 10.007316589355469,
      "learning_rate": 5.552e-06,
      "loss": 0.8303,
      "step": 18060
    },
    {
      "epoch": 722.8,
      "grad_norm": 8.7395601272583,
      "learning_rate": 5.544000000000001e-06,
      "loss": 0.8192,
      "step": 18070
    },
    {
      "epoch": 723.2,
      "grad_norm": 8.770408630371094,
      "learning_rate": 5.536e-06,
      "loss": 0.8345,
      "step": 18080
    },
    {
      "epoch": 723.6,
      "grad_norm": 6.140044689178467,
      "learning_rate": 5.528e-06,
      "loss": 0.809,
      "step": 18090
    },
    {
      "epoch": 724.0,
      "grad_norm": 7.843530178070068,
      "learning_rate": 5.5200000000000005e-06,
      "loss": 0.8165,
      "step": 18100
    },
    {
      "epoch": 724.4,
      "grad_norm": 12.357039451599121,
      "learning_rate": 5.512000000000001e-06,
      "loss": 0.7849,
      "step": 18110
    },
    {
      "epoch": 724.8,
      "grad_norm": 7.170350551605225,
      "learning_rate": 5.504e-06,
      "loss": 0.8169,
      "step": 18120
    },
    {
      "epoch": 725.2,
      "grad_norm": 9.638062477111816,
      "learning_rate": 5.496e-06,
      "loss": 0.8465,
      "step": 18130
    },
    {
      "epoch": 725.6,
      "grad_norm": 5.164151668548584,
      "learning_rate": 5.488e-06,
      "loss": 0.847,
      "step": 18140
    },
    {
      "epoch": 726.0,
      "grad_norm": 12.670552253723145,
      "learning_rate": 5.480000000000001e-06,
      "loss": 0.7967,
      "step": 18150
    },
    {
      "epoch": 726.4,
      "grad_norm": 10.185978889465332,
      "learning_rate": 5.472e-06,
      "loss": 0.8251,
      "step": 18160
    },
    {
      "epoch": 726.8,
      "grad_norm": 12.94162654876709,
      "learning_rate": 5.4640000000000005e-06,
      "loss": 0.8343,
      "step": 18170
    },
    {
      "epoch": 727.2,
      "grad_norm": 16.8023738861084,
      "learning_rate": 5.456e-06,
      "loss": 0.8335,
      "step": 18180
    },
    {
      "epoch": 727.6,
      "grad_norm": 15.447465896606445,
      "learning_rate": 5.448e-06,
      "loss": 0.82,
      "step": 18190
    },
    {
      "epoch": 728.0,
      "grad_norm": 12.871554374694824,
      "learning_rate": 5.4400000000000004e-06,
      "loss": 0.8413,
      "step": 18200
    },
    {
      "epoch": 728.4,
      "grad_norm": 10.124979019165039,
      "learning_rate": 5.432000000000001e-06,
      "loss": 0.8181,
      "step": 18210
    },
    {
      "epoch": 728.8,
      "grad_norm": 9.70885181427002,
      "learning_rate": 5.424e-06,
      "loss": 0.798,
      "step": 18220
    },
    {
      "epoch": 729.2,
      "grad_norm": 4.841791152954102,
      "learning_rate": 5.416e-06,
      "loss": 0.8025,
      "step": 18230
    },
    {
      "epoch": 729.6,
      "grad_norm": 13.38713550567627,
      "learning_rate": 5.408e-06,
      "loss": 0.8351,
      "step": 18240
    },
    {
      "epoch": 730.0,
      "grad_norm": 9.160745620727539,
      "learning_rate": 5.400000000000001e-06,
      "loss": 0.8338,
      "step": 18250
    },
    {
      "epoch": 730.4,
      "grad_norm": 11.823646545410156,
      "learning_rate": 5.392e-06,
      "loss": 0.8163,
      "step": 18260
    },
    {
      "epoch": 730.8,
      "grad_norm": 3.962827205657959,
      "learning_rate": 5.3840000000000005e-06,
      "loss": 0.7886,
      "step": 18270
    },
    {
      "epoch": 731.2,
      "grad_norm": 10.891237258911133,
      "learning_rate": 5.376e-06,
      "loss": 0.7893,
      "step": 18280
    },
    {
      "epoch": 731.6,
      "grad_norm": 8.478927612304688,
      "learning_rate": 5.368000000000001e-06,
      "loss": 0.7842,
      "step": 18290
    },
    {
      "epoch": 732.0,
      "grad_norm": 12.11449909210205,
      "learning_rate": 5.36e-06,
      "loss": 0.8168,
      "step": 18300
    },
    {
      "epoch": 732.4,
      "grad_norm": 7.606583118438721,
      "learning_rate": 5.352000000000001e-06,
      "loss": 0.8211,
      "step": 18310
    },
    {
      "epoch": 732.8,
      "grad_norm": 14.647987365722656,
      "learning_rate": 5.344e-06,
      "loss": 0.8032,
      "step": 18320
    },
    {
      "epoch": 733.2,
      "grad_norm": 4.244625091552734,
      "learning_rate": 5.336e-06,
      "loss": 0.8215,
      "step": 18330
    },
    {
      "epoch": 733.6,
      "grad_norm": 16.82962417602539,
      "learning_rate": 5.328000000000001e-06,
      "loss": 0.836,
      "step": 18340
    },
    {
      "epoch": 734.0,
      "grad_norm": 9.138935089111328,
      "learning_rate": 5.320000000000001e-06,
      "loss": 0.8106,
      "step": 18350
    },
    {
      "epoch": 734.4,
      "grad_norm": 4.881134033203125,
      "learning_rate": 5.312e-06,
      "loss": 0.8086,
      "step": 18360
    },
    {
      "epoch": 734.8,
      "grad_norm": 12.299165725708008,
      "learning_rate": 5.304e-06,
      "loss": 0.8145,
      "step": 18370
    },
    {
      "epoch": 735.2,
      "grad_norm": 4.504164218902588,
      "learning_rate": 5.296e-06,
      "loss": 0.7804,
      "step": 18380
    },
    {
      "epoch": 735.6,
      "grad_norm": 11.885092735290527,
      "learning_rate": 5.288000000000001e-06,
      "loss": 0.7876,
      "step": 18390
    },
    {
      "epoch": 736.0,
      "grad_norm": 4.072213649749756,
      "learning_rate": 5.28e-06,
      "loss": 0.8039,
      "step": 18400
    },
    {
      "epoch": 736.4,
      "grad_norm": 7.372979640960693,
      "learning_rate": 5.2720000000000005e-06,
      "loss": 0.7942,
      "step": 18410
    },
    {
      "epoch": 736.8,
      "grad_norm": 7.147414207458496,
      "learning_rate": 5.264e-06,
      "loss": 0.845,
      "step": 18420
    },
    {
      "epoch": 737.2,
      "grad_norm": 8.250879287719727,
      "learning_rate": 5.256e-06,
      "loss": 0.8049,
      "step": 18430
    },
    {
      "epoch": 737.6,
      "grad_norm": 24.06902313232422,
      "learning_rate": 5.248000000000001e-06,
      "loss": 0.8169,
      "step": 18440
    },
    {
      "epoch": 738.0,
      "grad_norm": 12.13149356842041,
      "learning_rate": 5.240000000000001e-06,
      "loss": 0.7958,
      "step": 18450
    },
    {
      "epoch": 738.4,
      "grad_norm": 4.668342590332031,
      "learning_rate": 5.232e-06,
      "loss": 0.811,
      "step": 18460
    },
    {
      "epoch": 738.8,
      "grad_norm": 15.882471084594727,
      "learning_rate": 5.224e-06,
      "loss": 0.8205,
      "step": 18470
    },
    {
      "epoch": 739.2,
      "grad_norm": 9.66341781616211,
      "learning_rate": 5.216e-06,
      "loss": 0.8453,
      "step": 18480
    },
    {
      "epoch": 739.6,
      "grad_norm": 7.882616996765137,
      "learning_rate": 5.208000000000001e-06,
      "loss": 0.8168,
      "step": 18490
    },
    {
      "epoch": 740.0,
      "grad_norm": 18.83534049987793,
      "learning_rate": 5.2e-06,
      "loss": 0.8372,
      "step": 18500
    },
    {
      "epoch": 740.4,
      "grad_norm": 4.752108573913574,
      "learning_rate": 5.1920000000000004e-06,
      "loss": 0.8052,
      "step": 18510
    },
    {
      "epoch": 740.8,
      "grad_norm": 14.391792297363281,
      "learning_rate": 5.184e-06,
      "loss": 0.8312,
      "step": 18520
    },
    {
      "epoch": 741.2,
      "grad_norm": 10.848126411437988,
      "learning_rate": 5.176e-06,
      "loss": 0.7816,
      "step": 18530
    },
    {
      "epoch": 741.6,
      "grad_norm": 8.857733726501465,
      "learning_rate": 5.168000000000001e-06,
      "loss": 0.8304,
      "step": 18540
    },
    {
      "epoch": 742.0,
      "grad_norm": 9.891890525817871,
      "learning_rate": 5.1600000000000006e-06,
      "loss": 0.8067,
      "step": 18550
    },
    {
      "epoch": 742.4,
      "grad_norm": 15.274304389953613,
      "learning_rate": 5.152e-06,
      "loss": 0.8174,
      "step": 18560
    },
    {
      "epoch": 742.8,
      "grad_norm": 8.672354698181152,
      "learning_rate": 5.144e-06,
      "loss": 0.8584,
      "step": 18570
    },
    {
      "epoch": 743.2,
      "grad_norm": 20.37812042236328,
      "learning_rate": 5.136e-06,
      "loss": 0.8158,
      "step": 18580
    },
    {
      "epoch": 743.6,
      "grad_norm": 10.377607345581055,
      "learning_rate": 5.128000000000001e-06,
      "loss": 0.8275,
      "step": 18590
    },
    {
      "epoch": 744.0,
      "grad_norm": 10.297033309936523,
      "learning_rate": 5.12e-06,
      "loss": 0.8257,
      "step": 18600
    },
    {
      "epoch": 744.4,
      "grad_norm": 9.977761268615723,
      "learning_rate": 5.112e-06,
      "loss": 0.8124,
      "step": 18610
    },
    {
      "epoch": 744.8,
      "grad_norm": 12.465953826904297,
      "learning_rate": 5.104e-06,
      "loss": 0.8217,
      "step": 18620
    },
    {
      "epoch": 745.2,
      "grad_norm": 16.272390365600586,
      "learning_rate": 5.096000000000001e-06,
      "loss": 0.7935,
      "step": 18630
    },
    {
      "epoch": 745.6,
      "grad_norm": 7.1356401443481445,
      "learning_rate": 5.088000000000001e-06,
      "loss": 0.825,
      "step": 18640
    },
    {
      "epoch": 746.0,
      "grad_norm": 8.847701072692871,
      "learning_rate": 5.0800000000000005e-06,
      "loss": 0.7949,
      "step": 18650
    },
    {
      "epoch": 746.4,
      "grad_norm": 6.1527323722839355,
      "learning_rate": 5.072e-06,
      "loss": 0.8037,
      "step": 18660
    },
    {
      "epoch": 746.8,
      "grad_norm": 11.769123077392578,
      "learning_rate": 5.064e-06,
      "loss": 0.8001,
      "step": 18670
    },
    {
      "epoch": 747.2,
      "grad_norm": 10.146403312683105,
      "learning_rate": 5.056000000000001e-06,
      "loss": 0.8567,
      "step": 18680
    },
    {
      "epoch": 747.6,
      "grad_norm": 7.203621864318848,
      "learning_rate": 5.048000000000001e-06,
      "loss": 0.7968,
      "step": 18690
    },
    {
      "epoch": 748.0,
      "grad_norm": 13.826766014099121,
      "learning_rate": 5.04e-06,
      "loss": 0.8325,
      "step": 18700
    },
    {
      "epoch": 748.4,
      "grad_norm": 7.499892711639404,
      "learning_rate": 5.032e-06,
      "loss": 0.8034,
      "step": 18710
    },
    {
      "epoch": 748.8,
      "grad_norm": 6.598250389099121,
      "learning_rate": 5.024e-06,
      "loss": 0.8023,
      "step": 18720
    },
    {
      "epoch": 749.2,
      "grad_norm": 9.241373062133789,
      "learning_rate": 5.016000000000001e-06,
      "loss": 0.834,
      "step": 18730
    },
    {
      "epoch": 749.6,
      "grad_norm": 13.966523170471191,
      "learning_rate": 5.008000000000001e-06,
      "loss": 0.8124,
      "step": 18740
    },
    {
      "epoch": 750.0,
      "grad_norm": 4.48238468170166,
      "learning_rate": 5e-06,
      "loss": 0.7861,
      "step": 18750
    },
    {
      "epoch": 750.4,
      "grad_norm": 4.588697910308838,
      "learning_rate": 4.992e-06,
      "loss": 0.7994,
      "step": 18760
    },
    {
      "epoch": 750.8,
      "grad_norm": 19.424400329589844,
      "learning_rate": 4.984000000000001e-06,
      "loss": 0.8231,
      "step": 18770
    },
    {
      "epoch": 751.2,
      "grad_norm": 4.739760875701904,
      "learning_rate": 4.976e-06,
      "loss": 0.8122,
      "step": 18780
    },
    {
      "epoch": 751.6,
      "grad_norm": 14.954314231872559,
      "learning_rate": 4.9680000000000005e-06,
      "loss": 0.8251,
      "step": 18790
    },
    {
      "epoch": 752.0,
      "grad_norm": 16.694061279296875,
      "learning_rate": 4.960000000000001e-06,
      "loss": 0.8418,
      "step": 18800
    },
    {
      "epoch": 752.4,
      "grad_norm": 3.954472303390503,
      "learning_rate": 4.952e-06,
      "loss": 0.7955,
      "step": 18810
    },
    {
      "epoch": 752.8,
      "grad_norm": 6.559010028839111,
      "learning_rate": 4.9440000000000004e-06,
      "loss": 0.8401,
      "step": 18820
    },
    {
      "epoch": 753.2,
      "grad_norm": 4.6456217765808105,
      "learning_rate": 4.936e-06,
      "loss": 0.8085,
      "step": 18830
    },
    {
      "epoch": 753.6,
      "grad_norm": 9.261679649353027,
      "learning_rate": 4.928000000000001e-06,
      "loss": 0.8139,
      "step": 18840
    },
    {
      "epoch": 754.0,
      "grad_norm": 34.829307556152344,
      "learning_rate": 4.92e-06,
      "loss": 0.8261,
      "step": 18850
    },
    {
      "epoch": 754.4,
      "grad_norm": 4.564137935638428,
      "learning_rate": 4.9120000000000006e-06,
      "loss": 0.8076,
      "step": 18860
    },
    {
      "epoch": 754.8,
      "grad_norm": 8.835457801818848,
      "learning_rate": 4.904000000000001e-06,
      "loss": 0.8249,
      "step": 18870
    },
    {
      "epoch": 755.2,
      "grad_norm": 9.494025230407715,
      "learning_rate": 4.896e-06,
      "loss": 0.7615,
      "step": 18880
    },
    {
      "epoch": 755.6,
      "grad_norm": 6.94295597076416,
      "learning_rate": 4.8880000000000005e-06,
      "loss": 0.819,
      "step": 18890
    },
    {
      "epoch": 756.0,
      "grad_norm": 4.518287181854248,
      "learning_rate": 4.880000000000001e-06,
      "loss": 0.8074,
      "step": 18900
    },
    {
      "epoch": 756.4,
      "grad_norm": 5.907440185546875,
      "learning_rate": 4.872000000000001e-06,
      "loss": 0.8096,
      "step": 18910
    },
    {
      "epoch": 756.8,
      "grad_norm": 16.063751220703125,
      "learning_rate": 4.864e-06,
      "loss": 0.7995,
      "step": 18920
    },
    {
      "epoch": 757.2,
      "grad_norm": 18.33725929260254,
      "learning_rate": 4.856e-06,
      "loss": 0.8156,
      "step": 18930
    },
    {
      "epoch": 757.6,
      "grad_norm": 6.07056999206543,
      "learning_rate": 4.848000000000001e-06,
      "loss": 0.7946,
      "step": 18940
    },
    {
      "epoch": 758.0,
      "grad_norm": 12.680381774902344,
      "learning_rate": 4.84e-06,
      "loss": 0.8035,
      "step": 18950
    },
    {
      "epoch": 758.4,
      "grad_norm": 11.138148307800293,
      "learning_rate": 4.8320000000000005e-06,
      "loss": 0.8125,
      "step": 18960
    },
    {
      "epoch": 758.8,
      "grad_norm": 6.093008518218994,
      "learning_rate": 4.824000000000001e-06,
      "loss": 0.7776,
      "step": 18970
    },
    {
      "epoch": 759.2,
      "grad_norm": 6.58022403717041,
      "learning_rate": 4.816e-06,
      "loss": 0.8331,
      "step": 18980
    },
    {
      "epoch": 759.6,
      "grad_norm": 5.602542877197266,
      "learning_rate": 4.808e-06,
      "loss": 0.7988,
      "step": 18990
    },
    {
      "epoch": 760.0,
      "grad_norm": 15.610998153686523,
      "learning_rate": 4.800000000000001e-06,
      "loss": 0.8569,
      "step": 19000
    },
    {
      "epoch": 760.4,
      "grad_norm": 9.004598617553711,
      "learning_rate": 4.792000000000001e-06,
      "loss": 0.8146,
      "step": 19010
    },
    {
      "epoch": 760.8,
      "grad_norm": 3.8369314670562744,
      "learning_rate": 4.784e-06,
      "loss": 0.794,
      "step": 19020
    },
    {
      "epoch": 761.2,
      "grad_norm": 6.845071315765381,
      "learning_rate": 4.7760000000000005e-06,
      "loss": 0.8161,
      "step": 19030
    },
    {
      "epoch": 761.6,
      "grad_norm": 14.419590950012207,
      "learning_rate": 4.768000000000001e-06,
      "loss": 0.791,
      "step": 19040
    },
    {
      "epoch": 762.0,
      "grad_norm": 21.81223487854004,
      "learning_rate": 4.76e-06,
      "loss": 0.8613,
      "step": 19050
    },
    {
      "epoch": 762.4,
      "grad_norm": 31.81532859802246,
      "learning_rate": 4.752e-06,
      "loss": 0.7997,
      "step": 19060
    },
    {
      "epoch": 762.8,
      "grad_norm": 3.0966238975524902,
      "learning_rate": 4.744000000000001e-06,
      "loss": 0.8145,
      "step": 19070
    },
    {
      "epoch": 763.2,
      "grad_norm": 5.732767105102539,
      "learning_rate": 4.736000000000001e-06,
      "loss": 0.8556,
      "step": 19080
    },
    {
      "epoch": 763.6,
      "grad_norm": 22.648656845092773,
      "learning_rate": 4.728e-06,
      "loss": 0.8204,
      "step": 19090
    },
    {
      "epoch": 764.0,
      "grad_norm": 11.126310348510742,
      "learning_rate": 4.7200000000000005e-06,
      "loss": 0.7967,
      "step": 19100
    },
    {
      "epoch": 764.4,
      "grad_norm": 26.71663475036621,
      "learning_rate": 4.712000000000001e-06,
      "loss": 0.8253,
      "step": 19110
    },
    {
      "epoch": 764.8,
      "grad_norm": 12.318402290344238,
      "learning_rate": 4.704e-06,
      "loss": 0.8056,
      "step": 19120
    },
    {
      "epoch": 765.2,
      "grad_norm": 9.950844764709473,
      "learning_rate": 4.6960000000000004e-06,
      "loss": 0.8256,
      "step": 19130
    },
    {
      "epoch": 765.6,
      "grad_norm": 8.435857772827148,
      "learning_rate": 4.688000000000001e-06,
      "loss": 0.8403,
      "step": 19140
    },
    {
      "epoch": 766.0,
      "grad_norm": 6.084391117095947,
      "learning_rate": 4.680000000000001e-06,
      "loss": 0.7946,
      "step": 19150
    },
    {
      "epoch": 766.4,
      "grad_norm": 13.074101448059082,
      "learning_rate": 4.672e-06,
      "loss": 0.8627,
      "step": 19160
    },
    {
      "epoch": 766.8,
      "grad_norm": 6.767658710479736,
      "learning_rate": 4.664000000000001e-06,
      "loss": 0.7976,
      "step": 19170
    },
    {
      "epoch": 767.2,
      "grad_norm": 5.789016246795654,
      "learning_rate": 4.656000000000001e-06,
      "loss": 0.8155,
      "step": 19180
    },
    {
      "epoch": 767.6,
      "grad_norm": 7.840013027191162,
      "learning_rate": 4.648e-06,
      "loss": 0.8572,
      "step": 19190
    },
    {
      "epoch": 768.0,
      "grad_norm": 16.242401123046875,
      "learning_rate": 4.6400000000000005e-06,
      "loss": 0.7928,
      "step": 19200
    },
    {
      "epoch": 768.4,
      "grad_norm": 12.623299598693848,
      "learning_rate": 4.632000000000001e-06,
      "loss": 0.8024,
      "step": 19210
    },
    {
      "epoch": 768.8,
      "grad_norm": 8.72884750366211,
      "learning_rate": 4.624e-06,
      "loss": 0.8169,
      "step": 19220
    },
    {
      "epoch": 769.2,
      "grad_norm": 8.849178314208984,
      "learning_rate": 4.616e-06,
      "loss": 0.8181,
      "step": 19230
    },
    {
      "epoch": 769.6,
      "grad_norm": 5.768557071685791,
      "learning_rate": 4.608000000000001e-06,
      "loss": 0.8033,
      "step": 19240
    },
    {
      "epoch": 770.0,
      "grad_norm": 8.70489501953125,
      "learning_rate": 4.600000000000001e-06,
      "loss": 0.8319,
      "step": 19250
    },
    {
      "epoch": 770.4,
      "grad_norm": 6.887990951538086,
      "learning_rate": 4.592e-06,
      "loss": 0.8229,
      "step": 19260
    },
    {
      "epoch": 770.8,
      "grad_norm": 11.18449592590332,
      "learning_rate": 4.5840000000000005e-06,
      "loss": 0.7674,
      "step": 19270
    },
    {
      "epoch": 771.2,
      "grad_norm": 8.319316864013672,
      "learning_rate": 4.576000000000001e-06,
      "loss": 0.8485,
      "step": 19280
    },
    {
      "epoch": 771.6,
      "grad_norm": 5.227421283721924,
      "learning_rate": 4.568e-06,
      "loss": 0.8192,
      "step": 19290
    },
    {
      "epoch": 772.0,
      "grad_norm": 14.880298614501953,
      "learning_rate": 4.56e-06,
      "loss": 0.8306,
      "step": 19300
    },
    {
      "epoch": 772.4,
      "grad_norm": 12.698470115661621,
      "learning_rate": 4.552000000000001e-06,
      "loss": 0.8383,
      "step": 19310
    },
    {
      "epoch": 772.8,
      "grad_norm": 10.297728538513184,
      "learning_rate": 4.544000000000001e-06,
      "loss": 0.8501,
      "step": 19320
    },
    {
      "epoch": 773.2,
      "grad_norm": 12.666500091552734,
      "learning_rate": 4.536e-06,
      "loss": 0.8078,
      "step": 19330
    },
    {
      "epoch": 773.6,
      "grad_norm": 13.09741497039795,
      "learning_rate": 4.5280000000000005e-06,
      "loss": 0.8105,
      "step": 19340
    },
    {
      "epoch": 774.0,
      "grad_norm": 7.272715091705322,
      "learning_rate": 4.520000000000001e-06,
      "loss": 0.8062,
      "step": 19350
    },
    {
      "epoch": 774.4,
      "grad_norm": 4.85734224319458,
      "learning_rate": 4.512e-06,
      "loss": 0.8114,
      "step": 19360
    },
    {
      "epoch": 774.8,
      "grad_norm": 8.82470989227295,
      "learning_rate": 4.504e-06,
      "loss": 0.789,
      "step": 19370
    },
    {
      "epoch": 775.2,
      "grad_norm": 7.330623626708984,
      "learning_rate": 4.496000000000001e-06,
      "loss": 0.7827,
      "step": 19380
    },
    {
      "epoch": 775.6,
      "grad_norm": 3.672119617462158,
      "learning_rate": 4.488e-06,
      "loss": 0.8063,
      "step": 19390
    },
    {
      "epoch": 776.0,
      "grad_norm": 17.757638931274414,
      "learning_rate": 4.48e-06,
      "loss": 0.8315,
      "step": 19400
    },
    {
      "epoch": 776.4,
      "grad_norm": 3.469168186187744,
      "learning_rate": 4.4720000000000006e-06,
      "loss": 0.7916,
      "step": 19410
    },
    {
      "epoch": 776.8,
      "grad_norm": 14.917825698852539,
      "learning_rate": 4.464000000000001e-06,
      "loss": 0.829,
      "step": 19420
    },
    {
      "epoch": 777.2,
      "grad_norm": 3.701364755630493,
      "learning_rate": 4.456e-06,
      "loss": 0.7993,
      "step": 19430
    },
    {
      "epoch": 777.6,
      "grad_norm": 27.55936050415039,
      "learning_rate": 4.4480000000000004e-06,
      "loss": 0.7899,
      "step": 19440
    },
    {
      "epoch": 778.0,
      "grad_norm": 7.316556453704834,
      "learning_rate": 4.440000000000001e-06,
      "loss": 0.7946,
      "step": 19450
    },
    {
      "epoch": 778.4,
      "grad_norm": 7.235353469848633,
      "learning_rate": 4.432e-06,
      "loss": 0.8154,
      "step": 19460
    },
    {
      "epoch": 778.8,
      "grad_norm": 12.45262336730957,
      "learning_rate": 4.424e-06,
      "loss": 0.7977,
      "step": 19470
    },
    {
      "epoch": 779.2,
      "grad_norm": 18.882261276245117,
      "learning_rate": 4.416000000000001e-06,
      "loss": 0.7921,
      "step": 19480
    },
    {
      "epoch": 779.6,
      "grad_norm": 5.792468070983887,
      "learning_rate": 4.408000000000001e-06,
      "loss": 0.8076,
      "step": 19490
    },
    {
      "epoch": 780.0,
      "grad_norm": 10.700640678405762,
      "learning_rate": 4.4e-06,
      "loss": 0.8513,
      "step": 19500
    },
    {
      "epoch": 780.4,
      "grad_norm": 6.365198135375977,
      "learning_rate": 4.3920000000000005e-06,
      "loss": 0.8351,
      "step": 19510
    },
    {
      "epoch": 780.8,
      "grad_norm": 7.989956378936768,
      "learning_rate": 4.384000000000001e-06,
      "loss": 0.7927,
      "step": 19520
    },
    {
      "epoch": 781.2,
      "grad_norm": 4.558363437652588,
      "learning_rate": 4.376e-06,
      "loss": 0.7866,
      "step": 19530
    },
    {
      "epoch": 781.6,
      "grad_norm": 13.965413093566895,
      "learning_rate": 4.368e-06,
      "loss": 0.806,
      "step": 19540
    },
    {
      "epoch": 782.0,
      "grad_norm": 23.1619815826416,
      "learning_rate": 4.360000000000001e-06,
      "loss": 0.7942,
      "step": 19550
    },
    {
      "epoch": 782.4,
      "grad_norm": 9.744001388549805,
      "learning_rate": 4.352e-06,
      "loss": 0.8045,
      "step": 19560
    },
    {
      "epoch": 782.8,
      "grad_norm": 5.370379447937012,
      "learning_rate": 4.344e-06,
      "loss": 0.8145,
      "step": 19570
    },
    {
      "epoch": 783.2,
      "grad_norm": 8.741928100585938,
      "learning_rate": 4.3360000000000005e-06,
      "loss": 0.8134,
      "step": 19580
    },
    {
      "epoch": 783.6,
      "grad_norm": 16.981592178344727,
      "learning_rate": 4.328000000000001e-06,
      "loss": 0.8163,
      "step": 19590
    },
    {
      "epoch": 784.0,
      "grad_norm": 4.160156726837158,
      "learning_rate": 4.32e-06,
      "loss": 0.802,
      "step": 19600
    },
    {
      "epoch": 784.4,
      "grad_norm": 20.749267578125,
      "learning_rate": 4.312e-06,
      "loss": 0.8033,
      "step": 19610
    },
    {
      "epoch": 784.8,
      "grad_norm": 7.044996738433838,
      "learning_rate": 4.304000000000001e-06,
      "loss": 0.7947,
      "step": 19620
    },
    {
      "epoch": 785.2,
      "grad_norm": 9.195014953613281,
      "learning_rate": 4.296e-06,
      "loss": 0.8155,
      "step": 19630
    },
    {
      "epoch": 785.6,
      "grad_norm": 5.040036201477051,
      "learning_rate": 4.288e-06,
      "loss": 0.7956,
      "step": 19640
    },
    {
      "epoch": 786.0,
      "grad_norm": 13.117358207702637,
      "learning_rate": 4.2800000000000005e-06,
      "loss": 0.8215,
      "step": 19650
    },
    {
      "epoch": 786.4,
      "grad_norm": 14.15845775604248,
      "learning_rate": 4.272000000000001e-06,
      "loss": 0.7875,
      "step": 19660
    },
    {
      "epoch": 786.8,
      "grad_norm": 10.571925163269043,
      "learning_rate": 4.264e-06,
      "loss": 0.8312,
      "step": 19670
    },
    {
      "epoch": 787.2,
      "grad_norm": 16.769309997558594,
      "learning_rate": 4.256e-06,
      "loss": 0.8563,
      "step": 19680
    },
    {
      "epoch": 787.6,
      "grad_norm": 26.76835823059082,
      "learning_rate": 4.248000000000001e-06,
      "loss": 0.8096,
      "step": 19690
    },
    {
      "epoch": 788.0,
      "grad_norm": 13.727920532226562,
      "learning_rate": 4.24e-06,
      "loss": 0.8003,
      "step": 19700
    },
    {
      "epoch": 788.4,
      "grad_norm": 9.346659660339355,
      "learning_rate": 4.232e-06,
      "loss": 0.7881,
      "step": 19710
    },
    {
      "epoch": 788.8,
      "grad_norm": 9.763616561889648,
      "learning_rate": 4.2240000000000006e-06,
      "loss": 0.8018,
      "step": 19720
    },
    {
      "epoch": 789.2,
      "grad_norm": 9.023372650146484,
      "learning_rate": 4.216e-06,
      "loss": 0.8217,
      "step": 19730
    },
    {
      "epoch": 789.6,
      "grad_norm": 10.092011451721191,
      "learning_rate": 4.208e-06,
      "loss": 0.8178,
      "step": 19740
    },
    {
      "epoch": 790.0,
      "grad_norm": 8.274270057678223,
      "learning_rate": 4.2000000000000004e-06,
      "loss": 0.7838,
      "step": 19750
    },
    {
      "epoch": 790.4,
      "grad_norm": 7.205319881439209,
      "learning_rate": 4.192000000000001e-06,
      "loss": 0.8208,
      "step": 19760
    },
    {
      "epoch": 790.8,
      "grad_norm": 5.615790367126465,
      "learning_rate": 4.184e-06,
      "loss": 0.8054,
      "step": 19770
    },
    {
      "epoch": 791.2,
      "grad_norm": 12.177986145019531,
      "learning_rate": 4.176e-06,
      "loss": 0.7991,
      "step": 19780
    },
    {
      "epoch": 791.6,
      "grad_norm": 7.983311653137207,
      "learning_rate": 4.168000000000001e-06,
      "loss": 0.7971,
      "step": 19790
    },
    {
      "epoch": 792.0,
      "grad_norm": 4.40643310546875,
      "learning_rate": 4.16e-06,
      "loss": 0.8195,
      "step": 19800
    },
    {
      "epoch": 792.4,
      "grad_norm": 12.777200698852539,
      "learning_rate": 4.152e-06,
      "loss": 0.7927,
      "step": 19810
    },
    {
      "epoch": 792.8,
      "grad_norm": 7.570058345794678,
      "learning_rate": 4.1440000000000005e-06,
      "loss": 0.8483,
      "step": 19820
    },
    {
      "epoch": 793.2,
      "grad_norm": 9.15910816192627,
      "learning_rate": 4.136000000000001e-06,
      "loss": 0.8032,
      "step": 19830
    },
    {
      "epoch": 793.6,
      "grad_norm": 8.971685409545898,
      "learning_rate": 4.128e-06,
      "loss": 0.8149,
      "step": 19840
    },
    {
      "epoch": 794.0,
      "grad_norm": 13.168603897094727,
      "learning_rate": 4.12e-06,
      "loss": 0.796,
      "step": 19850
    },
    {
      "epoch": 794.4,
      "grad_norm": 7.220012664794922,
      "learning_rate": 4.112000000000001e-06,
      "loss": 0.7863,
      "step": 19860
    },
    {
      "epoch": 794.8,
      "grad_norm": 11.401479721069336,
      "learning_rate": 4.104e-06,
      "loss": 0.8152,
      "step": 19870
    },
    {
      "epoch": 795.2,
      "grad_norm": 2.8251843452453613,
      "learning_rate": 4.096e-06,
      "loss": 0.8165,
      "step": 19880
    },
    {
      "epoch": 795.6,
      "grad_norm": 14.629297256469727,
      "learning_rate": 4.0880000000000005e-06,
      "loss": 0.819,
      "step": 19890
    },
    {
      "epoch": 796.0,
      "grad_norm": 7.81895637512207,
      "learning_rate": 4.08e-06,
      "loss": 0.8069,
      "step": 19900
    },
    {
      "epoch": 796.4,
      "grad_norm": 9.561046600341797,
      "learning_rate": 4.072e-06,
      "loss": 0.8177,
      "step": 19910
    },
    {
      "epoch": 796.8,
      "grad_norm": 7.786500453948975,
      "learning_rate": 4.064e-06,
      "loss": 0.856,
      "step": 19920
    },
    {
      "epoch": 797.2,
      "grad_norm": 5.836667060852051,
      "learning_rate": 4.056000000000001e-06,
      "loss": 0.795,
      "step": 19930
    },
    {
      "epoch": 797.6,
      "grad_norm": 9.690531730651855,
      "learning_rate": 4.048e-06,
      "loss": 0.8205,
      "step": 19940
    },
    {
      "epoch": 798.0,
      "grad_norm": 8.4613676071167,
      "learning_rate": 4.04e-06,
      "loss": 0.809,
      "step": 19950
    },
    {
      "epoch": 798.4,
      "grad_norm": 5.7964606285095215,
      "learning_rate": 4.0320000000000005e-06,
      "loss": 0.799,
      "step": 19960
    },
    {
      "epoch": 798.8,
      "grad_norm": 13.264350891113281,
      "learning_rate": 4.024e-06,
      "loss": 0.8116,
      "step": 19970
    },
    {
      "epoch": 799.2,
      "grad_norm": 19.407730102539062,
      "learning_rate": 4.016e-06,
      "loss": 0.8119,
      "step": 19980
    },
    {
      "epoch": 799.6,
      "grad_norm": 7.689670085906982,
      "learning_rate": 4.008e-06,
      "loss": 0.7879,
      "step": 19990
    },
    {
      "epoch": 800.0,
      "grad_norm": 8.362524032592773,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.7913,
      "step": 20000
    },
    {
      "epoch": 800.4,
      "grad_norm": 12.24928092956543,
      "learning_rate": 3.992e-06,
      "loss": 0.8164,
      "step": 20010
    },
    {
      "epoch": 800.8,
      "grad_norm": 4.8041672706604,
      "learning_rate": 3.984e-06,
      "loss": 0.8031,
      "step": 20020
    },
    {
      "epoch": 801.2,
      "grad_norm": 4.766398906707764,
      "learning_rate": 3.9760000000000006e-06,
      "loss": 0.8098,
      "step": 20030
    },
    {
      "epoch": 801.6,
      "grad_norm": 13.332696914672852,
      "learning_rate": 3.968e-06,
      "loss": 0.8375,
      "step": 20040
    },
    {
      "epoch": 802.0,
      "grad_norm": 13.002618789672852,
      "learning_rate": 3.96e-06,
      "loss": 0.7727,
      "step": 20050
    },
    {
      "epoch": 802.4,
      "grad_norm": 8.885211944580078,
      "learning_rate": 3.9520000000000004e-06,
      "loss": 0.7886,
      "step": 20060
    },
    {
      "epoch": 802.8,
      "grad_norm": 5.605870246887207,
      "learning_rate": 3.944e-06,
      "loss": 0.8046,
      "step": 20070
    },
    {
      "epoch": 803.2,
      "grad_norm": 14.171664237976074,
      "learning_rate": 3.936e-06,
      "loss": 0.7881,
      "step": 20080
    },
    {
      "epoch": 803.6,
      "grad_norm": 15.910806655883789,
      "learning_rate": 3.928e-06,
      "loss": 0.8548,
      "step": 20090
    },
    {
      "epoch": 804.0,
      "grad_norm": 9.858027458190918,
      "learning_rate": 3.920000000000001e-06,
      "loss": 0.7819,
      "step": 20100
    },
    {
      "epoch": 804.4,
      "grad_norm": 10.904088973999023,
      "learning_rate": 3.912e-06,
      "loss": 0.78,
      "step": 20110
    },
    {
      "epoch": 804.8,
      "grad_norm": 10.169087409973145,
      "learning_rate": 3.904e-06,
      "loss": 0.8248,
      "step": 20120
    },
    {
      "epoch": 805.2,
      "grad_norm": 19.038589477539062,
      "learning_rate": 3.8960000000000005e-06,
      "loss": 0.819,
      "step": 20130
    },
    {
      "epoch": 805.6,
      "grad_norm": 11.084395408630371,
      "learning_rate": 3.888e-06,
      "loss": 0.7848,
      "step": 20140
    },
    {
      "epoch": 806.0,
      "grad_norm": 7.514652729034424,
      "learning_rate": 3.88e-06,
      "loss": 0.8114,
      "step": 20150
    },
    {
      "epoch": 806.4,
      "grad_norm": 13.578936576843262,
      "learning_rate": 3.872e-06,
      "loss": 0.7974,
      "step": 20160
    },
    {
      "epoch": 806.8,
      "grad_norm": 9.332361221313477,
      "learning_rate": 3.864000000000001e-06,
      "loss": 0.7798,
      "step": 20170
    },
    {
      "epoch": 807.2,
      "grad_norm": 11.209417343139648,
      "learning_rate": 3.856e-06,
      "loss": 0.7942,
      "step": 20180
    },
    {
      "epoch": 807.6,
      "grad_norm": 7.680811882019043,
      "learning_rate": 3.848e-06,
      "loss": 0.824,
      "step": 20190
    },
    {
      "epoch": 808.0,
      "grad_norm": 8.89149284362793,
      "learning_rate": 3.8400000000000005e-06,
      "loss": 0.7992,
      "step": 20200
    },
    {
      "epoch": 808.4,
      "grad_norm": 5.379622459411621,
      "learning_rate": 3.832e-06,
      "loss": 0.7913,
      "step": 20210
    },
    {
      "epoch": 808.8,
      "grad_norm": 16.590702056884766,
      "learning_rate": 3.824e-06,
      "loss": 0.7926,
      "step": 20220
    },
    {
      "epoch": 809.2,
      "grad_norm": 25.699193954467773,
      "learning_rate": 3.816e-06,
      "loss": 0.8205,
      "step": 20230
    },
    {
      "epoch": 809.6,
      "grad_norm": 18.652971267700195,
      "learning_rate": 3.8080000000000006e-06,
      "loss": 0.8032,
      "step": 20240
    },
    {
      "epoch": 810.0,
      "grad_norm": 6.483284950256348,
      "learning_rate": 3.8000000000000005e-06,
      "loss": 0.795,
      "step": 20250
    },
    {
      "epoch": 810.4,
      "grad_norm": 8.043793678283691,
      "learning_rate": 3.7920000000000003e-06,
      "loss": 0.8172,
      "step": 20260
    },
    {
      "epoch": 810.8,
      "grad_norm": 16.568756103515625,
      "learning_rate": 3.7840000000000005e-06,
      "loss": 0.8208,
      "step": 20270
    },
    {
      "epoch": 811.2,
      "grad_norm": 7.468151569366455,
      "learning_rate": 3.7760000000000004e-06,
      "loss": 0.8263,
      "step": 20280
    },
    {
      "epoch": 811.6,
      "grad_norm": 12.936196327209473,
      "learning_rate": 3.7680000000000006e-06,
      "loss": 0.8357,
      "step": 20290
    },
    {
      "epoch": 812.0,
      "grad_norm": 13.978528022766113,
      "learning_rate": 3.7600000000000004e-06,
      "loss": 0.77,
      "step": 20300
    },
    {
      "epoch": 812.4,
      "grad_norm": 5.056862831115723,
      "learning_rate": 3.7520000000000002e-06,
      "loss": 0.7757,
      "step": 20310
    },
    {
      "epoch": 812.8,
      "grad_norm": 11.441303253173828,
      "learning_rate": 3.7440000000000005e-06,
      "loss": 0.8468,
      "step": 20320
    },
    {
      "epoch": 813.2,
      "grad_norm": 10.529870986938477,
      "learning_rate": 3.7360000000000003e-06,
      "loss": 0.7834,
      "step": 20330
    },
    {
      "epoch": 813.6,
      "grad_norm": 6.399703025817871,
      "learning_rate": 3.7280000000000006e-06,
      "loss": 0.803,
      "step": 20340
    },
    {
      "epoch": 814.0,
      "grad_norm": 9.47137451171875,
      "learning_rate": 3.7200000000000004e-06,
      "loss": 0.7964,
      "step": 20350
    },
    {
      "epoch": 814.4,
      "grad_norm": 7.488463878631592,
      "learning_rate": 3.712e-06,
      "loss": 0.8109,
      "step": 20360
    },
    {
      "epoch": 814.8,
      "grad_norm": 7.078629493713379,
      "learning_rate": 3.7040000000000005e-06,
      "loss": 0.7984,
      "step": 20370
    },
    {
      "epoch": 815.2,
      "grad_norm": 23.286758422851562,
      "learning_rate": 3.6960000000000003e-06,
      "loss": 0.7743,
      "step": 20380
    },
    {
      "epoch": 815.6,
      "grad_norm": 11.07690715789795,
      "learning_rate": 3.6880000000000005e-06,
      "loss": 0.8228,
      "step": 20390
    },
    {
      "epoch": 816.0,
      "grad_norm": 17.23099136352539,
      "learning_rate": 3.6800000000000003e-06,
      "loss": 0.8025,
      "step": 20400
    },
    {
      "epoch": 816.4,
      "grad_norm": 11.918622016906738,
      "learning_rate": 3.6720000000000006e-06,
      "loss": 0.8018,
      "step": 20410
    },
    {
      "epoch": 816.8,
      "grad_norm": 15.700115203857422,
      "learning_rate": 3.6640000000000004e-06,
      "loss": 0.7631,
      "step": 20420
    },
    {
      "epoch": 817.2,
      "grad_norm": 15.836997985839844,
      "learning_rate": 3.6560000000000002e-06,
      "loss": 0.8043,
      "step": 20430
    },
    {
      "epoch": 817.6,
      "grad_norm": 7.04254150390625,
      "learning_rate": 3.6480000000000005e-06,
      "loss": 0.8554,
      "step": 20440
    },
    {
      "epoch": 818.0,
      "grad_norm": 17.73801612854004,
      "learning_rate": 3.6400000000000003e-06,
      "loss": 0.8179,
      "step": 20450
    },
    {
      "epoch": 818.4,
      "grad_norm": 4.402536392211914,
      "learning_rate": 3.6320000000000005e-06,
      "loss": 0.8195,
      "step": 20460
    },
    {
      "epoch": 818.8,
      "grad_norm": 6.846560955047607,
      "learning_rate": 3.6240000000000004e-06,
      "loss": 0.7772,
      "step": 20470
    },
    {
      "epoch": 819.2,
      "grad_norm": 17.390644073486328,
      "learning_rate": 3.616e-06,
      "loss": 0.7928,
      "step": 20480
    },
    {
      "epoch": 819.6,
      "grad_norm": 22.749235153198242,
      "learning_rate": 3.6080000000000004e-06,
      "loss": 0.8129,
      "step": 20490
    },
    {
      "epoch": 820.0,
      "grad_norm": 20.000823974609375,
      "learning_rate": 3.6000000000000003e-06,
      "loss": 0.8021,
      "step": 20500
    },
    {
      "epoch": 820.4,
      "grad_norm": 10.660325050354004,
      "learning_rate": 3.5920000000000005e-06,
      "loss": 0.7804,
      "step": 20510
    },
    {
      "epoch": 820.8,
      "grad_norm": 17.97464942932129,
      "learning_rate": 3.5840000000000003e-06,
      "loss": 0.8386,
      "step": 20520
    },
    {
      "epoch": 821.2,
      "grad_norm": 5.704484939575195,
      "learning_rate": 3.576e-06,
      "loss": 0.8405,
      "step": 20530
    },
    {
      "epoch": 821.6,
      "grad_norm": 18.94441795349121,
      "learning_rate": 3.5680000000000004e-06,
      "loss": 0.7925,
      "step": 20540
    },
    {
      "epoch": 822.0,
      "grad_norm": 20.22940444946289,
      "learning_rate": 3.5600000000000002e-06,
      "loss": 0.7928,
      "step": 20550
    },
    {
      "epoch": 822.4,
      "grad_norm": 5.263007164001465,
      "learning_rate": 3.5520000000000005e-06,
      "loss": 0.8093,
      "step": 20560
    },
    {
      "epoch": 822.8,
      "grad_norm": 10.637842178344727,
      "learning_rate": 3.5440000000000003e-06,
      "loss": 0.8214,
      "step": 20570
    },
    {
      "epoch": 823.2,
      "grad_norm": 6.743153095245361,
      "learning_rate": 3.5360000000000005e-06,
      "loss": 0.8088,
      "step": 20580
    },
    {
      "epoch": 823.6,
      "grad_norm": 13.438704490661621,
      "learning_rate": 3.5280000000000004e-06,
      "loss": 0.7884,
      "step": 20590
    },
    {
      "epoch": 824.0,
      "grad_norm": 5.282951831817627,
      "learning_rate": 3.52e-06,
      "loss": 0.8104,
      "step": 20600
    },
    {
      "epoch": 824.4,
      "grad_norm": 11.566527366638184,
      "learning_rate": 3.5120000000000004e-06,
      "loss": 0.8036,
      "step": 20610
    },
    {
      "epoch": 824.8,
      "grad_norm": 3.817955255508423,
      "learning_rate": 3.5040000000000002e-06,
      "loss": 0.7822,
      "step": 20620
    },
    {
      "epoch": 825.2,
      "grad_norm": 6.941298961639404,
      "learning_rate": 3.4960000000000005e-06,
      "loss": 0.8385,
      "step": 20630
    },
    {
      "epoch": 825.6,
      "grad_norm": 8.387771606445312,
      "learning_rate": 3.4880000000000003e-06,
      "loss": 0.8296,
      "step": 20640
    },
    {
      "epoch": 826.0,
      "grad_norm": 15.38196849822998,
      "learning_rate": 3.48e-06,
      "loss": 0.8066,
      "step": 20650
    },
    {
      "epoch": 826.4,
      "grad_norm": 4.7425150871276855,
      "learning_rate": 3.4720000000000004e-06,
      "loss": 0.7853,
      "step": 20660
    },
    {
      "epoch": 826.8,
      "grad_norm": 11.01617431640625,
      "learning_rate": 3.464e-06,
      "loss": 0.7812,
      "step": 20670
    },
    {
      "epoch": 827.2,
      "grad_norm": 7.732813358306885,
      "learning_rate": 3.4560000000000005e-06,
      "loss": 0.8036,
      "step": 20680
    },
    {
      "epoch": 827.6,
      "grad_norm": 9.193504333496094,
      "learning_rate": 3.4480000000000003e-06,
      "loss": 0.7771,
      "step": 20690
    },
    {
      "epoch": 828.0,
      "grad_norm": 13.057352066040039,
      "learning_rate": 3.44e-06,
      "loss": 0.793,
      "step": 20700
    },
    {
      "epoch": 828.4,
      "grad_norm": 14.227228164672852,
      "learning_rate": 3.4320000000000003e-06,
      "loss": 0.8159,
      "step": 20710
    },
    {
      "epoch": 828.8,
      "grad_norm": 9.964111328125,
      "learning_rate": 3.424e-06,
      "loss": 0.7915,
      "step": 20720
    },
    {
      "epoch": 829.2,
      "grad_norm": 9.322388648986816,
      "learning_rate": 3.4160000000000004e-06,
      "loss": 0.7947,
      "step": 20730
    },
    {
      "epoch": 829.6,
      "grad_norm": 6.1836838722229,
      "learning_rate": 3.4080000000000002e-06,
      "loss": 0.8161,
      "step": 20740
    },
    {
      "epoch": 830.0,
      "grad_norm": 11.058356285095215,
      "learning_rate": 3.4000000000000005e-06,
      "loss": 0.7605,
      "step": 20750
    },
    {
      "epoch": 830.4,
      "grad_norm": 10.552781105041504,
      "learning_rate": 3.3920000000000003e-06,
      "loss": 0.8017,
      "step": 20760
    },
    {
      "epoch": 830.8,
      "grad_norm": 6.606732368469238,
      "learning_rate": 3.384e-06,
      "loss": 0.8002,
      "step": 20770
    },
    {
      "epoch": 831.2,
      "grad_norm": 12.989627838134766,
      "learning_rate": 3.3760000000000004e-06,
      "loss": 0.8018,
      "step": 20780
    },
    {
      "epoch": 831.6,
      "grad_norm": 12.739351272583008,
      "learning_rate": 3.368e-06,
      "loss": 0.7917,
      "step": 20790
    },
    {
      "epoch": 832.0,
      "grad_norm": 19.931440353393555,
      "learning_rate": 3.3600000000000004e-06,
      "loss": 0.8468,
      "step": 20800
    },
    {
      "epoch": 832.4,
      "grad_norm": 3.617379903793335,
      "learning_rate": 3.3520000000000003e-06,
      "loss": 0.8075,
      "step": 20810
    },
    {
      "epoch": 832.8,
      "grad_norm": 17.529102325439453,
      "learning_rate": 3.344e-06,
      "loss": 0.7886,
      "step": 20820
    },
    {
      "epoch": 833.2,
      "grad_norm": 12.105636596679688,
      "learning_rate": 3.3360000000000003e-06,
      "loss": 0.798,
      "step": 20830
    },
    {
      "epoch": 833.6,
      "grad_norm": 13.739603042602539,
      "learning_rate": 3.328e-06,
      "loss": 0.7936,
      "step": 20840
    },
    {
      "epoch": 834.0,
      "grad_norm": 18.33910369873047,
      "learning_rate": 3.3200000000000004e-06,
      "loss": 0.8275,
      "step": 20850
    },
    {
      "epoch": 834.4,
      "grad_norm": 6.029128074645996,
      "learning_rate": 3.3120000000000002e-06,
      "loss": 0.79,
      "step": 20860
    },
    {
      "epoch": 834.8,
      "grad_norm": 38.337677001953125,
      "learning_rate": 3.3040000000000005e-06,
      "loss": 0.8117,
      "step": 20870
    },
    {
      "epoch": 835.2,
      "grad_norm": 8.183856964111328,
      "learning_rate": 3.2960000000000003e-06,
      "loss": 0.7694,
      "step": 20880
    },
    {
      "epoch": 835.6,
      "grad_norm": 14.154329299926758,
      "learning_rate": 3.288e-06,
      "loss": 0.82,
      "step": 20890
    },
    {
      "epoch": 836.0,
      "grad_norm": 9.358707427978516,
      "learning_rate": 3.2800000000000004e-06,
      "loss": 0.8184,
      "step": 20900
    },
    {
      "epoch": 836.4,
      "grad_norm": 10.453186988830566,
      "learning_rate": 3.272e-06,
      "loss": 0.7708,
      "step": 20910
    },
    {
      "epoch": 836.8,
      "grad_norm": 20.273183822631836,
      "learning_rate": 3.2640000000000004e-06,
      "loss": 0.7945,
      "step": 20920
    },
    {
      "epoch": 837.2,
      "grad_norm": 3.8220560550689697,
      "learning_rate": 3.2560000000000003e-06,
      "loss": 0.7993,
      "step": 20930
    },
    {
      "epoch": 837.6,
      "grad_norm": 7.3842453956604,
      "learning_rate": 3.248e-06,
      "loss": 0.7941,
      "step": 20940
    },
    {
      "epoch": 838.0,
      "grad_norm": 7.770514965057373,
      "learning_rate": 3.2400000000000003e-06,
      "loss": 0.7738,
      "step": 20950
    },
    {
      "epoch": 838.4,
      "grad_norm": 7.9240803718566895,
      "learning_rate": 3.232e-06,
      "loss": 0.8379,
      "step": 20960
    },
    {
      "epoch": 838.8,
      "grad_norm": 14.49832534790039,
      "learning_rate": 3.2240000000000004e-06,
      "loss": 0.7835,
      "step": 20970
    },
    {
      "epoch": 839.2,
      "grad_norm": 6.95073127746582,
      "learning_rate": 3.216e-06,
      "loss": 0.7993,
      "step": 20980
    },
    {
      "epoch": 839.6,
      "grad_norm": 4.739634037017822,
      "learning_rate": 3.208e-06,
      "loss": 0.8053,
      "step": 20990
    },
    {
      "epoch": 840.0,
      "grad_norm": 13.334196090698242,
      "learning_rate": 3.2000000000000003e-06,
      "loss": 0.8109,
      "step": 21000
    },
    {
      "epoch": 840.4,
      "grad_norm": 29.254295349121094,
      "learning_rate": 3.192e-06,
      "loss": 0.7911,
      "step": 21010
    },
    {
      "epoch": 840.8,
      "grad_norm": 14.414603233337402,
      "learning_rate": 3.1840000000000003e-06,
      "loss": 0.7935,
      "step": 21020
    },
    {
      "epoch": 841.2,
      "grad_norm": 5.490322589874268,
      "learning_rate": 3.176e-06,
      "loss": 0.8119,
      "step": 21030
    },
    {
      "epoch": 841.6,
      "grad_norm": 12.048535346984863,
      "learning_rate": 3.1680000000000004e-06,
      "loss": 0.7861,
      "step": 21040
    },
    {
      "epoch": 842.0,
      "grad_norm": 23.045900344848633,
      "learning_rate": 3.1600000000000002e-06,
      "loss": 0.8338,
      "step": 21050
    },
    {
      "epoch": 842.4,
      "grad_norm": 18.107820510864258,
      "learning_rate": 3.152e-06,
      "loss": 0.7895,
      "step": 21060
    },
    {
      "epoch": 842.8,
      "grad_norm": 6.624147891998291,
      "learning_rate": 3.1440000000000003e-06,
      "loss": 0.7971,
      "step": 21070
    },
    {
      "epoch": 843.2,
      "grad_norm": 11.411932945251465,
      "learning_rate": 3.136e-06,
      "loss": 0.7804,
      "step": 21080
    },
    {
      "epoch": 843.6,
      "grad_norm": 5.569032192230225,
      "learning_rate": 3.1280000000000004e-06,
      "loss": 0.7806,
      "step": 21090
    },
    {
      "epoch": 844.0,
      "grad_norm": 5.446621894836426,
      "learning_rate": 3.12e-06,
      "loss": 0.8286,
      "step": 21100
    },
    {
      "epoch": 844.4,
      "grad_norm": 9.888567924499512,
      "learning_rate": 3.112e-06,
      "loss": 0.7706,
      "step": 21110
    },
    {
      "epoch": 844.8,
      "grad_norm": 5.263125896453857,
      "learning_rate": 3.1040000000000003e-06,
      "loss": 0.8049,
      "step": 21120
    },
    {
      "epoch": 845.2,
      "grad_norm": 10.63060188293457,
      "learning_rate": 3.096e-06,
      "loss": 0.8196,
      "step": 21130
    },
    {
      "epoch": 845.6,
      "grad_norm": 14.540369033813477,
      "learning_rate": 3.0880000000000003e-06,
      "loss": 0.8404,
      "step": 21140
    },
    {
      "epoch": 846.0,
      "grad_norm": 16.902050018310547,
      "learning_rate": 3.08e-06,
      "loss": 0.8021,
      "step": 21150
    },
    {
      "epoch": 846.4,
      "grad_norm": 4.6174492835998535,
      "learning_rate": 3.072e-06,
      "loss": 0.8152,
      "step": 21160
    },
    {
      "epoch": 846.8,
      "grad_norm": 4.745256423950195,
      "learning_rate": 3.0640000000000002e-06,
      "loss": 0.8242,
      "step": 21170
    },
    {
      "epoch": 847.2,
      "grad_norm": 36.60997009277344,
      "learning_rate": 3.056e-06,
      "loss": 0.8067,
      "step": 21180
    },
    {
      "epoch": 847.6,
      "grad_norm": 13.993551254272461,
      "learning_rate": 3.0480000000000003e-06,
      "loss": 0.8038,
      "step": 21190
    },
    {
      "epoch": 848.0,
      "grad_norm": 12.941167831420898,
      "learning_rate": 3.04e-06,
      "loss": 0.8224,
      "step": 21200
    },
    {
      "epoch": 848.4,
      "grad_norm": 16.527860641479492,
      "learning_rate": 3.0320000000000004e-06,
      "loss": 0.7905,
      "step": 21210
    },
    {
      "epoch": 848.8,
      "grad_norm": 11.698620796203613,
      "learning_rate": 3.024e-06,
      "loss": 0.8001,
      "step": 21220
    },
    {
      "epoch": 849.2,
      "grad_norm": 21.9212646484375,
      "learning_rate": 3.016e-06,
      "loss": 0.7775,
      "step": 21230
    },
    {
      "epoch": 849.6,
      "grad_norm": 11.542473793029785,
      "learning_rate": 3.0080000000000003e-06,
      "loss": 0.8136,
      "step": 21240
    },
    {
      "epoch": 850.0,
      "grad_norm": 17.187833786010742,
      "learning_rate": 3e-06,
      "loss": 0.8087,
      "step": 21250
    },
    {
      "epoch": 850.4,
      "grad_norm": 10.629063606262207,
      "learning_rate": 2.9920000000000003e-06,
      "loss": 0.7963,
      "step": 21260
    },
    {
      "epoch": 850.8,
      "grad_norm": 13.911382675170898,
      "learning_rate": 2.984e-06,
      "loss": 0.8321,
      "step": 21270
    },
    {
      "epoch": 851.2,
      "grad_norm": 3.9714255332946777,
      "learning_rate": 2.976e-06,
      "loss": 0.7865,
      "step": 21280
    },
    {
      "epoch": 851.6,
      "grad_norm": 4.285604953765869,
      "learning_rate": 2.9680000000000002e-06,
      "loss": 0.8055,
      "step": 21290
    },
    {
      "epoch": 852.0,
      "grad_norm": 10.951410293579102,
      "learning_rate": 2.96e-06,
      "loss": 0.8065,
      "step": 21300
    },
    {
      "epoch": 852.4,
      "grad_norm": 8.845965385437012,
      "learning_rate": 2.9520000000000003e-06,
      "loss": 0.8365,
      "step": 21310
    },
    {
      "epoch": 852.8,
      "grad_norm": 7.513947010040283,
      "learning_rate": 2.944e-06,
      "loss": 0.7783,
      "step": 21320
    },
    {
      "epoch": 853.2,
      "grad_norm": 4.6635050773620605,
      "learning_rate": 2.9360000000000003e-06,
      "loss": 0.8174,
      "step": 21330
    },
    {
      "epoch": 853.6,
      "grad_norm": 8.065946578979492,
      "learning_rate": 2.928e-06,
      "loss": 0.7737,
      "step": 21340
    },
    {
      "epoch": 854.0,
      "grad_norm": 9.684945106506348,
      "learning_rate": 2.92e-06,
      "loss": 0.8234,
      "step": 21350
    },
    {
      "epoch": 854.4,
      "grad_norm": 11.014081001281738,
      "learning_rate": 2.9120000000000002e-06,
      "loss": 0.8128,
      "step": 21360
    },
    {
      "epoch": 854.8,
      "grad_norm": 12.82193374633789,
      "learning_rate": 2.904e-06,
      "loss": 0.7704,
      "step": 21370
    },
    {
      "epoch": 855.2,
      "grad_norm": 16.995222091674805,
      "learning_rate": 2.8960000000000003e-06,
      "loss": 0.8036,
      "step": 21380
    },
    {
      "epoch": 855.6,
      "grad_norm": 17.290119171142578,
      "learning_rate": 2.888e-06,
      "loss": 0.8083,
      "step": 21390
    },
    {
      "epoch": 856.0,
      "grad_norm": 8.162501335144043,
      "learning_rate": 2.88e-06,
      "loss": 0.7978,
      "step": 21400
    },
    {
      "epoch": 856.4,
      "grad_norm": 11.63752555847168,
      "learning_rate": 2.872e-06,
      "loss": 0.8144,
      "step": 21410
    },
    {
      "epoch": 856.8,
      "grad_norm": 5.066864967346191,
      "learning_rate": 2.864e-06,
      "loss": 0.7905,
      "step": 21420
    },
    {
      "epoch": 857.2,
      "grad_norm": 14.576032638549805,
      "learning_rate": 2.8560000000000003e-06,
      "loss": 0.7767,
      "step": 21430
    },
    {
      "epoch": 857.6,
      "grad_norm": 6.9685492515563965,
      "learning_rate": 2.848e-06,
      "loss": 0.8239,
      "step": 21440
    },
    {
      "epoch": 858.0,
      "grad_norm": 4.347775936126709,
      "learning_rate": 2.84e-06,
      "loss": 0.7986,
      "step": 21450
    },
    {
      "epoch": 858.4,
      "grad_norm": 9.798054695129395,
      "learning_rate": 2.832e-06,
      "loss": 0.7928,
      "step": 21460
    },
    {
      "epoch": 858.8,
      "grad_norm": 13.613468170166016,
      "learning_rate": 2.824e-06,
      "loss": 0.7718,
      "step": 21470
    },
    {
      "epoch": 859.2,
      "grad_norm": 11.385904312133789,
      "learning_rate": 2.8160000000000002e-06,
      "loss": 0.7624,
      "step": 21480
    },
    {
      "epoch": 859.6,
      "grad_norm": 9.22406005859375,
      "learning_rate": 2.808e-06,
      "loss": 0.814,
      "step": 21490
    },
    {
      "epoch": 860.0,
      "grad_norm": 12.396095275878906,
      "learning_rate": 2.8000000000000003e-06,
      "loss": 0.7752,
      "step": 21500
    },
    {
      "epoch": 860.4,
      "grad_norm": 8.149284362792969,
      "learning_rate": 2.792e-06,
      "loss": 0.7987,
      "step": 21510
    },
    {
      "epoch": 860.8,
      "grad_norm": 6.536623001098633,
      "learning_rate": 2.784e-06,
      "loss": 0.7762,
      "step": 21520
    },
    {
      "epoch": 861.2,
      "grad_norm": 8.525696754455566,
      "learning_rate": 2.776e-06,
      "loss": 0.8126,
      "step": 21530
    },
    {
      "epoch": 861.6,
      "grad_norm": 12.981003761291504,
      "learning_rate": 2.768e-06,
      "loss": 0.795,
      "step": 21540
    },
    {
      "epoch": 862.0,
      "grad_norm": 12.556183815002441,
      "learning_rate": 2.7600000000000003e-06,
      "loss": 0.779,
      "step": 21550
    },
    {
      "epoch": 862.4,
      "grad_norm": 14.294320106506348,
      "learning_rate": 2.752e-06,
      "loss": 0.8165,
      "step": 21560
    },
    {
      "epoch": 862.8,
      "grad_norm": 6.734795093536377,
      "learning_rate": 2.744e-06,
      "loss": 0.8255,
      "step": 21570
    },
    {
      "epoch": 863.2,
      "grad_norm": 9.987475395202637,
      "learning_rate": 2.736e-06,
      "loss": 0.7643,
      "step": 21580
    },
    {
      "epoch": 863.6,
      "grad_norm": 5.54719352722168,
      "learning_rate": 2.728e-06,
      "loss": 0.7774,
      "step": 21590
    },
    {
      "epoch": 864.0,
      "grad_norm": 13.071846961975098,
      "learning_rate": 2.7200000000000002e-06,
      "loss": 0.8439,
      "step": 21600
    },
    {
      "epoch": 864.4,
      "grad_norm": 5.411553382873535,
      "learning_rate": 2.712e-06,
      "loss": 0.7803,
      "step": 21610
    },
    {
      "epoch": 864.8,
      "grad_norm": 10.559173583984375,
      "learning_rate": 2.704e-06,
      "loss": 0.8097,
      "step": 21620
    },
    {
      "epoch": 865.2,
      "grad_norm": 5.44573450088501,
      "learning_rate": 2.696e-06,
      "loss": 0.7912,
      "step": 21630
    },
    {
      "epoch": 865.6,
      "grad_norm": 13.918015480041504,
      "learning_rate": 2.688e-06,
      "loss": 0.7817,
      "step": 21640
    },
    {
      "epoch": 866.0,
      "grad_norm": 8.170218467712402,
      "learning_rate": 2.68e-06,
      "loss": 0.7951,
      "step": 21650
    },
    {
      "epoch": 866.4,
      "grad_norm": 12.126187324523926,
      "learning_rate": 2.672e-06,
      "loss": 0.7641,
      "step": 21660
    },
    {
      "epoch": 866.8,
      "grad_norm": 11.278876304626465,
      "learning_rate": 2.6640000000000007e-06,
      "loss": 0.8097,
      "step": 21670
    },
    {
      "epoch": 867.2,
      "grad_norm": 6.122002124786377,
      "learning_rate": 2.656e-06,
      "loss": 0.8254,
      "step": 21680
    },
    {
      "epoch": 867.6,
      "grad_norm": 7.243588447570801,
      "learning_rate": 2.648e-06,
      "loss": 0.8068,
      "step": 21690
    },
    {
      "epoch": 868.0,
      "grad_norm": 27.674636840820312,
      "learning_rate": 2.64e-06,
      "loss": 0.8027,
      "step": 21700
    },
    {
      "epoch": 868.4,
      "grad_norm": 9.340371131896973,
      "learning_rate": 2.632e-06,
      "loss": 0.7837,
      "step": 21710
    },
    {
      "epoch": 868.8,
      "grad_norm": 14.660415649414062,
      "learning_rate": 2.6240000000000006e-06,
      "loss": 0.7975,
      "step": 21720
    },
    {
      "epoch": 869.2,
      "grad_norm": 7.078919410705566,
      "learning_rate": 2.616e-06,
      "loss": 0.7918,
      "step": 21730
    },
    {
      "epoch": 869.6,
      "grad_norm": 11.950241088867188,
      "learning_rate": 2.608e-06,
      "loss": 0.8123,
      "step": 21740
    },
    {
      "epoch": 870.0,
      "grad_norm": 9.653111457824707,
      "learning_rate": 2.6e-06,
      "loss": 0.8136,
      "step": 21750
    },
    {
      "epoch": 870.4,
      "grad_norm": 17.2263126373291,
      "learning_rate": 2.592e-06,
      "loss": 0.7851,
      "step": 21760
    },
    {
      "epoch": 870.8,
      "grad_norm": 7.237794876098633,
      "learning_rate": 2.5840000000000006e-06,
      "loss": 0.7871,
      "step": 21770
    },
    {
      "epoch": 871.2,
      "grad_norm": 11.70493221282959,
      "learning_rate": 2.576e-06,
      "loss": 0.8173,
      "step": 21780
    },
    {
      "epoch": 871.6,
      "grad_norm": 4.972288131713867,
      "learning_rate": 2.568e-06,
      "loss": 0.7717,
      "step": 21790
    },
    {
      "epoch": 872.0,
      "grad_norm": 15.416669845581055,
      "learning_rate": 2.56e-06,
      "loss": 0.7942,
      "step": 21800
    },
    {
      "epoch": 872.4,
      "grad_norm": 13.119560241699219,
      "learning_rate": 2.552e-06,
      "loss": 0.801,
      "step": 21810
    },
    {
      "epoch": 872.8,
      "grad_norm": 5.929800510406494,
      "learning_rate": 2.5440000000000005e-06,
      "loss": 0.7808,
      "step": 21820
    },
    {
      "epoch": 873.2,
      "grad_norm": 9.85171127319336,
      "learning_rate": 2.536e-06,
      "loss": 0.8019,
      "step": 21830
    },
    {
      "epoch": 873.6,
      "grad_norm": 6.139883995056152,
      "learning_rate": 2.5280000000000006e-06,
      "loss": 0.7813,
      "step": 21840
    },
    {
      "epoch": 874.0,
      "grad_norm": 11.59260082244873,
      "learning_rate": 2.52e-06,
      "loss": 0.8214,
      "step": 21850
    },
    {
      "epoch": 874.4,
      "grad_norm": 17.892047882080078,
      "learning_rate": 2.512e-06,
      "loss": 0.8015,
      "step": 21860
    },
    {
      "epoch": 874.8,
      "grad_norm": 6.056270599365234,
      "learning_rate": 2.5040000000000005e-06,
      "loss": 0.816,
      "step": 21870
    },
    {
      "epoch": 875.2,
      "grad_norm": 14.773214340209961,
      "learning_rate": 2.496e-06,
      "loss": 0.7948,
      "step": 21880
    },
    {
      "epoch": 875.6,
      "grad_norm": 8.089986801147461,
      "learning_rate": 2.488e-06,
      "loss": 0.8074,
      "step": 21890
    },
    {
      "epoch": 876.0,
      "grad_norm": 10.664978981018066,
      "learning_rate": 2.4800000000000004e-06,
      "loss": 0.7791,
      "step": 21900
    },
    {
      "epoch": 876.4,
      "grad_norm": 3.75015926361084,
      "learning_rate": 2.4720000000000002e-06,
      "loss": 0.8015,
      "step": 21910
    },
    {
      "epoch": 876.8,
      "grad_norm": 4.57724142074585,
      "learning_rate": 2.4640000000000005e-06,
      "loss": 0.778,
      "step": 21920
    },
    {
      "epoch": 877.2,
      "grad_norm": 13.743752479553223,
      "learning_rate": 2.4560000000000003e-06,
      "loss": 0.8147,
      "step": 21930
    },
    {
      "epoch": 877.6,
      "grad_norm": 5.202176094055176,
      "learning_rate": 2.448e-06,
      "loss": 0.7984,
      "step": 21940
    },
    {
      "epoch": 878.0,
      "grad_norm": 19.22074317932129,
      "learning_rate": 2.4400000000000004e-06,
      "loss": 0.808,
      "step": 21950
    },
    {
      "epoch": 878.4,
      "grad_norm": 10.770708084106445,
      "learning_rate": 2.432e-06,
      "loss": 0.7987,
      "step": 21960
    },
    {
      "epoch": 878.8,
      "grad_norm": 16.863142013549805,
      "learning_rate": 2.4240000000000004e-06,
      "loss": 0.8175,
      "step": 21970
    },
    {
      "epoch": 879.2,
      "grad_norm": 26.653974533081055,
      "learning_rate": 2.4160000000000002e-06,
      "loss": 0.8086,
      "step": 21980
    },
    {
      "epoch": 879.6,
      "grad_norm": 7.336364269256592,
      "learning_rate": 2.408e-06,
      "loss": 0.7756,
      "step": 21990
    },
    {
      "epoch": 880.0,
      "grad_norm": 7.249305725097656,
      "learning_rate": 2.4000000000000003e-06,
      "loss": 0.7949,
      "step": 22000
    },
    {
      "epoch": 880.4,
      "grad_norm": 7.221933364868164,
      "learning_rate": 2.392e-06,
      "loss": 0.8146,
      "step": 22010
    },
    {
      "epoch": 880.8,
      "grad_norm": 19.30394744873047,
      "learning_rate": 2.3840000000000004e-06,
      "loss": 0.809,
      "step": 22020
    },
    {
      "epoch": 881.2,
      "grad_norm": 10.292216300964355,
      "learning_rate": 2.376e-06,
      "loss": 0.768,
      "step": 22030
    },
    {
      "epoch": 881.6,
      "grad_norm": 13.937583923339844,
      "learning_rate": 2.3680000000000005e-06,
      "loss": 0.8205,
      "step": 22040
    },
    {
      "epoch": 882.0,
      "grad_norm": 8.38841438293457,
      "learning_rate": 2.3600000000000003e-06,
      "loss": 0.8122,
      "step": 22050
    },
    {
      "epoch": 882.4,
      "grad_norm": 7.9910383224487305,
      "learning_rate": 2.352e-06,
      "loss": 0.7876,
      "step": 22060
    },
    {
      "epoch": 882.8,
      "grad_norm": 15.34162712097168,
      "learning_rate": 2.3440000000000003e-06,
      "loss": 0.7961,
      "step": 22070
    },
    {
      "epoch": 883.2,
      "grad_norm": 2.9630112648010254,
      "learning_rate": 2.336e-06,
      "loss": 0.8199,
      "step": 22080
    },
    {
      "epoch": 883.6,
      "grad_norm": 11.393754005432129,
      "learning_rate": 2.3280000000000004e-06,
      "loss": 0.783,
      "step": 22090
    },
    {
      "epoch": 884.0,
      "grad_norm": 11.939603805541992,
      "learning_rate": 2.3200000000000002e-06,
      "loss": 0.7884,
      "step": 22100
    },
    {
      "epoch": 884.4,
      "grad_norm": 4.90744161605835,
      "learning_rate": 2.312e-06,
      "loss": 0.7863,
      "step": 22110
    },
    {
      "epoch": 884.8,
      "grad_norm": 16.92188262939453,
      "learning_rate": 2.3040000000000003e-06,
      "loss": 0.7617,
      "step": 22120
    },
    {
      "epoch": 885.2,
      "grad_norm": 17.615690231323242,
      "learning_rate": 2.296e-06,
      "loss": 0.7979,
      "step": 22130
    },
    {
      "epoch": 885.6,
      "grad_norm": 9.566547393798828,
      "learning_rate": 2.2880000000000004e-06,
      "loss": 0.7927,
      "step": 22140
    },
    {
      "epoch": 886.0,
      "grad_norm": 21.83892250061035,
      "learning_rate": 2.28e-06,
      "loss": 0.8342,
      "step": 22150
    },
    {
      "epoch": 886.4,
      "grad_norm": 7.320161819458008,
      "learning_rate": 2.2720000000000004e-06,
      "loss": 0.7788,
      "step": 22160
    },
    {
      "epoch": 886.8,
      "grad_norm": 7.935730934143066,
      "learning_rate": 2.2640000000000003e-06,
      "loss": 0.7773,
      "step": 22170
    },
    {
      "epoch": 887.2,
      "grad_norm": 15.755313873291016,
      "learning_rate": 2.256e-06,
      "loss": 0.8202,
      "step": 22180
    },
    {
      "epoch": 887.6,
      "grad_norm": 22.046947479248047,
      "learning_rate": 2.2480000000000003e-06,
      "loss": 0.7934,
      "step": 22190
    },
    {
      "epoch": 888.0,
      "grad_norm": 4.529725551605225,
      "learning_rate": 2.24e-06,
      "loss": 0.8204,
      "step": 22200
    },
    {
      "epoch": 888.4,
      "grad_norm": 4.453213214874268,
      "learning_rate": 2.2320000000000004e-06,
      "loss": 0.777,
      "step": 22210
    },
    {
      "epoch": 888.8,
      "grad_norm": 8.042799949645996,
      "learning_rate": 2.2240000000000002e-06,
      "loss": 0.8005,
      "step": 22220
    },
    {
      "epoch": 889.2,
      "grad_norm": 10.186894416809082,
      "learning_rate": 2.216e-06,
      "loss": 0.7902,
      "step": 22230
    },
    {
      "epoch": 889.6,
      "grad_norm": 9.074912071228027,
      "learning_rate": 2.2080000000000003e-06,
      "loss": 0.8042,
      "step": 22240
    },
    {
      "epoch": 890.0,
      "grad_norm": 10.259572982788086,
      "learning_rate": 2.2e-06,
      "loss": 0.783,
      "step": 22250
    },
    {
      "epoch": 890.4,
      "grad_norm": 15.677213668823242,
      "learning_rate": 2.1920000000000004e-06,
      "loss": 0.7963,
      "step": 22260
    },
    {
      "epoch": 890.8,
      "grad_norm": 8.42008113861084,
      "learning_rate": 2.184e-06,
      "loss": 0.7786,
      "step": 22270
    },
    {
      "epoch": 891.2,
      "grad_norm": 9.69981861114502,
      "learning_rate": 2.176e-06,
      "loss": 0.7908,
      "step": 22280
    },
    {
      "epoch": 891.6,
      "grad_norm": 11.716063499450684,
      "learning_rate": 2.1680000000000002e-06,
      "loss": 0.809,
      "step": 22290
    },
    {
      "epoch": 892.0,
      "grad_norm": 21.12901496887207,
      "learning_rate": 2.16e-06,
      "loss": 0.7879,
      "step": 22300
    },
    {
      "epoch": 892.4,
      "grad_norm": 23.9251651763916,
      "learning_rate": 2.1520000000000003e-06,
      "loss": 0.7682,
      "step": 22310
    },
    {
      "epoch": 892.8,
      "grad_norm": 12.809676170349121,
      "learning_rate": 2.144e-06,
      "loss": 0.8162,
      "step": 22320
    },
    {
      "epoch": 893.2,
      "grad_norm": 10.38910961151123,
      "learning_rate": 2.1360000000000004e-06,
      "loss": 0.7859,
      "step": 22330
    },
    {
      "epoch": 893.6,
      "grad_norm": 19.074068069458008,
      "learning_rate": 2.128e-06,
      "loss": 0.8145,
      "step": 22340
    },
    {
      "epoch": 894.0,
      "grad_norm": 7.781987190246582,
      "learning_rate": 2.12e-06,
      "loss": 0.786,
      "step": 22350
    },
    {
      "epoch": 894.4,
      "grad_norm": 16.83690643310547,
      "learning_rate": 2.1120000000000003e-06,
      "loss": 0.8074,
      "step": 22360
    },
    {
      "epoch": 894.8,
      "grad_norm": 15.905829429626465,
      "learning_rate": 2.104e-06,
      "loss": 0.8104,
      "step": 22370
    },
    {
      "epoch": 895.2,
      "grad_norm": 7.287391662597656,
      "learning_rate": 2.0960000000000003e-06,
      "loss": 0.7811,
      "step": 22380
    },
    {
      "epoch": 895.6,
      "grad_norm": 10.680633544921875,
      "learning_rate": 2.088e-06,
      "loss": 0.8246,
      "step": 22390
    },
    {
      "epoch": 896.0,
      "grad_norm": 10.589189529418945,
      "learning_rate": 2.08e-06,
      "loss": 0.8062,
      "step": 22400
    },
    {
      "epoch": 896.4,
      "grad_norm": 9.082991600036621,
      "learning_rate": 2.0720000000000002e-06,
      "loss": 0.8284,
      "step": 22410
    },
    {
      "epoch": 896.8,
      "grad_norm": 15.467440605163574,
      "learning_rate": 2.064e-06,
      "loss": 0.783,
      "step": 22420
    },
    {
      "epoch": 897.2,
      "grad_norm": 4.15480899810791,
      "learning_rate": 2.0560000000000003e-06,
      "loss": 0.7873,
      "step": 22430
    },
    {
      "epoch": 897.6,
      "grad_norm": 27.883628845214844,
      "learning_rate": 2.048e-06,
      "loss": 0.8247,
      "step": 22440
    },
    {
      "epoch": 898.0,
      "grad_norm": 27.473772048950195,
      "learning_rate": 2.04e-06,
      "loss": 0.8435,
      "step": 22450
    },
    {
      "epoch": 898.4,
      "grad_norm": 9.19937801361084,
      "learning_rate": 2.032e-06,
      "loss": 0.7727,
      "step": 22460
    },
    {
      "epoch": 898.8,
      "grad_norm": 5.1199049949646,
      "learning_rate": 2.024e-06,
      "loss": 0.8209,
      "step": 22470
    },
    {
      "epoch": 899.2,
      "grad_norm": 10.88267707824707,
      "learning_rate": 2.0160000000000003e-06,
      "loss": 0.8044,
      "step": 22480
    },
    {
      "epoch": 899.6,
      "grad_norm": 4.827480792999268,
      "learning_rate": 2.008e-06,
      "loss": 0.7727,
      "step": 22490
    },
    {
      "epoch": 900.0,
      "grad_norm": 9.80164909362793,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.7944,
      "step": 22500
    },
    {
      "epoch": 900.4,
      "grad_norm": 12.583871841430664,
      "learning_rate": 1.992e-06,
      "loss": 0.791,
      "step": 22510
    },
    {
      "epoch": 900.8,
      "grad_norm": 7.975461006164551,
      "learning_rate": 1.984e-06,
      "loss": 0.7976,
      "step": 22520
    },
    {
      "epoch": 901.2,
      "grad_norm": 6.401695251464844,
      "learning_rate": 1.9760000000000002e-06,
      "loss": 0.7985,
      "step": 22530
    },
    {
      "epoch": 901.6,
      "grad_norm": 16.593961715698242,
      "learning_rate": 1.968e-06,
      "loss": 0.8112,
      "step": 22540
    },
    {
      "epoch": 902.0,
      "grad_norm": 22.34646224975586,
      "learning_rate": 1.9600000000000003e-06,
      "loss": 0.7685,
      "step": 22550
    },
    {
      "epoch": 902.4,
      "grad_norm": 3.4898858070373535,
      "learning_rate": 1.952e-06,
      "loss": 0.8103,
      "step": 22560
    },
    {
      "epoch": 902.8,
      "grad_norm": 14.314239501953125,
      "learning_rate": 1.944e-06,
      "loss": 0.7822,
      "step": 22570
    },
    {
      "epoch": 903.2,
      "grad_norm": 14.957547187805176,
      "learning_rate": 1.936e-06,
      "loss": 0.8062,
      "step": 22580
    },
    {
      "epoch": 903.6,
      "grad_norm": 10.619317054748535,
      "learning_rate": 1.928e-06,
      "loss": 0.7616,
      "step": 22590
    },
    {
      "epoch": 904.0,
      "grad_norm": 5.292733669281006,
      "learning_rate": 1.9200000000000003e-06,
      "loss": 0.7967,
      "step": 22600
    },
    {
      "epoch": 904.4,
      "grad_norm": 4.607564926147461,
      "learning_rate": 1.912e-06,
      "loss": 0.8214,
      "step": 22610
    },
    {
      "epoch": 904.8,
      "grad_norm": 8.028974533081055,
      "learning_rate": 1.9040000000000003e-06,
      "loss": 0.7716,
      "step": 22620
    },
    {
      "epoch": 905.2,
      "grad_norm": 13.008512496948242,
      "learning_rate": 1.8960000000000001e-06,
      "loss": 0.7868,
      "step": 22630
    },
    {
      "epoch": 905.6,
      "grad_norm": 5.531469345092773,
      "learning_rate": 1.8880000000000002e-06,
      "loss": 0.7819,
      "step": 22640
    },
    {
      "epoch": 906.0,
      "grad_norm": 11.805398941040039,
      "learning_rate": 1.8800000000000002e-06,
      "loss": 0.7751,
      "step": 22650
    },
    {
      "epoch": 906.4,
      "grad_norm": 22.907787322998047,
      "learning_rate": 1.8720000000000002e-06,
      "loss": 0.7723,
      "step": 22660
    },
    {
      "epoch": 906.8,
      "grad_norm": 6.6589531898498535,
      "learning_rate": 1.8640000000000003e-06,
      "loss": 0.7746,
      "step": 22670
    },
    {
      "epoch": 907.2,
      "grad_norm": 14.066079139709473,
      "learning_rate": 1.856e-06,
      "loss": 0.8025,
      "step": 22680
    },
    {
      "epoch": 907.6,
      "grad_norm": 10.58731460571289,
      "learning_rate": 1.8480000000000001e-06,
      "loss": 0.7957,
      "step": 22690
    },
    {
      "epoch": 908.0,
      "grad_norm": 8.951810836791992,
      "learning_rate": 1.8400000000000002e-06,
      "loss": 0.7545,
      "step": 22700
    },
    {
      "epoch": 908.4,
      "grad_norm": 6.366211891174316,
      "learning_rate": 1.8320000000000002e-06,
      "loss": 0.7962,
      "step": 22710
    },
    {
      "epoch": 908.8,
      "grad_norm": 15.132732391357422,
      "learning_rate": 1.8240000000000002e-06,
      "loss": 0.7856,
      "step": 22720
    },
    {
      "epoch": 909.2,
      "grad_norm": 16.981922149658203,
      "learning_rate": 1.8160000000000003e-06,
      "loss": 0.8041,
      "step": 22730
    },
    {
      "epoch": 909.6,
      "grad_norm": 20.341327667236328,
      "learning_rate": 1.808e-06,
      "loss": 0.763,
      "step": 22740
    },
    {
      "epoch": 910.0,
      "grad_norm": 11.98554801940918,
      "learning_rate": 1.8000000000000001e-06,
      "loss": 0.8029,
      "step": 22750
    },
    {
      "epoch": 910.4,
      "grad_norm": 10.955397605895996,
      "learning_rate": 1.7920000000000002e-06,
      "loss": 0.7819,
      "step": 22760
    },
    {
      "epoch": 910.8,
      "grad_norm": 23.246662139892578,
      "learning_rate": 1.7840000000000002e-06,
      "loss": 0.7878,
      "step": 22770
    },
    {
      "epoch": 911.2,
      "grad_norm": 5.850194454193115,
      "learning_rate": 1.7760000000000002e-06,
      "loss": 0.7847,
      "step": 22780
    },
    {
      "epoch": 911.6,
      "grad_norm": 20.12537956237793,
      "learning_rate": 1.7680000000000003e-06,
      "loss": 0.7752,
      "step": 22790
    },
    {
      "epoch": 912.0,
      "grad_norm": 12.624324798583984,
      "learning_rate": 1.76e-06,
      "loss": 0.7897,
      "step": 22800
    },
    {
      "epoch": 912.4,
      "grad_norm": 7.1068291664123535,
      "learning_rate": 1.7520000000000001e-06,
      "loss": 0.7889,
      "step": 22810
    },
    {
      "epoch": 912.8,
      "grad_norm": 12.772635459899902,
      "learning_rate": 1.7440000000000002e-06,
      "loss": 0.7823,
      "step": 22820
    },
    {
      "epoch": 913.2,
      "grad_norm": 19.780004501342773,
      "learning_rate": 1.7360000000000002e-06,
      "loss": 0.7684,
      "step": 22830
    },
    {
      "epoch": 913.6,
      "grad_norm": 10.392890930175781,
      "learning_rate": 1.7280000000000002e-06,
      "loss": 0.778,
      "step": 22840
    },
    {
      "epoch": 914.0,
      "grad_norm": 9.203454971313477,
      "learning_rate": 1.72e-06,
      "loss": 0.8355,
      "step": 22850
    },
    {
      "epoch": 914.4,
      "grad_norm": 8.033185005187988,
      "learning_rate": 1.712e-06,
      "loss": 0.7606,
      "step": 22860
    },
    {
      "epoch": 914.8,
      "grad_norm": 6.985729217529297,
      "learning_rate": 1.7040000000000001e-06,
      "loss": 0.775,
      "step": 22870
    },
    {
      "epoch": 915.2,
      "grad_norm": 18.666364669799805,
      "learning_rate": 1.6960000000000002e-06,
      "loss": 0.7705,
      "step": 22880
    },
    {
      "epoch": 915.6,
      "grad_norm": 18.054546356201172,
      "learning_rate": 1.6880000000000002e-06,
      "loss": 0.8313,
      "step": 22890
    },
    {
      "epoch": 916.0,
      "grad_norm": 8.948290824890137,
      "learning_rate": 1.6800000000000002e-06,
      "loss": 0.7891,
      "step": 22900
    },
    {
      "epoch": 916.4,
      "grad_norm": 37.912662506103516,
      "learning_rate": 1.672e-06,
      "loss": 0.7917,
      "step": 22910
    },
    {
      "epoch": 916.8,
      "grad_norm": 8.556154251098633,
      "learning_rate": 1.664e-06,
      "loss": 0.7947,
      "step": 22920
    },
    {
      "epoch": 917.2,
      "grad_norm": 21.431936264038086,
      "learning_rate": 1.6560000000000001e-06,
      "loss": 0.802,
      "step": 22930
    },
    {
      "epoch": 917.6,
      "grad_norm": 8.96448040008545,
      "learning_rate": 1.6480000000000001e-06,
      "loss": 0.8215,
      "step": 22940
    },
    {
      "epoch": 918.0,
      "grad_norm": 6.671812534332275,
      "learning_rate": 1.6400000000000002e-06,
      "loss": 0.8046,
      "step": 22950
    },
    {
      "epoch": 918.4,
      "grad_norm": 10.101863861083984,
      "learning_rate": 1.6320000000000002e-06,
      "loss": 0.7864,
      "step": 22960
    },
    {
      "epoch": 918.8,
      "grad_norm": 7.834014892578125,
      "learning_rate": 1.624e-06,
      "loss": 0.7754,
      "step": 22970
    },
    {
      "epoch": 919.2,
      "grad_norm": 14.964064598083496,
      "learning_rate": 1.616e-06,
      "loss": 0.7781,
      "step": 22980
    },
    {
      "epoch": 919.6,
      "grad_norm": 17.37037467956543,
      "learning_rate": 1.608e-06,
      "loss": 0.8025,
      "step": 22990
    },
    {
      "epoch": 920.0,
      "grad_norm": 10.324637413024902,
      "learning_rate": 1.6000000000000001e-06,
      "loss": 0.7868,
      "step": 23000
    },
    {
      "epoch": 920.4,
      "grad_norm": 10.237997055053711,
      "learning_rate": 1.5920000000000002e-06,
      "loss": 0.8104,
      "step": 23010
    },
    {
      "epoch": 920.8,
      "grad_norm": 6.531204700469971,
      "learning_rate": 1.5840000000000002e-06,
      "loss": 0.7801,
      "step": 23020
    },
    {
      "epoch": 921.2,
      "grad_norm": 5.4606122970581055,
      "learning_rate": 1.576e-06,
      "loss": 0.7757,
      "step": 23030
    },
    {
      "epoch": 921.6,
      "grad_norm": 16.120384216308594,
      "learning_rate": 1.568e-06,
      "loss": 0.7945,
      "step": 23040
    },
    {
      "epoch": 922.0,
      "grad_norm": 7.340606212615967,
      "learning_rate": 1.56e-06,
      "loss": 0.7564,
      "step": 23050
    },
    {
      "epoch": 922.4,
      "grad_norm": 6.842508792877197,
      "learning_rate": 1.5520000000000001e-06,
      "loss": 0.7996,
      "step": 23060
    },
    {
      "epoch": 922.8,
      "grad_norm": 7.850706100463867,
      "learning_rate": 1.5440000000000002e-06,
      "loss": 0.8129,
      "step": 23070
    },
    {
      "epoch": 923.2,
      "grad_norm": 13.917908668518066,
      "learning_rate": 1.536e-06,
      "loss": 0.7882,
      "step": 23080
    },
    {
      "epoch": 923.6,
      "grad_norm": 22.73418426513672,
      "learning_rate": 1.528e-06,
      "loss": 0.8168,
      "step": 23090
    },
    {
      "epoch": 924.0,
      "grad_norm": 10.481374740600586,
      "learning_rate": 1.52e-06,
      "loss": 0.7785,
      "step": 23100
    },
    {
      "epoch": 924.4,
      "grad_norm": 26.98733139038086,
      "learning_rate": 1.512e-06,
      "loss": 0.8014,
      "step": 23110
    },
    {
      "epoch": 924.8,
      "grad_norm": 4.451650619506836,
      "learning_rate": 1.5040000000000001e-06,
      "loss": 0.7675,
      "step": 23120
    },
    {
      "epoch": 925.2,
      "grad_norm": 20.138139724731445,
      "learning_rate": 1.4960000000000002e-06,
      "loss": 0.8026,
      "step": 23130
    },
    {
      "epoch": 925.6,
      "grad_norm": 11.798932075500488,
      "learning_rate": 1.488e-06,
      "loss": 0.7658,
      "step": 23140
    },
    {
      "epoch": 926.0,
      "grad_norm": 13.236940383911133,
      "learning_rate": 1.48e-06,
      "loss": 0.7916,
      "step": 23150
    },
    {
      "epoch": 926.4,
      "grad_norm": 6.221673488616943,
      "learning_rate": 1.472e-06,
      "loss": 0.7683,
      "step": 23160
    },
    {
      "epoch": 926.8,
      "grad_norm": 7.459372043609619,
      "learning_rate": 1.464e-06,
      "loss": 0.7526,
      "step": 23170
    },
    {
      "epoch": 927.2,
      "grad_norm": 3.486417770385742,
      "learning_rate": 1.4560000000000001e-06,
      "loss": 0.8125,
      "step": 23180
    },
    {
      "epoch": 927.6,
      "grad_norm": 30.412519454956055,
      "learning_rate": 1.4480000000000002e-06,
      "loss": 0.8079,
      "step": 23190
    },
    {
      "epoch": 928.0,
      "grad_norm": 5.965697288513184,
      "learning_rate": 1.44e-06,
      "loss": 0.779,
      "step": 23200
    },
    {
      "epoch": 928.4,
      "grad_norm": 5.426610469818115,
      "learning_rate": 1.432e-06,
      "loss": 0.7822,
      "step": 23210
    },
    {
      "epoch": 928.8,
      "grad_norm": 8.913640022277832,
      "learning_rate": 1.424e-06,
      "loss": 0.8216,
      "step": 23220
    },
    {
      "epoch": 929.2,
      "grad_norm": 6.721524238586426,
      "learning_rate": 1.416e-06,
      "loss": 0.7669,
      "step": 23230
    },
    {
      "epoch": 929.6,
      "grad_norm": 5.907192707061768,
      "learning_rate": 1.4080000000000001e-06,
      "loss": 0.7999,
      "step": 23240
    },
    {
      "epoch": 930.0,
      "grad_norm": 6.681097984313965,
      "learning_rate": 1.4000000000000001e-06,
      "loss": 0.77,
      "step": 23250
    },
    {
      "epoch": 930.4,
      "grad_norm": 7.2893266677856445,
      "learning_rate": 1.392e-06,
      "loss": 0.7771,
      "step": 23260
    },
    {
      "epoch": 930.8,
      "grad_norm": 5.1493024826049805,
      "learning_rate": 1.384e-06,
      "loss": 0.7847,
      "step": 23270
    },
    {
      "epoch": 931.2,
      "grad_norm": 14.076762199401855,
      "learning_rate": 1.376e-06,
      "loss": 0.7905,
      "step": 23280
    },
    {
      "epoch": 931.6,
      "grad_norm": 11.995781898498535,
      "learning_rate": 1.368e-06,
      "loss": 0.7852,
      "step": 23290
    },
    {
      "epoch": 932.0,
      "grad_norm": 7.4766764640808105,
      "learning_rate": 1.3600000000000001e-06,
      "loss": 0.7973,
      "step": 23300
    },
    {
      "epoch": 932.4,
      "grad_norm": 4.32503604888916,
      "learning_rate": 1.352e-06,
      "loss": 0.8137,
      "step": 23310
    },
    {
      "epoch": 932.8,
      "grad_norm": 9.342803955078125,
      "learning_rate": 1.344e-06,
      "loss": 0.7878,
      "step": 23320
    },
    {
      "epoch": 933.2,
      "grad_norm": 9.47799301147461,
      "learning_rate": 1.336e-06,
      "loss": 0.7792,
      "step": 23330
    },
    {
      "epoch": 933.6,
      "grad_norm": 16.464109420776367,
      "learning_rate": 1.328e-06,
      "loss": 0.7635,
      "step": 23340
    },
    {
      "epoch": 934.0,
      "grad_norm": 11.853658676147461,
      "learning_rate": 1.32e-06,
      "loss": 0.7894,
      "step": 23350
    },
    {
      "epoch": 934.4,
      "grad_norm": 5.389631271362305,
      "learning_rate": 1.3120000000000003e-06,
      "loss": 0.8322,
      "step": 23360
    },
    {
      "epoch": 934.8,
      "grad_norm": 4.159948348999023,
      "learning_rate": 1.304e-06,
      "loss": 0.7715,
      "step": 23370
    },
    {
      "epoch": 935.2,
      "grad_norm": 8.655744552612305,
      "learning_rate": 1.296e-06,
      "loss": 0.7644,
      "step": 23380
    },
    {
      "epoch": 935.6,
      "grad_norm": 16.603906631469727,
      "learning_rate": 1.288e-06,
      "loss": 0.8188,
      "step": 23390
    },
    {
      "epoch": 936.0,
      "grad_norm": 20.950620651245117,
      "learning_rate": 1.28e-06,
      "loss": 0.7775,
      "step": 23400
    },
    {
      "epoch": 936.4,
      "grad_norm": 6.450145721435547,
      "learning_rate": 1.2720000000000003e-06,
      "loss": 0.7887,
      "step": 23410
    },
    {
      "epoch": 936.8,
      "grad_norm": 18.229642868041992,
      "learning_rate": 1.2640000000000003e-06,
      "loss": 0.8068,
      "step": 23420
    },
    {
      "epoch": 937.2,
      "grad_norm": 10.522418022155762,
      "learning_rate": 1.256e-06,
      "loss": 0.7868,
      "step": 23430
    },
    {
      "epoch": 937.6,
      "grad_norm": 28.0279541015625,
      "learning_rate": 1.248e-06,
      "loss": 0.7992,
      "step": 23440
    },
    {
      "epoch": 938.0,
      "grad_norm": 13.796463966369629,
      "learning_rate": 1.2400000000000002e-06,
      "loss": 0.788,
      "step": 23450
    },
    {
      "epoch": 938.4,
      "grad_norm": 14.63631820678711,
      "learning_rate": 1.2320000000000002e-06,
      "loss": 0.7973,
      "step": 23460
    },
    {
      "epoch": 938.8,
      "grad_norm": 26.51325798034668,
      "learning_rate": 1.224e-06,
      "loss": 0.7947,
      "step": 23470
    },
    {
      "epoch": 939.2,
      "grad_norm": 4.686963081359863,
      "learning_rate": 1.216e-06,
      "loss": 0.8057,
      "step": 23480
    },
    {
      "epoch": 939.6,
      "grad_norm": 14.85594367980957,
      "learning_rate": 1.2080000000000001e-06,
      "loss": 0.7952,
      "step": 23490
    },
    {
      "epoch": 940.0,
      "grad_norm": 9.827336311340332,
      "learning_rate": 1.2000000000000002e-06,
      "loss": 0.8041,
      "step": 23500
    },
    {
      "epoch": 940.4,
      "grad_norm": 11.699251174926758,
      "learning_rate": 1.1920000000000002e-06,
      "loss": 0.7737,
      "step": 23510
    },
    {
      "epoch": 940.8,
      "grad_norm": 15.491106033325195,
      "learning_rate": 1.1840000000000002e-06,
      "loss": 0.7905,
      "step": 23520
    },
    {
      "epoch": 941.2,
      "grad_norm": 10.234272003173828,
      "learning_rate": 1.176e-06,
      "loss": 0.8009,
      "step": 23530
    },
    {
      "epoch": 941.6,
      "grad_norm": 9.778539657592773,
      "learning_rate": 1.168e-06,
      "loss": 0.7893,
      "step": 23540
    },
    {
      "epoch": 942.0,
      "grad_norm": 5.601399898529053,
      "learning_rate": 1.1600000000000001e-06,
      "loss": 0.785,
      "step": 23550
    },
    {
      "epoch": 942.4,
      "grad_norm": 17.55587387084961,
      "learning_rate": 1.1520000000000002e-06,
      "loss": 0.7959,
      "step": 23560
    },
    {
      "epoch": 942.8,
      "grad_norm": 16.056806564331055,
      "learning_rate": 1.1440000000000002e-06,
      "loss": 0.8049,
      "step": 23570
    },
    {
      "epoch": 943.2,
      "grad_norm": 13.25644588470459,
      "learning_rate": 1.1360000000000002e-06,
      "loss": 0.785,
      "step": 23580
    },
    {
      "epoch": 943.6,
      "grad_norm": 5.997614860534668,
      "learning_rate": 1.128e-06,
      "loss": 0.7847,
      "step": 23590
    },
    {
      "epoch": 944.0,
      "grad_norm": 16.04939842224121,
      "learning_rate": 1.12e-06,
      "loss": 0.7804,
      "step": 23600
    },
    {
      "epoch": 944.4,
      "grad_norm": 14.67269229888916,
      "learning_rate": 1.1120000000000001e-06,
      "loss": 0.7744,
      "step": 23610
    },
    {
      "epoch": 944.8,
      "grad_norm": 5.599843502044678,
      "learning_rate": 1.1040000000000001e-06,
      "loss": 0.8193,
      "step": 23620
    },
    {
      "epoch": 945.2,
      "grad_norm": 3.9074649810791016,
      "learning_rate": 1.0960000000000002e-06,
      "loss": 0.807,
      "step": 23630
    },
    {
      "epoch": 945.6,
      "grad_norm": 9.66919231414795,
      "learning_rate": 1.088e-06,
      "loss": 0.7574,
      "step": 23640
    },
    {
      "epoch": 946.0,
      "grad_norm": 21.534807205200195,
      "learning_rate": 1.08e-06,
      "loss": 0.7752,
      "step": 23650
    },
    {
      "epoch": 946.4,
      "grad_norm": 13.979294776916504,
      "learning_rate": 1.072e-06,
      "loss": 0.7932,
      "step": 23660
    },
    {
      "epoch": 946.8,
      "grad_norm": 10.583748817443848,
      "learning_rate": 1.064e-06,
      "loss": 0.7844,
      "step": 23670
    },
    {
      "epoch": 947.2,
      "grad_norm": 11.612338066101074,
      "learning_rate": 1.0560000000000001e-06,
      "loss": 0.7712,
      "step": 23680
    },
    {
      "epoch": 947.6,
      "grad_norm": 6.333192825317383,
      "learning_rate": 1.0480000000000002e-06,
      "loss": 0.7963,
      "step": 23690
    },
    {
      "epoch": 948.0,
      "grad_norm": 10.956186294555664,
      "learning_rate": 1.04e-06,
      "loss": 0.81,
      "step": 23700
    },
    {
      "epoch": 948.4,
      "grad_norm": 20.927406311035156,
      "learning_rate": 1.032e-06,
      "loss": 0.7734,
      "step": 23710
    },
    {
      "epoch": 948.8,
      "grad_norm": 16.877328872680664,
      "learning_rate": 1.024e-06,
      "loss": 0.8124,
      "step": 23720
    },
    {
      "epoch": 949.2,
      "grad_norm": 3.874218702316284,
      "learning_rate": 1.016e-06,
      "loss": 0.7781,
      "step": 23730
    },
    {
      "epoch": 949.6,
      "grad_norm": 11.881978988647461,
      "learning_rate": 1.0080000000000001e-06,
      "loss": 0.7889,
      "step": 23740
    },
    {
      "epoch": 950.0,
      "grad_norm": 12.559118270874023,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.7674,
      "step": 23750
    },
    {
      "epoch": 950.4,
      "grad_norm": 4.221888542175293,
      "learning_rate": 9.92e-07,
      "loss": 0.7597,
      "step": 23760
    },
    {
      "epoch": 950.8,
      "grad_norm": 3.4407994747161865,
      "learning_rate": 9.84e-07,
      "loss": 0.8132,
      "step": 23770
    },
    {
      "epoch": 951.2,
      "grad_norm": 12.192229270935059,
      "learning_rate": 9.76e-07,
      "loss": 0.8103,
      "step": 23780
    },
    {
      "epoch": 951.6,
      "grad_norm": 15.436333656311035,
      "learning_rate": 9.68e-07,
      "loss": 0.8164,
      "step": 23790
    },
    {
      "epoch": 952.0,
      "grad_norm": 10.417203903198242,
      "learning_rate": 9.600000000000001e-07,
      "loss": 0.7751,
      "step": 23800
    },
    {
      "epoch": 952.4,
      "grad_norm": 13.611154556274414,
      "learning_rate": 9.520000000000002e-07,
      "loss": 0.8071,
      "step": 23810
    },
    {
      "epoch": 952.8,
      "grad_norm": 14.035871505737305,
      "learning_rate": 9.440000000000001e-07,
      "loss": 0.7776,
      "step": 23820
    },
    {
      "epoch": 953.2,
      "grad_norm": 9.882955551147461,
      "learning_rate": 9.360000000000001e-07,
      "loss": 0.8029,
      "step": 23830
    },
    {
      "epoch": 953.6,
      "grad_norm": 9.162284851074219,
      "learning_rate": 9.28e-07,
      "loss": 0.7665,
      "step": 23840
    },
    {
      "epoch": 954.0,
      "grad_norm": 17.707698822021484,
      "learning_rate": 9.200000000000001e-07,
      "loss": 0.7767,
      "step": 23850
    },
    {
      "epoch": 954.4,
      "grad_norm": 22.7930965423584,
      "learning_rate": 9.120000000000001e-07,
      "loss": 0.7801,
      "step": 23860
    },
    {
      "epoch": 954.8,
      "grad_norm": 5.0034098625183105,
      "learning_rate": 9.04e-07,
      "loss": 0.7833,
      "step": 23870
    },
    {
      "epoch": 955.2,
      "grad_norm": 11.782465934753418,
      "learning_rate": 8.960000000000001e-07,
      "loss": 0.8132,
      "step": 23880
    },
    {
      "epoch": 955.6,
      "grad_norm": 5.129108428955078,
      "learning_rate": 8.880000000000001e-07,
      "loss": 0.7767,
      "step": 23890
    },
    {
      "epoch": 956.0,
      "grad_norm": 8.475641250610352,
      "learning_rate": 8.8e-07,
      "loss": 0.8136,
      "step": 23900
    },
    {
      "epoch": 956.4,
      "grad_norm": 4.801186561584473,
      "learning_rate": 8.720000000000001e-07,
      "loss": 0.7804,
      "step": 23910
    },
    {
      "epoch": 956.8,
      "grad_norm": 5.197455406188965,
      "learning_rate": 8.640000000000001e-07,
      "loss": 0.7914,
      "step": 23920
    },
    {
      "epoch": 957.2,
      "grad_norm": 8.45261287689209,
      "learning_rate": 8.56e-07,
      "loss": 0.744,
      "step": 23930
    },
    {
      "epoch": 957.6,
      "grad_norm": 10.141430854797363,
      "learning_rate": 8.480000000000001e-07,
      "loss": 0.7619,
      "step": 23940
    },
    {
      "epoch": 958.0,
      "grad_norm": 12.2708740234375,
      "learning_rate": 8.400000000000001e-07,
      "loss": 0.7937,
      "step": 23950
    },
    {
      "epoch": 958.4,
      "grad_norm": 14.494327545166016,
      "learning_rate": 8.32e-07,
      "loss": 0.8116,
      "step": 23960
    },
    {
      "epoch": 958.8,
      "grad_norm": 14.493620872497559,
      "learning_rate": 8.240000000000001e-07,
      "loss": 0.7715,
      "step": 23970
    },
    {
      "epoch": 959.2,
      "grad_norm": 29.533428192138672,
      "learning_rate": 8.160000000000001e-07,
      "loss": 0.7917,
      "step": 23980
    },
    {
      "epoch": 959.6,
      "grad_norm": 5.762932300567627,
      "learning_rate": 8.08e-07,
      "loss": 0.7694,
      "step": 23990
    },
    {
      "epoch": 960.0,
      "grad_norm": 19.294837951660156,
      "learning_rate": 8.000000000000001e-07,
      "loss": 0.8071,
      "step": 24000
    },
    {
      "epoch": 960.4,
      "grad_norm": 7.547972202301025,
      "learning_rate": 7.920000000000001e-07,
      "loss": 0.7668,
      "step": 24010
    },
    {
      "epoch": 960.8,
      "grad_norm": 12.277533531188965,
      "learning_rate": 7.84e-07,
      "loss": 0.7583,
      "step": 24020
    },
    {
      "epoch": 961.2,
      "grad_norm": 6.717729568481445,
      "learning_rate": 7.760000000000001e-07,
      "loss": 0.8108,
      "step": 24030
    },
    {
      "epoch": 961.6,
      "grad_norm": 6.478728294372559,
      "learning_rate": 7.68e-07,
      "loss": 0.7915,
      "step": 24040
    },
    {
      "epoch": 962.0,
      "grad_norm": 9.583157539367676,
      "learning_rate": 7.6e-07,
      "loss": 0.7922,
      "step": 24050
    },
    {
      "epoch": 962.4,
      "grad_norm": 10.268223762512207,
      "learning_rate": 7.520000000000001e-07,
      "loss": 0.8108,
      "step": 24060
    },
    {
      "epoch": 962.8,
      "grad_norm": 7.9830546379089355,
      "learning_rate": 7.44e-07,
      "loss": 0.7766,
      "step": 24070
    },
    {
      "epoch": 963.2,
      "grad_norm": 6.217845439910889,
      "learning_rate": 7.36e-07,
      "loss": 0.7792,
      "step": 24080
    },
    {
      "epoch": 963.6,
      "grad_norm": 2.9303112030029297,
      "learning_rate": 7.280000000000001e-07,
      "loss": 0.7541,
      "step": 24090
    },
    {
      "epoch": 964.0,
      "grad_norm": 3.7359957695007324,
      "learning_rate": 7.2e-07,
      "loss": 0.785,
      "step": 24100
    },
    {
      "epoch": 964.4,
      "grad_norm": 5.9711503982543945,
      "learning_rate": 7.12e-07,
      "loss": 0.8082,
      "step": 24110
    },
    {
      "epoch": 964.8,
      "grad_norm": 6.694952964782715,
      "learning_rate": 7.040000000000001e-07,
      "loss": 0.7734,
      "step": 24120
    },
    {
      "epoch": 965.2,
      "grad_norm": 9.772940635681152,
      "learning_rate": 6.96e-07,
      "loss": 0.7792,
      "step": 24130
    },
    {
      "epoch": 965.6,
      "grad_norm": 5.147880554199219,
      "learning_rate": 6.88e-07,
      "loss": 0.8,
      "step": 24140
    },
    {
      "epoch": 966.0,
      "grad_norm": 3.7790400981903076,
      "learning_rate": 6.800000000000001e-07,
      "loss": 0.7998,
      "step": 24150
    },
    {
      "epoch": 966.4,
      "grad_norm": 8.009200096130371,
      "learning_rate": 6.72e-07,
      "loss": 0.7922,
      "step": 24160
    },
    {
      "epoch": 966.8,
      "grad_norm": 20.40108299255371,
      "learning_rate": 6.64e-07,
      "loss": 0.7783,
      "step": 24170
    },
    {
      "epoch": 967.2,
      "grad_norm": 4.377744674682617,
      "learning_rate": 6.560000000000002e-07,
      "loss": 0.7843,
      "step": 24180
    },
    {
      "epoch": 967.6,
      "grad_norm": 8.806824684143066,
      "learning_rate": 6.48e-07,
      "loss": 0.7821,
      "step": 24190
    },
    {
      "epoch": 968.0,
      "grad_norm": 9.646270751953125,
      "learning_rate": 6.4e-07,
      "loss": 0.7938,
      "step": 24200
    },
    {
      "epoch": 968.4,
      "grad_norm": 13.639986991882324,
      "learning_rate": 6.320000000000002e-07,
      "loss": 0.813,
      "step": 24210
    },
    {
      "epoch": 968.8,
      "grad_norm": 9.607888221740723,
      "learning_rate": 6.24e-07,
      "loss": 0.8005,
      "step": 24220
    },
    {
      "epoch": 969.2,
      "grad_norm": 4.012691497802734,
      "learning_rate": 6.160000000000001e-07,
      "loss": 0.772,
      "step": 24230
    },
    {
      "epoch": 969.6,
      "grad_norm": 8.734903335571289,
      "learning_rate": 6.08e-07,
      "loss": 0.8103,
      "step": 24240
    },
    {
      "epoch": 970.0,
      "grad_norm": 36.68321990966797,
      "learning_rate": 6.000000000000001e-07,
      "loss": 0.804,
      "step": 24250
    },
    {
      "epoch": 970.4,
      "grad_norm": 15.357222557067871,
      "learning_rate": 5.920000000000001e-07,
      "loss": 0.8149,
      "step": 24260
    },
    {
      "epoch": 970.8,
      "grad_norm": 3.757934331893921,
      "learning_rate": 5.84e-07,
      "loss": 0.7933,
      "step": 24270
    },
    {
      "epoch": 971.2,
      "grad_norm": 10.090957641601562,
      "learning_rate": 5.760000000000001e-07,
      "loss": 0.7863,
      "step": 24280
    },
    {
      "epoch": 971.6,
      "grad_norm": 20.007068634033203,
      "learning_rate": 5.680000000000001e-07,
      "loss": 0.821,
      "step": 24290
    },
    {
      "epoch": 972.0,
      "grad_norm": 18.1865291595459,
      "learning_rate": 5.6e-07,
      "loss": 0.8128,
      "step": 24300
    },
    {
      "epoch": 972.4,
      "grad_norm": 11.391682624816895,
      "learning_rate": 5.520000000000001e-07,
      "loss": 0.7639,
      "step": 24310
    },
    {
      "epoch": 972.8,
      "grad_norm": 11.392425537109375,
      "learning_rate": 5.44e-07,
      "loss": 0.7834,
      "step": 24320
    },
    {
      "epoch": 973.2,
      "grad_norm": 12.354409217834473,
      "learning_rate": 5.36e-07,
      "loss": 0.792,
      "step": 24330
    },
    {
      "epoch": 973.6,
      "grad_norm": 7.207925319671631,
      "learning_rate": 5.280000000000001e-07,
      "loss": 0.8144,
      "step": 24340
    },
    {
      "epoch": 974.0,
      "grad_norm": 9.60055160522461,
      "learning_rate": 5.2e-07,
      "loss": 0.7948,
      "step": 24350
    },
    {
      "epoch": 974.4,
      "grad_norm": 14.870254516601562,
      "learning_rate": 5.12e-07,
      "loss": 0.7715,
      "step": 24360
    },
    {
      "epoch": 974.8,
      "grad_norm": 7.799767017364502,
      "learning_rate": 5.040000000000001e-07,
      "loss": 0.8119,
      "step": 24370
    },
    {
      "epoch": 975.2,
      "grad_norm": 15.179903984069824,
      "learning_rate": 4.96e-07,
      "loss": 0.79,
      "step": 24380
    },
    {
      "epoch": 975.6,
      "grad_norm": 22.731523513793945,
      "learning_rate": 4.88e-07,
      "loss": 0.7555,
      "step": 24390
    },
    {
      "epoch": 976.0,
      "grad_norm": 8.512452125549316,
      "learning_rate": 4.800000000000001e-07,
      "loss": 0.8145,
      "step": 24400
    },
    {
      "epoch": 976.4,
      "grad_norm": 8.238227844238281,
      "learning_rate": 4.7200000000000004e-07,
      "loss": 0.7893,
      "step": 24410
    },
    {
      "epoch": 976.8,
      "grad_norm": 15.655999183654785,
      "learning_rate": 4.64e-07,
      "loss": 0.7879,
      "step": 24420
    },
    {
      "epoch": 977.2,
      "grad_norm": 21.753074645996094,
      "learning_rate": 4.5600000000000006e-07,
      "loss": 0.7935,
      "step": 24430
    },
    {
      "epoch": 977.6,
      "grad_norm": 11.9629487991333,
      "learning_rate": 4.4800000000000004e-07,
      "loss": 0.8103,
      "step": 24440
    },
    {
      "epoch": 978.0,
      "grad_norm": 12.219908714294434,
      "learning_rate": 4.4e-07,
      "loss": 0.7805,
      "step": 24450
    },
    {
      "epoch": 978.4,
      "grad_norm": 12.784062385559082,
      "learning_rate": 4.3200000000000006e-07,
      "loss": 0.7834,
      "step": 24460
    },
    {
      "epoch": 978.8,
      "grad_norm": 3.6228790283203125,
      "learning_rate": 4.2400000000000004e-07,
      "loss": 0.7784,
      "step": 24470
    },
    {
      "epoch": 979.2,
      "grad_norm": 12.232060432434082,
      "learning_rate": 4.16e-07,
      "loss": 0.7982,
      "step": 24480
    },
    {
      "epoch": 979.6,
      "grad_norm": 11.038174629211426,
      "learning_rate": 4.0800000000000005e-07,
      "loss": 0.8056,
      "step": 24490
    },
    {
      "epoch": 980.0,
      "grad_norm": 4.6592230796813965,
      "learning_rate": 4.0000000000000003e-07,
      "loss": 0.783,
      "step": 24500
    },
    {
      "epoch": 980.4,
      "grad_norm": 7.515757083892822,
      "learning_rate": 3.92e-07,
      "loss": 0.7723,
      "step": 24510
    },
    {
      "epoch": 980.8,
      "grad_norm": 6.556680679321289,
      "learning_rate": 3.84e-07,
      "loss": 0.7913,
      "step": 24520
    },
    {
      "epoch": 981.2,
      "grad_norm": 5.6716461181640625,
      "learning_rate": 3.7600000000000003e-07,
      "loss": 0.7813,
      "step": 24530
    },
    {
      "epoch": 981.6,
      "grad_norm": 12.290019989013672,
      "learning_rate": 3.68e-07,
      "loss": 0.8079,
      "step": 24540
    },
    {
      "epoch": 982.0,
      "grad_norm": 4.32669734954834,
      "learning_rate": 3.6e-07,
      "loss": 0.766,
      "step": 24550
    },
    {
      "epoch": 982.4,
      "grad_norm": 11.22471809387207,
      "learning_rate": 3.5200000000000003e-07,
      "loss": 0.7866,
      "step": 24560
    },
    {
      "epoch": 982.8,
      "grad_norm": 3.1862456798553467,
      "learning_rate": 3.44e-07,
      "loss": 0.8045,
      "step": 24570
    },
    {
      "epoch": 983.2,
      "grad_norm": 4.2452778816223145,
      "learning_rate": 3.36e-07,
      "loss": 0.7754,
      "step": 24580
    },
    {
      "epoch": 983.6,
      "grad_norm": 4.450268745422363,
      "learning_rate": 3.280000000000001e-07,
      "loss": 0.7921,
      "step": 24590
    },
    {
      "epoch": 984.0,
      "grad_norm": 7.103703022003174,
      "learning_rate": 3.2e-07,
      "loss": 0.8024,
      "step": 24600
    },
    {
      "epoch": 984.4,
      "grad_norm": 12.649662971496582,
      "learning_rate": 3.12e-07,
      "loss": 0.7888,
      "step": 24610
    },
    {
      "epoch": 984.8,
      "grad_norm": 7.509141445159912,
      "learning_rate": 3.04e-07,
      "loss": 0.7928,
      "step": 24620
    },
    {
      "epoch": 985.2,
      "grad_norm": 8.91793441772461,
      "learning_rate": 2.9600000000000006e-07,
      "loss": 0.7926,
      "step": 24630
    },
    {
      "epoch": 985.6,
      "grad_norm": 3.8790087699890137,
      "learning_rate": 2.8800000000000004e-07,
      "loss": 0.8024,
      "step": 24640
    },
    {
      "epoch": 986.0,
      "grad_norm": 20.46806526184082,
      "learning_rate": 2.8e-07,
      "loss": 0.7707,
      "step": 24650
    },
    {
      "epoch": 986.4,
      "grad_norm": 3.5978891849517822,
      "learning_rate": 2.72e-07,
      "loss": 0.7994,
      "step": 24660
    },
    {
      "epoch": 986.8,
      "grad_norm": 12.004870414733887,
      "learning_rate": 2.6400000000000003e-07,
      "loss": 0.7953,
      "step": 24670
    },
    {
      "epoch": 987.2,
      "grad_norm": 6.354410648345947,
      "learning_rate": 2.56e-07,
      "loss": 0.7756,
      "step": 24680
    },
    {
      "epoch": 987.6,
      "grad_norm": 21.80596160888672,
      "learning_rate": 2.48e-07,
      "loss": 0.7952,
      "step": 24690
    },
    {
      "epoch": 988.0,
      "grad_norm": 8.862419128417969,
      "learning_rate": 2.4000000000000003e-07,
      "loss": 0.7641,
      "step": 24700
    },
    {
      "epoch": 988.4,
      "grad_norm": 5.929675102233887,
      "learning_rate": 2.32e-07,
      "loss": 0.827,
      "step": 24710
    },
    {
      "epoch": 988.8,
      "grad_norm": 10.475892066955566,
      "learning_rate": 2.2400000000000002e-07,
      "loss": 0.7825,
      "step": 24720
    },
    {
      "epoch": 989.2,
      "grad_norm": 10.888025283813477,
      "learning_rate": 2.1600000000000003e-07,
      "loss": 0.8012,
      "step": 24730
    },
    {
      "epoch": 989.6,
      "grad_norm": 7.28345251083374,
      "learning_rate": 2.08e-07,
      "loss": 0.7926,
      "step": 24740
    },
    {
      "epoch": 990.0,
      "grad_norm": 11.673789024353027,
      "learning_rate": 2.0000000000000002e-07,
      "loss": 0.7874,
      "step": 24750
    },
    {
      "epoch": 990.4,
      "grad_norm": 10.556862831115723,
      "learning_rate": 1.92e-07,
      "loss": 0.772,
      "step": 24760
    },
    {
      "epoch": 990.8,
      "grad_norm": 6.725208282470703,
      "learning_rate": 1.84e-07,
      "loss": 0.7924,
      "step": 24770
    },
    {
      "epoch": 991.2,
      "grad_norm": 27.40730094909668,
      "learning_rate": 1.7600000000000001e-07,
      "loss": 0.7792,
      "step": 24780
    },
    {
      "epoch": 991.6,
      "grad_norm": 7.174427509307861,
      "learning_rate": 1.68e-07,
      "loss": 0.8074,
      "step": 24790
    },
    {
      "epoch": 992.0,
      "grad_norm": 14.812591552734375,
      "learning_rate": 1.6e-07,
      "loss": 0.7887,
      "step": 24800
    },
    {
      "epoch": 992.4,
      "grad_norm": 9.728845596313477,
      "learning_rate": 1.52e-07,
      "loss": 0.776,
      "step": 24810
    },
    {
      "epoch": 992.8,
      "grad_norm": 7.618686199188232,
      "learning_rate": 1.4400000000000002e-07,
      "loss": 0.7666,
      "step": 24820
    },
    {
      "epoch": 993.2,
      "grad_norm": 13.136109352111816,
      "learning_rate": 1.36e-07,
      "loss": 0.7736,
      "step": 24830
    },
    {
      "epoch": 993.6,
      "grad_norm": 9.140373229980469,
      "learning_rate": 1.28e-07,
      "loss": 0.7835,
      "step": 24840
    },
    {
      "epoch": 994.0,
      "grad_norm": 10.473536491394043,
      "learning_rate": 1.2000000000000002e-07,
      "loss": 0.7993,
      "step": 24850
    },
    {
      "epoch": 994.4,
      "grad_norm": 4.457634925842285,
      "learning_rate": 1.1200000000000001e-07,
      "loss": 0.8023,
      "step": 24860
    },
    {
      "epoch": 994.8,
      "grad_norm": 9.3051176071167,
      "learning_rate": 1.04e-07,
      "loss": 0.7946,
      "step": 24870
    },
    {
      "epoch": 995.2,
      "grad_norm": 6.212364196777344,
      "learning_rate": 9.6e-08,
      "loss": 0.7842,
      "step": 24880
    },
    {
      "epoch": 995.6,
      "grad_norm": 12.29541301727295,
      "learning_rate": 8.800000000000001e-08,
      "loss": 0.7936,
      "step": 24890
    },
    {
      "epoch": 996.0,
      "grad_norm": 15.590035438537598,
      "learning_rate": 8e-08,
      "loss": 0.7724,
      "step": 24900
    },
    {
      "epoch": 996.4,
      "grad_norm": 30.729047775268555,
      "learning_rate": 7.200000000000001e-08,
      "loss": 0.8135,
      "step": 24910
    },
    {
      "epoch": 996.8,
      "grad_norm": 9.933777809143066,
      "learning_rate": 6.4e-08,
      "loss": 0.7754,
      "step": 24920
    },
    {
      "epoch": 997.2,
      "grad_norm": 13.734128952026367,
      "learning_rate": 5.6000000000000005e-08,
      "loss": 0.7728,
      "step": 24930
    },
    {
      "epoch": 997.6,
      "grad_norm": 5.753314018249512,
      "learning_rate": 4.8e-08,
      "loss": 0.7544,
      "step": 24940
    },
    {
      "epoch": 998.0,
      "grad_norm": 5.487344264984131,
      "learning_rate": 4e-08,
      "loss": 0.7977,
      "step": 24950
    },
    {
      "epoch": 998.4,
      "grad_norm": 12.364362716674805,
      "learning_rate": 3.2e-08,
      "loss": 0.7811,
      "step": 24960
    },
    {
      "epoch": 998.8,
      "grad_norm": 12.698321342468262,
      "learning_rate": 2.4e-08,
      "loss": 0.7834,
      "step": 24970
    },
    {
      "epoch": 999.2,
      "grad_norm": 4.857914447784424,
      "learning_rate": 1.6e-08,
      "loss": 0.7663,
      "step": 24980
    },
    {
      "epoch": 999.6,
      "grad_norm": 11.81200885772705,
      "learning_rate": 8e-09,
      "loss": 0.7825,
      "step": 24990
    },
    {
      "epoch": 1000.0,
      "grad_norm": 13.415609359741211,
      "learning_rate": 0.0,
      "loss": 0.7923,
      "step": 25000
    }
  ],
  "logging_steps": 10,
  "max_steps": 25000,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 1000,
  "save_steps": 1000,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 2380032000000.0,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
